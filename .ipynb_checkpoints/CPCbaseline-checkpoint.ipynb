{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "z57IXf9q1Ovh",
    "outputId": "1b2cbade-88b2-48d7-b64c-3ab7d29c1715"
   },
   "outputs": [],
   "source": [
    "# if colab\n",
    "\n",
    "# !pip install pybullet\n",
    "# !pip install gym\n",
    "# !apt-get install python-opengl -y\n",
    "# !apt install xvfb -y\n",
    "# !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "# !pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t8ezUpd1SIy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np \n",
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "import pybullet_envs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "y0_9dbk8Cbnv",
    "outputId": "4cdb116a-5cec-4456-dc79-f07bb48d9fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_seed = 654765645\n",
    "tf_seed = 776644345\n",
    "np.random.seed(np_seed)\n",
    "tf.random.set_seed(tf_seed)\n",
    "\n",
    "# check if GPU\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hG1Ruv5FCgDv",
    "outputId": "4fe5a6b2-b4e6-4241-e5ca-c412cf4637a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# root_dir = \"drive/My Drive/\"\n",
    "# base_dir = root_dir + 'CPCtesting'\n",
    "# os.makedirs(base_dir,exist_ok=True)\n",
    "\n",
    "# train_dir = base_dir + '/train'\n",
    "# os.makedirs(train_dir,exist_ok=True)\n",
    "\n",
    "# model_dir = base_dir + '/model'\n",
    "# os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "# if local machine\n",
    "base_dir = \".\"\n",
    "\n",
    "train_dir = base_dir + '/train'\n",
    "os.makedirs(train_dir,exist_ok=True)\n",
    "\n",
    "model_dir = base_dir + '/model'\n",
    "os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "logs_base_dir = base_dir + '/logs'\n",
    "\n",
    "log_dir = base_dir + '/training_logs_save'\n",
    "\n",
    "reward_dir = base_dir + '/training_rewards_save'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# tensorboard\n",
    "%load_ext tensorboard\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWEWANi66t_w"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIKY-VyC1bsu"
   },
   "outputs": [],
   "source": [
    "class CPCModel(tf.keras.Model):\n",
    "    def __init__(self,code_size, predict_terms, terms=4, units=256, image_size=64, channels=3):\n",
    "        super(CPCModel, self).__init__()\n",
    "        self.code_size = code_size\n",
    "        self.predict_terms = predict_terms\n",
    "        self.terms = terms\n",
    "        self.units = units\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu1 = tf.keras.layers.LeakyReLU()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu2 = tf.keras.layers.LeakyReLU()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu3 = tf.keras.layers.LeakyReLU()\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu4 = tf.keras.layers.LeakyReLU()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense5 = tf.keras.layers.Dense(units=256, activation='linear')\n",
    "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu5 = tf.keras.layers.LeakyReLU()\n",
    "        self.dense6 = tf.keras.layers.Dense(units=code_size, activation='linear', name='encoder_embedding')\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(units, return_sequences=False, name='ar_context')\n",
    "        self.linear = tf.keras.layers.Dense(predict_terms*code_size, activation='linear')    \n",
    "   \n",
    "    def encoding(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.lrelu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lrelu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.lrelu4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.lrelu5(x)\n",
    "        z = self.dense6(x)\n",
    "        return z\n",
    "  \n",
    "    def get_context(self, x):\n",
    "        z = self.encoding(x)\n",
    "        z = tf.reshape(z, [-1, self.terms, self.code_size])\n",
    "        c = self.gru(z)\n",
    "        return c\n",
    "    def get_prediction(self, x):\n",
    "        c = self.get_context(x)\n",
    "        z_hats = self.linear(c)\n",
    "        z_hat = tf.reshape(z_hats, [-1, self.predict_terms, self.code_size])\n",
    "        return z_hat\n",
    "\n",
    "    def optimizer(self):\n",
    "        pass\n",
    "\n",
    "    def loss(self,weights,biases,labels,inputs,num_samples,num_classes): \n",
    "        loss = tf.nn.nce_loss(\n",
    "        weights, biases, labels, inputs, num_sampled, num_classes, num_true=1,\n",
    "        sampled_values=None, remove_accidental_hits=False, name='nce_loss')\n",
    "        return loss\n",
    "  \n",
    "    def call(self,inputs):\n",
    "        x_tm, x_tp = inputs\n",
    "        x_tm = tf.reshape(x_tm, [-1, self.image_size, self.image_size, self.channels])\n",
    "        x_tp = tf.reshape(x_tp, [-1, self.image_size, self.image_size, self.channels])\n",
    "        z_hat = self.get_prediction(x_tm)\n",
    "        z_tp = self.encoding(x_tp)\n",
    "        z_tp = tf.reshape(z_tp, [-1, self.predict_terms, self.code_size])\n",
    "        dot_prods = tf.reduce_mean(tf.reduce_mean(z_hat*z_tp, axis=-1), axis=-1, keepdims=True)\n",
    "        probs = tf.sigmoid(dot_prods)\n",
    "        return probs\n",
    "\n",
    "\n",
    "  # def save(self):\n",
    "  #       f1 = os.path.join(folder,'target_actor')\n",
    "  #       f2 = os.path.join(folder, 'target_critic')\n",
    "  #       f3 = os.path.join(folder, 'actor')\n",
    "  #       f4 = os.path.join(folder, 'critic')\n",
    "  #       self.target_actor.save(f1)\n",
    "  #       self.target_critic.save(f2)\n",
    "  #       self.actor.save(f3)\n",
    "  #       self.critic.save(f4)\n",
    "\n",
    "\n",
    "  # def load(self):\n",
    "  #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wW6bj9SJkd20"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self,state_space,action_space,capacity,batch):\n",
    "        self.capacity = capacity\n",
    "        self.batch = batch\n",
    "        \n",
    "        self.avaliable_batch = 0\n",
    "        self.idx = 0\n",
    "        self.entries = 0 \n",
    "        \n",
    "        self.states = np.empty((self.capacity,state_space),dtype = np.float32)\n",
    "        self.next_states = np.empty((self.capacity,state_space),dtype = np.float32)\n",
    "        self.actions = np.empty((self.capacity,action_space),dtype = np.float32)\n",
    "        self.rewards = np.empty((self.capacity,1),dtype = np.float32)\n",
    "        self.not_dones = np.empty((self.capacity, 1), dtype=np.float32)\n",
    "        \n",
    "    def add(self,state,next_state,action,reward,done):\n",
    "        np.copyto(self.states[self.idx], state)\n",
    "        np.copyto(self.actions[self.idx], action)\n",
    "        np.copyto(self.rewards[self.idx], reward)\n",
    "        np.copyto(self.next_states[self.idx], next_state)\n",
    "        np.copyto(self.not_dones[self.idx], not done)\n",
    "        #self.avaliable_batch= (self.avaliable_batch + 1) if self.avaliable_batch < self.batch else self.batch\n",
    "        #self.entries = (self.entries + 1) if self.entries < self.capacity else self.capacity\n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "        \n",
    "    def sample(self):\n",
    "        #num = self.avaliable_batch\n",
    "        #if(num > self.batch):\n",
    "        #    num = self.batch\n",
    "        #print('avaliable_batch: ',self.avaliable_batch, \"entries: \", self.entries,'capacity: ', self.capacity)\n",
    "        idx = np.random.choice(self.capacity,size = self.batch,replace=False)\n",
    "        #print('test idx: ', idx)\n",
    "        \n",
    "        states = tf.convert_to_tensor(self.states[idx])\n",
    "        next_states = tf.convert_to_tensor(self.next_states[idx])\n",
    "        actions = tf.convert_to_tensor(self.actions[idx])\n",
    "        rewards = tf.convert_to_tensor(self.rewards[idx])\n",
    "        not_dones = tf.convert_to_tensor(self.not_dones[idx])\n",
    "        \n",
    "        return states,next_states,actions,rewards,not_dones\n",
    "    \n",
    "    def fill_buffer(self,timesteps,state,prev_timesteps):\n",
    "        print('sim test: ',env._max_episode_steps,\":\",timesteps)\n",
    "        for step in range(timesteps):\n",
    "            action = env.action_space.sample()\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            np.copyto(self.states[step], state)\n",
    "            np.copyto(self.actions[step], action)\n",
    "            np.copyto(self.rewards[step], reward)\n",
    "            np.copyto(self.next_states[step], next_state)\n",
    "            np.copyto(self.not_dones[step], not done)\n",
    "            state = next_state\n",
    "            if(done):\n",
    "                print(\"step: \", step)\n",
    "                state = env.reset()\n",
    "                print('done seeding replay buffer')            \n",
    "            \n",
    "        \n",
    "\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self,action_space,critic,actor_lr = 0.001,variance = 0.2):\n",
    "        super(Actor,self).__init__()\n",
    "        \n",
    "        #params\n",
    "        self.std = np.sqrt(variance)\n",
    "        self.noise_flag = 1.0\n",
    "        self.action_space = action_space\n",
    "        \n",
    "        #optimizer\n",
    "        self.opt = tf.keras.optimizers.Adam(actor_lr)\n",
    "        self.critic = critic\n",
    "       \n",
    "        #model\n",
    "        self.dense1 = tf.keras.layers.Dense(400,activation = 'relu',dtype='float32')\n",
    "        self.dense2 = tf.keras.layers.Dense(300,activation='relu',dtype='float32')\n",
    "        self.dense3 = tf.keras.layers.Dense(action_space,activation = 'tanh',dtype='float32')    \n",
    "        \n",
    "    def loss(self,states,actions):\n",
    "        actions = self(states)\n",
    "        #stateactions = tf.concat([states,actions],-1)\n",
    "        Q = self.critic(states,actions)\n",
    "        loss = - tf.reduce_mean(Q)\n",
    "        return loss\n",
    "    \n",
    "    def update(self,states,actions):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss(states,actions)\n",
    "\n",
    "        grad = tape.gradient(loss,self.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grad, self.trainable_variables))\n",
    "        #print('actor loss: ', loss ,\"\\n\" )\n",
    "        return loss\n",
    "    \n",
    "    def set_noise_flag(self,num):\n",
    "        self.noise_flag = np.float32(not not num)\n",
    "    \n",
    "    def continous_noise(self):\n",
    "        result = np.random.normal(0,self.std,size=(self.action_space,))\n",
    "        return self.noise_flag *result\n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self,critic_lr = 0.001):\n",
    "        super(Critic,self).__init__()\n",
    "        \n",
    "        # optimizer\n",
    "        self.opt = tf.keras.optimizers.Adam(critic_lr)\n",
    "        \n",
    "        # loss\n",
    "        #self.loss = tf.keras.losses.MSE\n",
    "        \n",
    "        \n",
    "        # layers\n",
    "        self.dense1 = tf.keras.layers.Dense(400,activation = 'relu',dtype='float32')\n",
    "        self.dense2 = tf.keras.layers.Dense(300,activation='relu',dtype='float32')\n",
    "        self.dense3 = tf.keras.layers.Dense(1,dtype='float32') \n",
    "        \n",
    "    #loss\n",
    "    def loss(self,actual,pred):\n",
    "        result = tf.keras.losses.MSE(actual,pred)\n",
    "        #print('result: ', result)\n",
    "        #print('actual: ', actual.shape) # shape (16,1)\n",
    "        #print('pred: ',pred.shape) # shape (16,1,1,1)\n",
    "        return result\n",
    "    \n",
    "    def update(self,states,actions,Q_h):\n",
    "        match = Q_h.shape[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            Q = self.call(states,actions)\n",
    "            Q = tf.reshape(Q,(1,1,1,match))\n",
    "            Q_h = tf.reshape(Q_h,(1,1,1,match))\n",
    "            loss = self.loss(Q,Q_h)\n",
    "\n",
    "        grad = tape.gradient(loss,self.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grad, self.trainable_variables))\n",
    "        #print('critic loss: ', loss ,\"\\n\" )\n",
    "        return loss\n",
    "    \n",
    "    #predict\n",
    "    def call(self,states,actions):\n",
    "        x = tf.concat([states,actions],-1)\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SAC(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 state_space,\n",
    "                 action_space,\n",
    "                 capacity = 1000,\n",
    "                 batch = 1, \n",
    "                 tau=0.999,\n",
    "                 gamma=0.9,\n",
    "                 actor_lr = 0.001, \n",
    "                 critic_lr = 0.0001,\n",
    "                 variance = 1.0):\n",
    "        super(SAC,self).__init__()\n",
    "        # tensorboard callbacks\n",
    "        self.cb = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=1/3, patience=2, min_lr=1e-4),\n",
    "                   tf.keras.callbacks.ModelCheckpoint('weights/weights.{epoch:02d}-{val_binary_accuracy:.2f}.cpkt',\n",
    "                                          monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True),\n",
    "                   tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3),\n",
    "                   tf.keras.callbacks.TensorBoard()]\n",
    "        \n",
    "        \n",
    "        #hyperparameters\n",
    "        self.batch = batch\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.actor_lr = actor_lr\n",
    "        self.critic_lr = critic_lr\n",
    "        self.noise_flag = 1\n",
    "        self.std = np.sqrt(variance)\n",
    "        \n",
    "        \n",
    "        #spaces\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.state_action_space = self.action_space + self.state_space\n",
    "        \n",
    "        # replay buffer\n",
    "        self.replay_buffer = ReplayBuffer(self.state_space,self.action_space,capacity,self.batch)\n",
    "        \n",
    "        # models\n",
    "        self.critic = Critic(critic_lr = critic_lr)        \n",
    "        self.actor = Actor(self.action_space,actor_lr=actor_lr,critic = self.critic)\n",
    "        #self.critic.compile(optimizer = self.critic.opt,loss = self.critic.loss)\n",
    "        #self.actor.compile(optimizer = self.actor.opt,loss = self.actor.loss)\n",
    "        \n",
    "        # target models\n",
    "        self.target_actor = Actor(self.action_space,actor_lr=actor_lr,critic = self.critic)\n",
    "        self.target_critic = Critic(critic_lr = critic_lr)  \n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "        \n",
    "        #cpc\n",
    "        #self.cpc = CPC(code_size=128, predict_terms=4, terms=4, units=256, image_size=64, channels=3)\n",
    "    \n",
    "    def store_replay(self,state,next_state,action,reward,done):\n",
    "        self.replay_buffer.add(state,next_state,action,reward,done)\n",
    "    \n",
    "    def set_labels(self,states,new_states,actions,rewards):\n",
    "        mu = self.target_actor(new_states)\n",
    "        #print(mu,states)\n",
    "#         stateactions = tf.concat([states,mu],1)\n",
    "        Q_h = self.target_critic(new_states,mu)\n",
    "        y = rewards + self.gamma * Q_h\n",
    "        #y = np.concatenate(self.y,0).astype('float32') #.reshape((self.minibatch_size,1,1,1))\n",
    "        #print('y: ',self.y)\n",
    "        y = tf.reshape(y,(self.replay_buffer.batch,1,1,1))\n",
    "        return y \n",
    "    \n",
    "        \n",
    "    def discrete_random_noise(self):\n",
    "        pass\n",
    "    \n",
    "    def update_target_weights(self):   \n",
    "        tgt_critic_weight = self.target_critic.get_weights()\n",
    "        tgt_actor_weight = self.target_actor.get_weights()\n",
    "        actor_weight = self.actor.get_weights()\n",
    "        critic_weight = self.target_actor.get_weights()\n",
    "        \n",
    "        for idx,(part_tgt,part_net) in enumerate(zip(tgt_critic_weight,critic_weight)):\n",
    "            tgt_critic_weight[idx] = self.tau*part_tgt + (1-self.tau)*part_net\n",
    "        \n",
    "        for idx,(part_tgt,part_net) in enumerate(zip(tgt_actor_weight,actor_weight)):\n",
    "            tgt_actor_weight[idx] = self.tau*part_tgt + (1-self.tau)*part_net\n",
    "            \n",
    "        self.target_actor.set_weights(tgt_actor_weight)\n",
    "        self.target_critic.set_weights(tgt_critic_weight)\n",
    "            \n",
    "    def save(self,filename):\n",
    "        self.actor.save_weights(filename)\n",
    "        self.critic.save_weights(filename)\n",
    "        self.target_actor.save_weights(filename)\n",
    "        self.target_critic.save_weights(filename)\n",
    "    \n",
    "    def load(self,filename):\n",
    "        self.actor.load_weights(filename)\n",
    "        self.critic.load_weights(filename)\n",
    "        self.target_actor.load_weights(filename)\n",
    "        self.target_critic.load_weights(filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StY2xL3E73ea"
   },
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, batch_size, terms, predict_terms=1, image_size=64, color=False, rescale=True, aug=True, is_training=True, method='cpc'):\n",
    "        self.batch_size = batch_size\n",
    "        self.terms = terms\n",
    "        self.predict_terms = predict_terms\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        self.rescale = rescale\n",
    "        self.aug = aug\n",
    "        self.is_training = is_training\n",
    "        self.method = method\n",
    "        self.lena = cv2.imread(os.path.join(base_dir,'lena.jpg'))\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "        if self.is_training:\n",
    "            self.x = x_train/255.0\n",
    "            self.y = y_train\n",
    "        else:\n",
    "            self.x = x_test/255.0\n",
    "            self.y = y_test\n",
    "        self.idxs = []\n",
    "        for i in range(10):\n",
    "            y = y_train if self.is_training else y_test\n",
    "            self.idxs.append(np.where(y == i)[0])\n",
    "        self.n_samples = len(self.y)//terms if self.method == 'cpc' else len(self.y)\n",
    "        self.shape = self.x.shape\n",
    "        self.n_batches = self.n_samples//batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.cpc_batch() if self.method == 'cpc' else self.benchmark_batch()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def cpc_batch(self):\n",
    "        img_labels = np.zeros((self.batch_size, self.terms + self.predict_terms))\n",
    "        sentence_labels = np.ones((self.batch_size, 1)).astype('int32')\n",
    "        for bi in range(self.batch_size):\n",
    "            seed = np.random.randint(10)\n",
    "            sentence = np.arange(seed, seed + self.terms + self.predict_terms) % 10\n",
    "            if bi < self.batch_size//2:\n",
    "                num = np.arange(10)\n",
    "                predicted = sentence[-self.predict_terms:]\n",
    "                for i, p in enumerate(predicted):\n",
    "                    predicted[i] = np.random.choice(num[num != p], 1)\n",
    "                sentence[-self.predict_terms:] = predicted % 10\n",
    "                sentence_labels[bi, :] = 0\n",
    "            img_labels[bi, :] = sentence\n",
    "        images = self.get_samples(img_labels).reshape((self.batch_size, self.terms+self.predict_terms, self.image_size, self.image_size, 3))\n",
    "        x_images = images[:, :-self.predict_terms, ...]\n",
    "        y_images = images[:, -self.predict_terms:, ...]\n",
    "        idx = np.random.choice(self.batch_size, self.batch_size, replace=False)\n",
    "        return [x_images[idx], y_images[idx]], sentence_labels[idx]\n",
    "\n",
    "    def get_samples(self, img_labels):\n",
    "        idx = []\n",
    "        for label in img_labels.flatten():\n",
    "            idx.append(np.random.choice(self.idxs[int(label)], 1)[0])\n",
    "        img_batch = self.x[idx, :, :]\n",
    "        if self.aug:\n",
    "            img_batch = self._aug_batch(img_batch)\n",
    "        return img_batch\n",
    "\n",
    "    def _aug_batch(self, img_batch):\n",
    "        if self.image_size != 28:\n",
    "            resized = []\n",
    "            for i in range(img_batch.shape[0]):\n",
    "                resized.append(cv2.resize(img_batch[i], (self.image_size, self.image_size)))\n",
    "            img_batch = np.stack(resized)\n",
    "        img_batch = img_batch.reshape((img_batch.shape[0], 1, self.image_size, self.image_size))\n",
    "        img_batch = np.concatenate([img_batch, img_batch, img_batch], axis=1)\n",
    "\n",
    "        if self.color:\n",
    "            img_batch[img_batch >= 0.5] = 1\n",
    "            img_batch[img_batch < 0.5] = 0\n",
    "            for i in range(img_batch.shape[0]):\n",
    "                x_c = np.random.randint(0, self.lena.shape[0] - self.image_size)\n",
    "                y_c = np.random.randint(0, self.lena.shape[1] - self.image_size)\n",
    "                img = self.lena[x_c:x_c+self.image_size, y_c:y_c+self.image_size]\n",
    "                img = np.array(img).transpose((2, 0, 1))/255.0\n",
    "                for j in range(3):\n",
    "                    img[j, :, :] = (img[j, :, :] + np.random.uniform(0, 1))/2.0\n",
    "                img[img_batch[i, :, :, :] == 1] = 1 - img[img_batch[i, :, :, :] == 1]\n",
    "                img_batch[i, :, :, :] = img\n",
    "\n",
    "        if self.rescale:\n",
    "            img_batch = img_batch * 2 - 1\n",
    "        img_batch = img_batch.transpose((0, 2, 3, 1))\n",
    "        return img_batch\n",
    "\n",
    "    def benchmark_batch(self):\n",
    "        idx = np.random.choice(len(self.x), self.batch_size, replace=False)\n",
    "        img_batch = self.x[idx]\n",
    "        label_batch = self.y[idx]\n",
    "        if self.aug:\n",
    "            img_batch = self._aug_batch(img_batch)\n",
    "        label_batch = label_batch.reshape((-1, 1))\n",
    "        return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TbyX3qlk1b4g",
    "outputId": "5ee8316c-0a96-4277-b003-e9937032d726"
   },
   "outputs": [],
   "source": [
    "# #train loop\n",
    "# dh_train = DataHandler(64, 4, predict_terms=4, image_size=64, color=True, rescale=True, aug=True, is_training=True, method='cpc')\n",
    "# dh_test = DataHandler(64, 4, predict_terms=4, image_size=64, color=True, rescale=True, aug=True, is_training=False, method='cpc')\n",
    "# accuracy_metric_train = tf.keras.metrics.BinaryAccuracy()\n",
    "# loss_metric_train = tf.keras.metrics.BinaryCrossentropy()\n",
    "# accuracy_metric_test = tf.keras.metrics.BinaryAccuracy()\n",
    "# loss_metric_test = tf.keras.metrics.BinaryCrossentropy()\n",
    "# cpc = CPCModel(code_size=128, predict_terms=4, terms=4, units=256, image_size=64, channels=3)\n",
    "# optim = tf.keras.optimizers.Adam(1e-3)\n",
    "# cb = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=1/3, patience=2, min_lr=1e-4),\n",
    "#       tf.keras.callbacks.ModelCheckpoint('weights/weights.{epoch:02d}-{val_binary_accuracy:.2f}.cpkt',\n",
    "#                                           monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True),\n",
    "#       tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3),\n",
    "#       tf.keras.callbacks.TensorBoard()]\n",
    "# cpc.compile(optimizer=optim, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "# cpc.fit(x=dh_train, epochs=10, validation_data=dh_test, steps_per_epoch=60000//64, validation_steps=10000//64, callbacks=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vn5Hapce1cE5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtara\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# train loop params\n",
    "\n",
    "\n",
    "episodes = 200\n",
    "episode_steps = 1000\n",
    "buffer_size = 10000\n",
    "batch_size = 16\n",
    "\n",
    "# pybullet setup\n",
    "env = gym.make('HalfCheetahBulletEnv-v0')\n",
    "env.render(mode = 'human')\n",
    "env._max_episode_steps = episode_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 6\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "writer_reward = tf.summary.create_file_writer(reward_dir)\n",
    "\n",
    "#get spaces\n",
    "state_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.shape[0]\n",
    "print(state_space,action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0eguufNR5p4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sim test:  10000 : 10000\n",
      "step:  9999\n",
      "done seeding replay buffer\n",
      "t:  0  :episode:  0\n",
      "q_loss:  [1.6673005]\n",
      "t:  1  :episode:  0\n",
      "q_loss:  [0.99453485]\n",
      "t:  2  :episode:  0\n",
      "q_loss:  [0.3904292]\n",
      "t:  3  :episode:  0\n",
      "q_loss:  [1.1167037]\n",
      "t:  4  :episode:  0\n",
      "q_loss:  [0.7583326]\n",
      "t:  5  :episode:  0\n",
      "q_loss:  [0.56657004]\n",
      "t:  6  :episode:  0\n",
      "q_loss:  [0.11957851]\n",
      "t:  7  :episode:  0\n",
      "q_loss:  [0.73382115]\n",
      "t:  8  :episode:  0\n",
      "q_loss:  [0.37331802]\n",
      "t:  9  :episode:  0\n",
      "q_loss:  [0.44329017]\n",
      "t:  10  :episode:  0\n",
      "q_loss:  [0.22944075]\n",
      "t:  11  :episode:  0\n",
      "q_loss:  [0.4245382]\n",
      "t:  12  :episode:  0\n",
      "q_loss:  [0.5026316]\n",
      "t:  13  :episode:  0\n",
      "q_loss:  [0.2762586]\n",
      "t:  14  :episode:  0\n",
      "q_loss:  [0.6947439]\n",
      "t:  15  :episode:  0\n",
      "q_loss:  [0.24559486]\n",
      "t:  16  :episode:  0\n",
      "q_loss:  [0.45345622]\n",
      "t:  17  :episode:  0\n",
      "q_loss:  [0.55860496]\n",
      "t:  18  :episode:  0\n",
      "q_loss:  [0.4149734]\n",
      "t:  19  :episode:  0\n",
      "q_loss:  [0.36037403]\n",
      "t:  20  :episode:  0\n",
      "q_loss:  [0.43833846]\n",
      "t:  21  :episode:  0\n",
      "q_loss:  [0.32847083]\n",
      "t:  22  :episode:  0\n",
      "q_loss:  [0.17062643]\n",
      "t:  23  :episode:  0\n",
      "q_loss:  [0.17539468]\n",
      "t:  24  :episode:  0\n",
      "q_loss:  [0.5192301]\n",
      "t:  25  :episode:  0\n",
      "q_loss:  [0.63144803]\n",
      "t:  26  :episode:  0\n",
      "q_loss:  [0.8026908]\n",
      "t:  27  :episode:  0\n",
      "q_loss:  [0.28201935]\n",
      "t:  28  :episode:  0\n",
      "q_loss:  [0.47900543]\n",
      "t:  29  :episode:  0\n",
      "q_loss:  [0.3890571]\n",
      "t:  30  :episode:  0\n",
      "q_loss:  [0.4148842]\n",
      "t:  31  :episode:  0\n",
      "q_loss:  [0.34446317]\n",
      "t:  32  :episode:  0\n",
      "q_loss:  [0.83118254]\n",
      "t:  33  :episode:  0\n",
      "q_loss:  [0.38280475]\n",
      "t:  34  :episode:  0\n",
      "q_loss:  [0.29720104]\n",
      "t:  35  :episode:  0\n",
      "q_loss:  [0.24047293]\n",
      "t:  36  :episode:  0\n",
      "q_loss:  [0.44293004]\n",
      "t:  37  :episode:  0\n",
      "q_loss:  [0.5738988]\n",
      "t:  38  :episode:  0\n",
      "q_loss:  [0.3433376]\n",
      "t:  39  :episode:  0\n",
      "q_loss:  [0.25095508]\n",
      "t:  40  :episode:  0\n",
      "q_loss:  [0.3909895]\n",
      "t:  41  :episode:  0\n",
      "q_loss:  [0.12585399]\n",
      "t:  42  :episode:  0\n",
      "q_loss:  [0.53314006]\n",
      "t:  43  :episode:  0\n",
      "q_loss:  [0.41366518]\n",
      "t:  44  :episode:  0\n",
      "q_loss:  [0.30916232]\n",
      "t:  45  :episode:  0\n",
      "q_loss:  [0.38416815]\n",
      "t:  46  :episode:  0\n",
      "q_loss:  [0.31292433]\n",
      "t:  47  :episode:  0\n",
      "q_loss:  [0.31622583]\n",
      "t:  48  :episode:  0\n",
      "q_loss:  [0.60442984]\n",
      "t:  49  :episode:  0\n",
      "q_loss:  [0.25620872]\n",
      "t:  50  :episode:  0\n",
      "q_loss:  [0.5955397]\n",
      "t:  51  :episode:  0\n",
      "q_loss:  [0.621004]\n",
      "t:  52  :episode:  0\n",
      "q_loss:  [0.15662962]\n",
      "t:  53  :episode:  0\n",
      "q_loss:  [0.25429046]\n",
      "t:  54  :episode:  0\n",
      "q_loss:  [0.19884112]\n",
      "t:  55  :episode:  0\n",
      "q_loss:  [0.5504122]\n",
      "t:  56  :episode:  0\n",
      "q_loss:  [0.36771291]\n",
      "t:  57  :episode:  0\n",
      "q_loss:  [0.5524987]\n",
      "t:  58  :episode:  0\n",
      "q_loss:  [0.87158614]\n",
      "t:  59  :episode:  0\n",
      "q_loss:  [0.31019506]\n",
      "t:  60  :episode:  0\n",
      "q_loss:  [0.31052157]\n",
      "t:  61  :episode:  0\n",
      "q_loss:  [0.0698276]\n",
      "t:  62  :episode:  0\n",
      "q_loss:  [0.35328555]\n",
      "t:  63  :episode:  0\n",
      "q_loss:  [0.38708603]\n",
      "t:  64  :episode:  0\n",
      "q_loss:  [0.510057]\n",
      "t:  65  :episode:  0\n",
      "q_loss:  [0.2788782]\n",
      "t:  66  :episode:  0\n",
      "q_loss:  [0.7984441]\n",
      "t:  67  :episode:  0\n",
      "q_loss:  [0.1348376]\n",
      "t:  68  :episode:  0\n",
      "q_loss:  [0.43857488]\n",
      "t:  69  :episode:  0\n",
      "q_loss:  [0.33264345]\n",
      "t:  70  :episode:  0\n",
      "q_loss:  [0.21385136]\n",
      "t:  71  :episode:  0\n",
      "q_loss:  [0.25103778]\n",
      "t:  72  :episode:  0\n",
      "q_loss:  [0.4960551]\n",
      "t:  73  :episode:  0\n",
      "q_loss:  [0.78182864]\n",
      "t:  74  :episode:  0\n",
      "q_loss:  [0.6756113]\n",
      "t:  75  :episode:  0\n",
      "q_loss:  [0.41616547]\n",
      "t:  76  :episode:  0\n",
      "q_loss:  [0.5752255]\n",
      "t:  77  :episode:  0\n",
      "q_loss:  [0.3332312]\n",
      "t:  78  :episode:  0\n",
      "q_loss:  [0.4989586]\n",
      "t:  79  :episode:  0\n",
      "q_loss:  [0.4345694]\n",
      "t:  80  :episode:  0\n",
      "q_loss:  [0.44711548]\n",
      "t:  81  :episode:  0\n",
      "q_loss:  [0.7337501]\n",
      "t:  82  :episode:  0\n",
      "q_loss:  [0.24281523]\n",
      "t:  83  :episode:  0\n",
      "q_loss:  [0.29131573]\n",
      "t:  84  :episode:  0\n",
      "q_loss:  [0.35088706]\n",
      "t:  85  :episode:  0\n",
      "q_loss:  [0.12059922]\n",
      "t:  86  :episode:  0\n",
      "q_loss:  [0.27327397]\n",
      "t:  87  :episode:  0\n",
      "q_loss:  [0.50877833]\n",
      "t:  88  :episode:  0\n",
      "q_loss:  [0.33635083]\n",
      "t:  89  :episode:  0\n",
      "q_loss:  [0.70639557]\n",
      "t:  90  :episode:  0\n",
      "q_loss:  [0.2836486]\n",
      "t:  91  :episode:  0\n",
      "q_loss:  [0.30607006]\n",
      "t:  92  :episode:  0\n",
      "q_loss:  [0.38851205]\n",
      "t:  93  :episode:  0\n",
      "q_loss:  [0.24074501]\n",
      "t:  94  :episode:  0\n",
      "q_loss:  [0.12178638]\n",
      "t:  95  :episode:  0\n",
      "q_loss:  [0.4540251]\n",
      "t:  96  :episode:  0\n",
      "q_loss:  [0.5886417]\n",
      "t:  97  :episode:  0\n",
      "q_loss:  [0.28559273]\n",
      "t:  98  :episode:  0\n",
      "q_loss:  [0.37033352]\n",
      "t:  99  :episode:  0\n",
      "q_loss:  [0.56510293]\n",
      "t:  100  :episode:  0\n",
      "q_loss:  [0.20423293]\n",
      "t:  101  :episode:  0\n",
      "q_loss:  [0.84782326]\n",
      "t:  102  :episode:  0\n",
      "q_loss:  [0.45755753]\n",
      "t:  103  :episode:  0\n",
      "q_loss:  [0.27647287]\n",
      "t:  104  :episode:  0\n",
      "q_loss:  [0.25036284]\n",
      "t:  105  :episode:  0\n",
      "q_loss:  [0.45587552]\n",
      "t:  106  :episode:  0\n",
      "q_loss:  [0.4341639]\n",
      "t:  107  :episode:  0\n",
      "q_loss:  [0.48623413]\n",
      "t:  108  :episode:  0\n",
      "q_loss:  [0.12231707]\n",
      "t:  109  :episode:  0\n",
      "q_loss:  [0.1947502]\n",
      "t:  110  :episode:  0\n",
      "q_loss:  [0.46410453]\n",
      "t:  111  :episode:  0\n",
      "q_loss:  [0.64362764]\n",
      "t:  112  :episode:  0\n",
      "q_loss:  [0.24365506]\n",
      "t:  113  :episode:  0\n",
      "q_loss:  [0.30884296]\n",
      "t:  114  :episode:  0\n",
      "q_loss:  [0.4857877]\n",
      "t:  115  :episode:  0\n",
      "q_loss:  [0.2788614]\n",
      "t:  116  :episode:  0\n",
      "q_loss:  [0.75117135]\n",
      "t:  117  :episode:  0\n",
      "q_loss:  [0.22809893]\n",
      "t:  118  :episode:  0\n",
      "q_loss:  [0.4738309]\n",
      "t:  119  :episode:  0\n",
      "q_loss:  [0.09598796]\n",
      "t:  120  :episode:  0\n",
      "q_loss:  [0.4098553]\n",
      "t:  121  :episode:  0\n",
      "q_loss:  [0.25271347]\n",
      "t:  122  :episode:  0\n",
      "q_loss:  [0.4036239]\n",
      "t:  123  :episode:  0\n",
      "q_loss:  [0.6438889]\n",
      "t:  124  :episode:  0\n",
      "q_loss:  [0.5296647]\n",
      "t:  125  :episode:  0\n",
      "q_loss:  [0.23613961]\n",
      "t:  126  :episode:  0\n",
      "q_loss:  [0.24697205]\n",
      "t:  127  :episode:  0\n",
      "q_loss:  [0.2748797]\n",
      "t:  128  :episode:  0\n",
      "q_loss:  [0.27533782]\n",
      "t:  129  :episode:  0\n",
      "q_loss:  [0.31625962]\n",
      "t:  130  :episode:  0\n",
      "q_loss:  [0.49301106]\n",
      "t:  131  :episode:  0\n",
      "q_loss:  [0.3700348]\n",
      "t:  132  :episode:  0\n",
      "q_loss:  [0.55596423]\n",
      "t:  133  :episode:  0\n",
      "q_loss:  [0.52512974]\n",
      "t:  134  :episode:  0\n",
      "q_loss:  [0.26266348]\n",
      "t:  135  :episode:  0\n",
      "q_loss:  [0.60200405]\n",
      "t:  136  :episode:  0\n",
      "q_loss:  [0.23643269]\n",
      "t:  137  :episode:  0\n",
      "q_loss:  [0.7092533]\n",
      "t:  138  :episode:  0\n",
      "q_loss:  [0.29739684]\n",
      "t:  139  :episode:  0\n",
      "q_loss:  [0.3935048]\n",
      "t:  140  :episode:  0\n",
      "q_loss:  [0.7601118]\n",
      "t:  141  :episode:  0\n",
      "q_loss:  [0.5778273]\n",
      "t:  142  :episode:  0\n",
      "q_loss:  [0.40841874]\n",
      "t:  143  :episode:  0\n",
      "q_loss:  [0.26102215]\n",
      "t:  144  :episode:  0\n",
      "q_loss:  [0.31086063]\n",
      "t:  145  :episode:  0\n",
      "q_loss:  [0.2817976]\n",
      "t:  146  :episode:  0\n",
      "q_loss:  [0.15421315]\n",
      "t:  147  :episode:  0\n",
      "q_loss:  [0.31818572]\n",
      "t:  148  :episode:  0\n",
      "q_loss:  [0.17762499]\n",
      "t:  149  :episode:  0\n",
      "q_loss:  [0.25180948]\n",
      "t:  150  :episode:  0\n",
      "q_loss:  [0.4861812]\n",
      "t:  151  :episode:  0\n",
      "q_loss:  [0.4204639]\n",
      "t:  152  :episode:  0\n",
      "q_loss:  [0.24186414]\n",
      "t:  153  :episode:  0\n",
      "q_loss:  [0.43902463]\n",
      "t:  154  :episode:  0\n",
      "q_loss:  [0.39662167]\n",
      "t:  155  :episode:  0\n",
      "q_loss:  [0.16504166]\n",
      "t:  156  :episode:  0\n",
      "q_loss:  [0.5763096]\n",
      "t:  157  :episode:  0\n",
      "q_loss:  [0.301378]\n",
      "t:  158  :episode:  0\n",
      "q_loss:  [0.30489403]\n",
      "t:  159  :episode:  0\n",
      "q_loss:  [0.21564847]\n",
      "t:  160  :episode:  0\n",
      "q_loss:  [0.47565687]\n",
      "t:  161  :episode:  0\n",
      "q_loss:  [0.41858625]\n",
      "t:  162  :episode:  0\n",
      "q_loss:  [0.41349494]\n",
      "t:  163  :episode:  0\n",
      "q_loss:  [0.4145803]\n",
      "t:  164  :episode:  0\n",
      "q_loss:  [0.44661534]\n",
      "t:  165  :episode:  0\n",
      "q_loss:  [0.13661961]\n",
      "t:  166  :episode:  0\n",
      "q_loss:  [0.13747239]\n",
      "t:  167  :episode:  0\n",
      "q_loss:  [0.1552697]\n",
      "t:  168  :episode:  0\n",
      "q_loss:  [0.58023727]\n",
      "t:  169  :episode:  0\n",
      "q_loss:  [0.14433694]\n",
      "t:  170  :episode:  0\n",
      "q_loss:  [0.7366819]\n",
      "t:  171  :episode:  0\n",
      "q_loss:  [0.2855977]\n",
      "t:  172  :episode:  0\n",
      "q_loss:  [0.46933258]\n",
      "t:  173  :episode:  0\n",
      "q_loss:  [0.14115435]\n",
      "t:  174  :episode:  0\n",
      "q_loss:  [0.22517347]\n",
      "t:  175  :episode:  0\n",
      "q_loss:  [0.22294724]\n",
      "t:  176  :episode:  0\n",
      "q_loss:  [0.7037147]\n",
      "t:  177  :episode:  0\n",
      "q_loss:  [0.6047567]\n",
      "t:  178  :episode:  0\n",
      "q_loss:  [0.14629808]\n",
      "t:  179  :episode:  0\n",
      "q_loss:  [0.42531693]\n",
      "t:  180  :episode:  0\n",
      "q_loss:  [0.42953855]\n",
      "t:  181  :episode:  0\n",
      "q_loss:  [0.73025656]\n",
      "t:  182  :episode:  0\n",
      "q_loss:  [0.465309]\n",
      "t:  183  :episode:  0\n",
      "q_loss:  [0.40437657]\n",
      "t:  184  :episode:  0\n",
      "q_loss:  [0.32571647]\n",
      "t:  185  :episode:  0\n",
      "q_loss:  [0.32928115]\n",
      "t:  186  :episode:  0\n",
      "q_loss:  [0.43726897]\n",
      "t:  187  :episode:  0\n",
      "q_loss:  [0.33395088]\n",
      "t:  188  :episode:  0\n",
      "q_loss:  [0.5111293]\n",
      "t:  189  :episode:  0\n",
      "q_loss:  [0.35927272]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  190  :episode:  0\n",
      "q_loss:  [0.10827016]\n",
      "t:  191  :episode:  0\n",
      "q_loss:  [0.4491059]\n",
      "t:  192  :episode:  0\n",
      "q_loss:  [0.21075132]\n",
      "t:  193  :episode:  0\n",
      "q_loss:  [0.27546114]\n",
      "t:  194  :episode:  0\n",
      "q_loss:  [0.33728853]\n",
      "t:  195  :episode:  0\n",
      "q_loss:  [0.5383558]\n",
      "t:  196  :episode:  0\n",
      "q_loss:  [0.44953692]\n",
      "t:  197  :episode:  0\n",
      "q_loss:  [0.43449247]\n",
      "t:  198  :episode:  0\n",
      "q_loss:  [0.2692543]\n",
      "t:  199  :episode:  0\n",
      "q_loss:  [0.38534868]\n",
      "t:  200  :episode:  0\n",
      "q_loss:  [0.38211733]\n",
      "t:  201  :episode:  0\n",
      "q_loss:  [0.25014293]\n",
      "t:  202  :episode:  0\n",
      "q_loss:  [0.14787029]\n",
      "t:  203  :episode:  0\n",
      "q_loss:  [0.25517994]\n",
      "t:  204  :episode:  0\n",
      "q_loss:  [0.36086458]\n",
      "t:  205  :episode:  0\n",
      "q_loss:  [0.31397307]\n",
      "t:  206  :episode:  0\n",
      "q_loss:  [0.67410994]\n",
      "t:  207  :episode:  0\n",
      "q_loss:  [0.21997803]\n",
      "t:  208  :episode:  0\n",
      "q_loss:  [0.573527]\n",
      "t:  209  :episode:  0\n",
      "q_loss:  [0.15335113]\n",
      "t:  210  :episode:  0\n",
      "q_loss:  [0.32916573]\n",
      "t:  211  :episode:  0\n",
      "q_loss:  [0.11907011]\n",
      "t:  212  :episode:  0\n",
      "q_loss:  [0.5502083]\n",
      "t:  213  :episode:  0\n",
      "q_loss:  [0.46881133]\n",
      "t:  214  :episode:  0\n",
      "q_loss:  [0.5185087]\n",
      "t:  215  :episode:  0\n",
      "q_loss:  [0.2979815]\n",
      "t:  216  :episode:  0\n",
      "q_loss:  [0.40807968]\n",
      "t:  217  :episode:  0\n",
      "q_loss:  [0.66028905]\n",
      "t:  218  :episode:  0\n",
      "q_loss:  [0.182444]\n",
      "t:  219  :episode:  0\n",
      "q_loss:  [0.4364577]\n",
      "t:  220  :episode:  0\n",
      "q_loss:  [0.22734003]\n",
      "t:  221  :episode:  0\n",
      "q_loss:  [0.43284264]\n",
      "t:  222  :episode:  0\n",
      "q_loss:  [0.45245922]\n",
      "t:  223  :episode:  0\n",
      "q_loss:  [0.6273756]\n",
      "t:  224  :episode:  0\n",
      "q_loss:  [0.186521]\n",
      "t:  225  :episode:  0\n",
      "q_loss:  [0.4487061]\n",
      "t:  226  :episode:  0\n",
      "q_loss:  [0.1712151]\n",
      "t:  227  :episode:  0\n",
      "q_loss:  [0.23157595]\n",
      "t:  228  :episode:  0\n",
      "q_loss:  [0.45592308]\n",
      "t:  229  :episode:  0\n",
      "q_loss:  [0.45620152]\n",
      "t:  230  :episode:  0\n",
      "q_loss:  [0.21434808]\n",
      "t:  231  :episode:  0\n",
      "q_loss:  [0.6538172]\n",
      "t:  232  :episode:  0\n",
      "q_loss:  [0.49872532]\n",
      "t:  233  :episode:  0\n",
      "q_loss:  [0.34654883]\n",
      "t:  234  :episode:  0\n",
      "q_loss:  [0.29956913]\n",
      "t:  235  :episode:  0\n",
      "q_loss:  [0.84872055]\n",
      "t:  236  :episode:  0\n",
      "q_loss:  [0.27053896]\n",
      "t:  237  :episode:  0\n",
      "q_loss:  [0.3702219]\n",
      "t:  238  :episode:  0\n",
      "q_loss:  [0.37003303]\n",
      "t:  239  :episode:  0\n",
      "q_loss:  [0.23657402]\n",
      "t:  240  :episode:  0\n",
      "q_loss:  [0.54272366]\n",
      "t:  241  :episode:  0\n",
      "q_loss:  [0.4710896]\n",
      "t:  242  :episode:  0\n",
      "q_loss:  [0.61835194]\n",
      "t:  243  :episode:  0\n",
      "q_loss:  [0.40338305]\n",
      "t:  244  :episode:  0\n",
      "q_loss:  [0.19653651]\n",
      "t:  245  :episode:  0\n",
      "q_loss:  [0.45252714]\n",
      "t:  246  :episode:  0\n",
      "q_loss:  [0.46354073]\n",
      "t:  247  :episode:  0\n",
      "q_loss:  [0.23560634]\n",
      "t:  248  :episode:  0\n",
      "q_loss:  [0.74783576]\n",
      "t:  249  :episode:  0\n",
      "q_loss:  [0.23131251]\n",
      "t:  250  :episode:  0\n",
      "q_loss:  [0.5718148]\n",
      "t:  251  :episode:  0\n",
      "q_loss:  [0.36273897]\n",
      "t:  252  :episode:  0\n",
      "q_loss:  [0.14125931]\n",
      "t:  253  :episode:  0\n",
      "q_loss:  [0.5544639]\n",
      "t:  254  :episode:  0\n",
      "q_loss:  [0.26346326]\n",
      "t:  255  :episode:  0\n",
      "q_loss:  [0.2879808]\n",
      "t:  256  :episode:  0\n",
      "q_loss:  [0.22632907]\n",
      "t:  257  :episode:  0\n",
      "q_loss:  [0.37065545]\n",
      "t:  258  :episode:  0\n",
      "q_loss:  [0.22612366]\n",
      "t:  259  :episode:  0\n",
      "q_loss:  [0.46367064]\n",
      "t:  260  :episode:  0\n",
      "q_loss:  [0.32505277]\n",
      "t:  261  :episode:  0\n",
      "q_loss:  [0.31583315]\n",
      "t:  262  :episode:  0\n",
      "q_loss:  [0.2810934]\n",
      "t:  263  :episode:  0\n",
      "q_loss:  [0.3171621]\n",
      "t:  264  :episode:  0\n",
      "q_loss:  [0.6044713]\n",
      "t:  265  :episode:  0\n",
      "q_loss:  [0.5467457]\n",
      "t:  266  :episode:  0\n",
      "q_loss:  [0.38717508]\n",
      "t:  267  :episode:  0\n",
      "q_loss:  [0.32628414]\n",
      "t:  268  :episode:  0\n",
      "q_loss:  [0.07262909]\n",
      "t:  269  :episode:  0\n",
      "q_loss:  [0.07894345]\n",
      "t:  270  :episode:  0\n",
      "q_loss:  [0.34696203]\n",
      "t:  271  :episode:  0\n",
      "q_loss:  [0.24788775]\n",
      "t:  272  :episode:  0\n",
      "q_loss:  [0.32001546]\n",
      "t:  273  :episode:  0\n",
      "q_loss:  [0.21730807]\n",
      "t:  274  :episode:  0\n",
      "q_loss:  [0.2258941]\n",
      "t:  275  :episode:  0\n",
      "q_loss:  [0.05745181]\n",
      "t:  276  :episode:  0\n",
      "q_loss:  [0.16647229]\n",
      "t:  277  :episode:  0\n",
      "q_loss:  [0.260626]\n",
      "t:  278  :episode:  0\n",
      "q_loss:  [0.2434946]\n",
      "t:  279  :episode:  0\n",
      "q_loss:  [0.28130215]\n",
      "t:  280  :episode:  0\n",
      "q_loss:  [0.09022295]\n",
      "t:  281  :episode:  0\n",
      "q_loss:  [0.08895604]\n",
      "t:  282  :episode:  0\n",
      "q_loss:  [0.31057104]\n",
      "t:  283  :episode:  0\n",
      "q_loss:  [0.13252228]\n",
      "t:  284  :episode:  0\n",
      "q_loss:  [0.28892928]\n",
      "t:  285  :episode:  0\n",
      "q_loss:  [0.20327975]\n",
      "t:  286  :episode:  0\n",
      "q_loss:  [0.3108564]\n",
      "t:  287  :episode:  0\n",
      "q_loss:  [0.6004091]\n",
      "t:  288  :episode:  0\n",
      "q_loss:  [0.21539919]\n",
      "t:  289  :episode:  0\n",
      "q_loss:  [0.0474689]\n",
      "t:  290  :episode:  0\n",
      "q_loss:  [0.32396844]\n",
      "t:  291  :episode:  0\n",
      "q_loss:  [0.2680871]\n",
      "t:  292  :episode:  0\n",
      "q_loss:  [0.2329661]\n",
      "t:  293  :episode:  0\n",
      "q_loss:  [0.27016625]\n",
      "t:  294  :episode:  0\n",
      "q_loss:  [0.3441918]\n",
      "t:  295  :episode:  0\n",
      "q_loss:  [0.42649373]\n",
      "t:  296  :episode:  0\n",
      "q_loss:  [0.10772644]\n",
      "t:  297  :episode:  0\n",
      "q_loss:  [0.52705526]\n",
      "t:  298  :episode:  0\n",
      "q_loss:  [0.20856418]\n",
      "t:  299  :episode:  0\n",
      "q_loss:  [0.5848781]\n",
      "t:  300  :episode:  0\n",
      "q_loss:  [0.30233777]\n",
      "t:  301  :episode:  0\n",
      "q_loss:  [0.11158958]\n",
      "t:  302  :episode:  0\n",
      "q_loss:  [0.5120077]\n",
      "t:  303  :episode:  0\n",
      "q_loss:  [0.16921078]\n",
      "t:  304  :episode:  0\n",
      "q_loss:  [0.8328502]\n",
      "t:  305  :episode:  0\n",
      "q_loss:  [0.04851385]\n",
      "t:  306  :episode:  0\n",
      "q_loss:  [0.27759352]\n",
      "t:  307  :episode:  0\n",
      "q_loss:  [0.24503657]\n",
      "t:  308  :episode:  0\n",
      "q_loss:  [0.03922615]\n",
      "t:  309  :episode:  0\n",
      "q_loss:  [0.33369267]\n",
      "t:  310  :episode:  0\n",
      "q_loss:  [0.16471712]\n",
      "t:  311  :episode:  0\n",
      "q_loss:  [0.1141349]\n",
      "t:  312  :episode:  0\n",
      "q_loss:  [0.38661253]\n",
      "t:  313  :episode:  0\n",
      "q_loss:  [0.28143424]\n",
      "t:  314  :episode:  0\n",
      "q_loss:  [0.30347002]\n",
      "t:  315  :episode:  0\n",
      "q_loss:  [0.30785853]\n",
      "t:  316  :episode:  0\n",
      "q_loss:  [0.2409798]\n",
      "t:  317  :episode:  0\n",
      "q_loss:  [0.15320298]\n",
      "t:  318  :episode:  0\n",
      "q_loss:  [0.4227957]\n",
      "t:  319  :episode:  0\n",
      "q_loss:  [0.4151262]\n",
      "t:  320  :episode:  0\n",
      "q_loss:  [0.3097644]\n",
      "t:  321  :episode:  0\n",
      "q_loss:  [0.6946952]\n",
      "t:  322  :episode:  0\n",
      "q_loss:  [0.30404776]\n",
      "t:  323  :episode:  0\n",
      "q_loss:  [0.16249949]\n",
      "t:  324  :episode:  0\n",
      "q_loss:  [0.2452446]\n",
      "t:  325  :episode:  0\n",
      "q_loss:  [0.23431684]\n",
      "t:  326  :episode:  0\n",
      "q_loss:  [0.5706928]\n",
      "t:  327  :episode:  0\n",
      "q_loss:  [0.1840454]\n",
      "t:  328  :episode:  0\n",
      "q_loss:  [0.11136618]\n",
      "t:  329  :episode:  0\n",
      "q_loss:  [0.25722656]\n",
      "t:  330  :episode:  0\n",
      "q_loss:  [0.31255436]\n",
      "t:  331  :episode:  0\n",
      "q_loss:  [0.6874471]\n",
      "t:  332  :episode:  0\n",
      "q_loss:  [0.29942667]\n",
      "t:  333  :episode:  0\n",
      "q_loss:  [0.352274]\n",
      "t:  334  :episode:  0\n",
      "q_loss:  [0.20730056]\n",
      "t:  335  :episode:  0\n",
      "q_loss:  [0.12941025]\n",
      "t:  336  :episode:  0\n",
      "q_loss:  [0.13103558]\n",
      "t:  337  :episode:  0\n",
      "q_loss:  [0.18420279]\n",
      "t:  338  :episode:  0\n",
      "q_loss:  [0.33315247]\n",
      "t:  339  :episode:  0\n",
      "q_loss:  [0.6534463]\n",
      "t:  340  :episode:  0\n",
      "q_loss:  [0.20536692]\n",
      "t:  341  :episode:  0\n",
      "q_loss:  [0.13616373]\n",
      "t:  342  :episode:  0\n",
      "q_loss:  [0.66375583]\n",
      "t:  343  :episode:  0\n",
      "q_loss:  [0.33845413]\n",
      "t:  344  :episode:  0\n",
      "q_loss:  [0.62781215]\n",
      "t:  345  :episode:  0\n",
      "q_loss:  [0.58834404]\n",
      "t:  346  :episode:  0\n",
      "q_loss:  [0.49196613]\n",
      "t:  347  :episode:  0\n",
      "q_loss:  [0.6608664]\n",
      "t:  348  :episode:  0\n",
      "q_loss:  [0.14922346]\n",
      "t:  349  :episode:  0\n",
      "q_loss:  [0.24825054]\n",
      "t:  350  :episode:  0\n",
      "q_loss:  [0.2812528]\n",
      "t:  351  :episode:  0\n",
      "q_loss:  [0.3463583]\n",
      "t:  352  :episode:  0\n",
      "q_loss:  [0.9201211]\n",
      "t:  353  :episode:  0\n",
      "q_loss:  [0.95678234]\n",
      "t:  354  :episode:  0\n",
      "q_loss:  [0.3188253]\n",
      "t:  355  :episode:  0\n",
      "q_loss:  [0.19095035]\n",
      "t:  356  :episode:  0\n",
      "q_loss:  [0.2720777]\n",
      "t:  357  :episode:  0\n",
      "q_loss:  [0.10333405]\n",
      "t:  358  :episode:  0\n",
      "q_loss:  [0.29257554]\n",
      "t:  359  :episode:  0\n",
      "q_loss:  [0.09813723]\n",
      "t:  360  :episode:  0\n",
      "q_loss:  [0.11957176]\n",
      "t:  361  :episode:  0\n",
      "q_loss:  [0.47876704]\n",
      "t:  362  :episode:  0\n",
      "q_loss:  [0.2445163]\n",
      "t:  363  :episode:  0\n",
      "q_loss:  [0.22572358]\n",
      "t:  364  :episode:  0\n",
      "q_loss:  [0.22874714]\n",
      "t:  365  :episode:  0\n",
      "q_loss:  [0.39923102]\n",
      "t:  366  :episode:  0\n",
      "q_loss:  [0.2243606]\n",
      "t:  367  :episode:  0\n",
      "q_loss:  [0.29515713]\n",
      "t:  368  :episode:  0\n",
      "q_loss:  [0.21621537]\n",
      "t:  369  :episode:  0\n",
      "q_loss:  [0.2557918]\n",
      "t:  370  :episode:  0\n",
      "q_loss:  [0.15696052]\n",
      "t:  371  :episode:  0\n",
      "q_loss:  [0.1543568]\n",
      "t:  372  :episode:  0\n",
      "q_loss:  [0.34574687]\n",
      "t:  373  :episode:  0\n",
      "q_loss:  [0.11513858]\n",
      "t:  374  :episode:  0\n",
      "q_loss:  [1.0229102]\n",
      "t:  375  :episode:  0\n",
      "q_loss:  [0.34694138]\n",
      "t:  376  :episode:  0\n",
      "q_loss:  [0.2869659]\n",
      "t:  377  :episode:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [0.3482115]\n",
      "t:  378  :episode:  0\n",
      "q_loss:  [0.3492006]\n",
      "t:  379  :episode:  0\n",
      "q_loss:  [0.44797805]\n",
      "t:  380  :episode:  0\n",
      "q_loss:  [0.36175147]\n",
      "t:  381  :episode:  0\n",
      "q_loss:  [0.11595603]\n",
      "t:  382  :episode:  0\n",
      "q_loss:  [0.19441657]\n",
      "t:  383  :episode:  0\n",
      "q_loss:  [0.14934915]\n",
      "t:  384  :episode:  0\n",
      "q_loss:  [0.22876292]\n",
      "t:  385  :episode:  0\n",
      "q_loss:  [0.58408237]\n",
      "t:  386  :episode:  0\n",
      "q_loss:  [0.1986756]\n",
      "t:  387  :episode:  0\n",
      "q_loss:  [0.22035907]\n",
      "t:  388  :episode:  0\n",
      "q_loss:  [0.5010184]\n",
      "t:  389  :episode:  0\n",
      "q_loss:  [0.53008395]\n",
      "t:  390  :episode:  0\n",
      "q_loss:  [0.66233754]\n",
      "t:  391  :episode:  0\n",
      "q_loss:  [0.7222476]\n",
      "t:  392  :episode:  0\n",
      "q_loss:  [0.18676925]\n",
      "t:  393  :episode:  0\n",
      "q_loss:  [0.13378447]\n",
      "t:  394  :episode:  0\n",
      "q_loss:  [0.39999747]\n",
      "t:  395  :episode:  0\n",
      "q_loss:  [0.43770325]\n",
      "t:  396  :episode:  0\n",
      "q_loss:  [0.17864856]\n",
      "t:  397  :episode:  0\n",
      "q_loss:  [0.82682514]\n",
      "t:  398  :episode:  0\n",
      "q_loss:  [0.25096035]\n",
      "t:  399  :episode:  0\n",
      "q_loss:  [0.28299823]\n",
      "t:  400  :episode:  0\n",
      "q_loss:  [0.43567938]\n",
      "t:  401  :episode:  0\n",
      "q_loss:  [0.28630954]\n",
      "t:  402  :episode:  0\n",
      "q_loss:  [0.24102882]\n",
      "t:  403  :episode:  0\n",
      "q_loss:  [0.25393304]\n",
      "t:  404  :episode:  0\n",
      "q_loss:  [0.15041605]\n",
      "t:  405  :episode:  0\n",
      "q_loss:  [0.65827334]\n",
      "t:  406  :episode:  0\n",
      "q_loss:  [0.42157078]\n",
      "t:  407  :episode:  0\n",
      "q_loss:  [0.22499292]\n",
      "t:  408  :episode:  0\n",
      "q_loss:  [0.07171092]\n",
      "t:  409  :episode:  0\n",
      "q_loss:  [0.3228864]\n",
      "t:  410  :episode:  0\n",
      "q_loss:  [0.26801676]\n",
      "t:  411  :episode:  0\n",
      "q_loss:  [0.19148482]\n",
      "t:  412  :episode:  0\n",
      "q_loss:  [0.4835497]\n",
      "t:  413  :episode:  0\n",
      "q_loss:  [0.06954575]\n",
      "t:  414  :episode:  0\n",
      "q_loss:  [0.09885375]\n",
      "t:  415  :episode:  0\n",
      "q_loss:  [0.34937924]\n",
      "t:  416  :episode:  0\n",
      "q_loss:  [0.24253991]\n",
      "t:  417  :episode:  0\n",
      "q_loss:  [0.63866204]\n",
      "t:  418  :episode:  0\n",
      "q_loss:  [0.27435544]\n",
      "t:  419  :episode:  0\n",
      "q_loss:  [0.23656207]\n",
      "t:  420  :episode:  0\n",
      "q_loss:  [0.53405213]\n",
      "t:  421  :episode:  0\n",
      "q_loss:  [0.06071106]\n",
      "t:  422  :episode:  0\n",
      "q_loss:  [0.29158622]\n",
      "t:  423  :episode:  0\n",
      "q_loss:  [0.16632286]\n",
      "t:  424  :episode:  0\n",
      "q_loss:  [0.41955552]\n",
      "t:  425  :episode:  0\n",
      "q_loss:  [0.26631427]\n",
      "t:  426  :episode:  0\n",
      "q_loss:  [0.28648445]\n",
      "t:  427  :episode:  0\n",
      "q_loss:  [0.12300872]\n",
      "t:  428  :episode:  0\n",
      "q_loss:  [0.1434086]\n",
      "t:  429  :episode:  0\n",
      "q_loss:  [0.582556]\n",
      "t:  430  :episode:  0\n",
      "q_loss:  [0.26418817]\n",
      "t:  431  :episode:  0\n",
      "q_loss:  [0.36425588]\n",
      "t:  432  :episode:  0\n",
      "q_loss:  [0.11929132]\n",
      "t:  433  :episode:  0\n",
      "q_loss:  [0.21349211]\n",
      "t:  434  :episode:  0\n",
      "q_loss:  [0.35262758]\n",
      "t:  435  :episode:  0\n",
      "q_loss:  [0.31005085]\n",
      "t:  436  :episode:  0\n",
      "q_loss:  [0.4494204]\n",
      "t:  437  :episode:  0\n",
      "q_loss:  [0.10427791]\n",
      "t:  438  :episode:  0\n",
      "q_loss:  [0.17516918]\n",
      "t:  439  :episode:  0\n",
      "q_loss:  [0.23638359]\n",
      "t:  440  :episode:  0\n",
      "q_loss:  [0.41788977]\n",
      "t:  441  :episode:  0\n",
      "q_loss:  [0.22595364]\n",
      "t:  442  :episode:  0\n",
      "q_loss:  [0.37614757]\n",
      "t:  443  :episode:  0\n",
      "q_loss:  [0.19511238]\n",
      "t:  444  :episode:  0\n",
      "q_loss:  [0.0995634]\n",
      "t:  445  :episode:  0\n",
      "q_loss:  [0.28548515]\n",
      "t:  446  :episode:  0\n",
      "q_loss:  [0.19871223]\n",
      "t:  447  :episode:  0\n",
      "q_loss:  [0.19252205]\n",
      "t:  448  :episode:  0\n",
      "q_loss:  [0.09719069]\n",
      "t:  449  :episode:  0\n",
      "q_loss:  [0.35770562]\n",
      "t:  450  :episode:  0\n",
      "q_loss:  [0.30581716]\n",
      "t:  451  :episode:  0\n",
      "q_loss:  [0.32260412]\n",
      "t:  452  :episode:  0\n",
      "q_loss:  [0.23852211]\n",
      "t:  453  :episode:  0\n",
      "q_loss:  [0.09331742]\n",
      "t:  454  :episode:  0\n",
      "q_loss:  [0.2946167]\n",
      "t:  455  :episode:  0\n",
      "q_loss:  [0.1827097]\n",
      "t:  456  :episode:  0\n",
      "q_loss:  [0.56769055]\n",
      "t:  457  :episode:  0\n",
      "q_loss:  [0.40222448]\n",
      "t:  458  :episode:  0\n",
      "q_loss:  [0.2722567]\n",
      "t:  459  :episode:  0\n",
      "q_loss:  [0.26215944]\n",
      "t:  460  :episode:  0\n",
      "q_loss:  [0.36692864]\n",
      "t:  461  :episode:  0\n",
      "q_loss:  [0.24905413]\n",
      "t:  462  :episode:  0\n",
      "q_loss:  [0.19036767]\n",
      "t:  463  :episode:  0\n",
      "q_loss:  [0.06158049]\n",
      "t:  464  :episode:  0\n",
      "q_loss:  [0.4270509]\n",
      "t:  465  :episode:  0\n",
      "q_loss:  [0.4237764]\n",
      "t:  466  :episode:  0\n",
      "q_loss:  [0.4486608]\n",
      "t:  467  :episode:  0\n",
      "q_loss:  [0.1576746]\n",
      "t:  468  :episode:  0\n",
      "q_loss:  [0.23804355]\n",
      "t:  469  :episode:  0\n",
      "q_loss:  [0.44874087]\n",
      "t:  470  :episode:  0\n",
      "q_loss:  [0.54954267]\n",
      "t:  471  :episode:  0\n",
      "q_loss:  [0.18424207]\n",
      "t:  472  :episode:  0\n",
      "q_loss:  [0.450833]\n",
      "t:  473  :episode:  0\n",
      "q_loss:  [0.18541928]\n",
      "t:  474  :episode:  0\n",
      "q_loss:  [0.2658658]\n",
      "t:  475  :episode:  0\n",
      "q_loss:  [0.43894637]\n",
      "t:  476  :episode:  0\n",
      "q_loss:  [0.56334794]\n",
      "t:  477  :episode:  0\n",
      "q_loss:  [0.08094798]\n",
      "t:  478  :episode:  0\n",
      "q_loss:  [0.21421787]\n",
      "t:  479  :episode:  0\n",
      "q_loss:  [0.3395295]\n",
      "t:  480  :episode:  0\n",
      "q_loss:  [0.37279102]\n",
      "t:  481  :episode:  0\n",
      "q_loss:  [0.32467973]\n",
      "t:  482  :episode:  0\n",
      "q_loss:  [0.2802518]\n",
      "t:  483  :episode:  0\n",
      "q_loss:  [0.43603098]\n",
      "t:  484  :episode:  0\n",
      "q_loss:  [0.26709786]\n",
      "t:  485  :episode:  0\n",
      "q_loss:  [0.08210355]\n",
      "t:  486  :episode:  0\n",
      "q_loss:  [0.2687508]\n",
      "t:  487  :episode:  0\n",
      "q_loss:  [0.17366102]\n",
      "t:  488  :episode:  0\n",
      "q_loss:  [0.52308416]\n",
      "t:  489  :episode:  0\n",
      "q_loss:  [0.19120815]\n",
      "t:  490  :episode:  0\n",
      "q_loss:  [0.4443295]\n",
      "t:  491  :episode:  0\n",
      "q_loss:  [0.78044987]\n",
      "t:  492  :episode:  0\n",
      "q_loss:  [0.3520043]\n",
      "t:  493  :episode:  0\n",
      "q_loss:  [0.46686465]\n",
      "t:  494  :episode:  0\n",
      "q_loss:  [0.5522753]\n",
      "t:  495  :episode:  0\n",
      "q_loss:  [0.50556004]\n",
      "t:  496  :episode:  0\n",
      "q_loss:  [0.15172651]\n",
      "t:  497  :episode:  0\n",
      "q_loss:  [0.14598797]\n",
      "t:  498  :episode:  0\n",
      "q_loss:  [0.2861845]\n",
      "t:  499  :episode:  0\n",
      "q_loss:  [0.10148601]\n",
      "t:  500  :episode:  0\n",
      "q_loss:  [0.62102264]\n",
      "t:  501  :episode:  0\n",
      "q_loss:  [0.6087497]\n",
      "t:  502  :episode:  0\n",
      "q_loss:  [0.23992342]\n",
      "t:  503  :episode:  0\n",
      "q_loss:  [0.4557112]\n",
      "t:  504  :episode:  0\n",
      "q_loss:  [0.75182843]\n",
      "t:  505  :episode:  0\n",
      "q_loss:  [0.35436773]\n",
      "t:  506  :episode:  0\n",
      "q_loss:  [0.36801046]\n",
      "t:  507  :episode:  0\n",
      "q_loss:  [0.6449198]\n",
      "t:  508  :episode:  0\n",
      "q_loss:  [0.41234952]\n",
      "t:  509  :episode:  0\n",
      "q_loss:  [0.28112584]\n",
      "t:  510  :episode:  0\n",
      "q_loss:  [0.54136336]\n",
      "t:  511  :episode:  0\n",
      "q_loss:  [0.27061594]\n",
      "t:  512  :episode:  0\n",
      "q_loss:  [0.22991204]\n",
      "t:  513  :episode:  0\n",
      "q_loss:  [0.38936698]\n",
      "t:  514  :episode:  0\n",
      "q_loss:  [0.39432704]\n",
      "t:  515  :episode:  0\n",
      "q_loss:  [0.36924684]\n",
      "t:  516  :episode:  0\n",
      "q_loss:  [0.31875554]\n",
      "t:  517  :episode:  0\n",
      "q_loss:  [0.37952042]\n",
      "t:  518  :episode:  0\n",
      "q_loss:  [0.75580245]\n",
      "t:  519  :episode:  0\n",
      "q_loss:  [0.13107085]\n",
      "t:  520  :episode:  0\n",
      "q_loss:  [0.53064823]\n",
      "t:  521  :episode:  0\n",
      "q_loss:  [0.25634587]\n",
      "t:  522  :episode:  0\n",
      "q_loss:  [0.6346271]\n",
      "t:  523  :episode:  0\n",
      "q_loss:  [0.37858516]\n",
      "t:  524  :episode:  0\n",
      "q_loss:  [0.72597504]\n",
      "t:  525  :episode:  0\n",
      "q_loss:  [0.5450114]\n",
      "t:  526  :episode:  0\n",
      "q_loss:  [0.17279798]\n",
      "t:  527  :episode:  0\n",
      "q_loss:  [0.30269483]\n",
      "t:  528  :episode:  0\n",
      "q_loss:  [0.3839227]\n",
      "t:  529  :episode:  0\n",
      "q_loss:  [0.45552617]\n",
      "t:  530  :episode:  0\n",
      "q_loss:  [0.35420936]\n",
      "t:  531  :episode:  0\n",
      "q_loss:  [0.10454188]\n",
      "t:  532  :episode:  0\n",
      "q_loss:  [0.29471275]\n",
      "t:  533  :episode:  0\n",
      "q_loss:  [0.16932791]\n",
      "t:  534  :episode:  0\n",
      "q_loss:  [0.35779995]\n",
      "t:  535  :episode:  0\n",
      "q_loss:  [0.39945173]\n",
      "t:  536  :episode:  0\n",
      "q_loss:  [0.31504285]\n",
      "t:  537  :episode:  0\n",
      "q_loss:  [0.4104609]\n",
      "t:  538  :episode:  0\n",
      "q_loss:  [0.11050711]\n",
      "t:  539  :episode:  0\n",
      "q_loss:  [0.6120832]\n",
      "t:  540  :episode:  0\n",
      "q_loss:  [0.3885206]\n",
      "t:  541  :episode:  0\n",
      "q_loss:  [0.47745278]\n",
      "t:  542  :episode:  0\n",
      "q_loss:  [0.60441107]\n",
      "t:  543  :episode:  0\n",
      "q_loss:  [0.25339657]\n",
      "t:  544  :episode:  0\n",
      "q_loss:  [0.67668575]\n",
      "t:  545  :episode:  0\n",
      "q_loss:  [0.08113399]\n",
      "t:  546  :episode:  0\n",
      "q_loss:  [0.3528207]\n",
      "t:  547  :episode:  0\n",
      "q_loss:  [0.23940927]\n",
      "t:  548  :episode:  0\n",
      "q_loss:  [0.31776062]\n",
      "t:  549  :episode:  0\n",
      "q_loss:  [0.4939385]\n",
      "t:  550  :episode:  0\n",
      "q_loss:  [0.84695274]\n",
      "t:  551  :episode:  0\n",
      "q_loss:  [0.25580066]\n",
      "t:  552  :episode:  0\n",
      "q_loss:  [0.60638094]\n",
      "t:  553  :episode:  0\n",
      "q_loss:  [0.21837282]\n",
      "t:  554  :episode:  0\n",
      "q_loss:  [0.14792924]\n",
      "t:  555  :episode:  0\n",
      "q_loss:  [0.08877873]\n",
      "t:  556  :episode:  0\n",
      "q_loss:  [0.12410915]\n",
      "t:  557  :episode:  0\n",
      "q_loss:  [0.23222564]\n",
      "t:  558  :episode:  0\n",
      "q_loss:  [0.20477259]\n",
      "t:  559  :episode:  0\n",
      "q_loss:  [0.5591155]\n",
      "t:  560  :episode:  0\n",
      "q_loss:  [0.10429814]\n",
      "t:  561  :episode:  0\n",
      "q_loss:  [0.30450702]\n",
      "t:  562  :episode:  0\n",
      "q_loss:  [0.07661056]\n",
      "t:  563  :episode:  0\n",
      "q_loss:  [0.30180866]\n",
      "t:  564  :episode:  0\n",
      "q_loss:  [0.75342333]\n",
      "t:  565  :episode:  0\n",
      "q_loss:  [0.40079412]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  566  :episode:  0\n",
      "q_loss:  [0.34399527]\n",
      "t:  567  :episode:  0\n",
      "q_loss:  [0.14945099]\n",
      "t:  568  :episode:  0\n",
      "q_loss:  [0.11456781]\n",
      "t:  569  :episode:  0\n",
      "q_loss:  [0.52204216]\n",
      "t:  570  :episode:  0\n",
      "q_loss:  [0.46909934]\n",
      "t:  571  :episode:  0\n",
      "q_loss:  [0.41130814]\n",
      "t:  572  :episode:  0\n",
      "q_loss:  [0.23905984]\n",
      "t:  573  :episode:  0\n",
      "q_loss:  [0.36889422]\n",
      "t:  574  :episode:  0\n",
      "q_loss:  [0.43285635]\n",
      "t:  575  :episode:  0\n",
      "q_loss:  [0.07125936]\n",
      "t:  576  :episode:  0\n",
      "q_loss:  [0.25652653]\n",
      "t:  577  :episode:  0\n",
      "q_loss:  [0.2787871]\n",
      "t:  578  :episode:  0\n",
      "q_loss:  [0.16910309]\n",
      "t:  579  :episode:  0\n",
      "q_loss:  [0.20832613]\n",
      "t:  580  :episode:  0\n",
      "q_loss:  [0.07891693]\n",
      "t:  581  :episode:  0\n",
      "q_loss:  [0.08362661]\n",
      "t:  582  :episode:  0\n",
      "q_loss:  [0.13297752]\n",
      "t:  583  :episode:  0\n",
      "q_loss:  [0.1784291]\n",
      "t:  584  :episode:  0\n",
      "q_loss:  [0.2859247]\n",
      "t:  585  :episode:  0\n",
      "q_loss:  [0.54208]\n",
      "t:  586  :episode:  0\n",
      "q_loss:  [0.55445486]\n",
      "t:  587  :episode:  0\n",
      "q_loss:  [0.3656098]\n",
      "t:  588  :episode:  0\n",
      "q_loss:  [0.44416624]\n",
      "t:  589  :episode:  0\n",
      "q_loss:  [0.50843465]\n",
      "t:  590  :episode:  0\n",
      "q_loss:  [0.07905003]\n",
      "t:  591  :episode:  0\n",
      "q_loss:  [0.61563903]\n",
      "t:  592  :episode:  0\n",
      "q_loss:  [0.2598945]\n",
      "t:  593  :episode:  0\n",
      "q_loss:  [0.46854705]\n",
      "t:  594  :episode:  0\n",
      "q_loss:  [0.66734815]\n",
      "t:  595  :episode:  0\n",
      "q_loss:  [0.28636354]\n",
      "t:  596  :episode:  0\n",
      "q_loss:  [0.32001823]\n",
      "t:  597  :episode:  0\n",
      "q_loss:  [0.06828336]\n",
      "t:  598  :episode:  0\n",
      "q_loss:  [0.05217235]\n",
      "t:  599  :episode:  0\n",
      "q_loss:  [0.6346896]\n",
      "t:  600  :episode:  0\n",
      "q_loss:  [0.233594]\n",
      "t:  601  :episode:  0\n",
      "q_loss:  [0.2463086]\n",
      "t:  602  :episode:  0\n",
      "q_loss:  [0.36564845]\n",
      "t:  603  :episode:  0\n",
      "q_loss:  [0.41894588]\n",
      "t:  604  :episode:  0\n",
      "q_loss:  [0.6291412]\n",
      "t:  605  :episode:  0\n",
      "q_loss:  [0.92945004]\n",
      "t:  606  :episode:  0\n",
      "q_loss:  [0.12760851]\n",
      "t:  607  :episode:  0\n",
      "q_loss:  [0.44844967]\n",
      "t:  608  :episode:  0\n",
      "q_loss:  [0.2604655]\n",
      "t:  609  :episode:  0\n",
      "q_loss:  [0.50808007]\n",
      "t:  610  :episode:  0\n",
      "q_loss:  [0.17968024]\n",
      "t:  611  :episode:  0\n",
      "q_loss:  [0.43927225]\n",
      "t:  612  :episode:  0\n",
      "q_loss:  [0.50724036]\n",
      "t:  613  :episode:  0\n",
      "q_loss:  [0.17975117]\n",
      "t:  614  :episode:  0\n",
      "q_loss:  [0.4038588]\n",
      "t:  615  :episode:  0\n",
      "q_loss:  [0.35397482]\n",
      "t:  616  :episode:  0\n",
      "q_loss:  [0.11926056]\n",
      "t:  617  :episode:  0\n",
      "q_loss:  [0.10302982]\n",
      "t:  618  :episode:  0\n",
      "q_loss:  [0.16720721]\n",
      "t:  619  :episode:  0\n",
      "q_loss:  [0.16212162]\n",
      "t:  620  :episode:  0\n",
      "q_loss:  [0.20827632]\n",
      "t:  621  :episode:  0\n",
      "q_loss:  [0.2665444]\n",
      "t:  622  :episode:  0\n",
      "q_loss:  [0.44767797]\n",
      "t:  623  :episode:  0\n",
      "q_loss:  [0.31948254]\n",
      "t:  624  :episode:  0\n",
      "q_loss:  [0.298131]\n",
      "t:  625  :episode:  0\n",
      "q_loss:  [0.2965173]\n",
      "t:  626  :episode:  0\n",
      "q_loss:  [0.17458797]\n",
      "t:  627  :episode:  0\n",
      "q_loss:  [0.13197732]\n",
      "t:  628  :episode:  0\n",
      "q_loss:  [0.26981175]\n",
      "t:  629  :episode:  0\n",
      "q_loss:  [0.13301179]\n",
      "t:  630  :episode:  0\n",
      "q_loss:  [0.5851099]\n",
      "t:  631  :episode:  0\n",
      "q_loss:  [0.71810734]\n",
      "t:  632  :episode:  0\n",
      "q_loss:  [0.30018663]\n",
      "t:  633  :episode:  0\n",
      "q_loss:  [0.30425978]\n",
      "t:  634  :episode:  0\n",
      "q_loss:  [0.8278644]\n",
      "t:  635  :episode:  0\n",
      "q_loss:  [0.28914174]\n",
      "t:  636  :episode:  0\n",
      "q_loss:  [0.40039212]\n",
      "t:  637  :episode:  0\n",
      "q_loss:  [0.19415636]\n",
      "t:  638  :episode:  0\n",
      "q_loss:  [0.22543812]\n",
      "t:  639  :episode:  0\n",
      "q_loss:  [0.3211788]\n",
      "t:  640  :episode:  0\n",
      "q_loss:  [0.17427105]\n",
      "t:  641  :episode:  0\n",
      "q_loss:  [0.53067553]\n",
      "t:  642  :episode:  0\n",
      "q_loss:  [0.3445067]\n",
      "t:  643  :episode:  0\n",
      "q_loss:  [0.61658156]\n",
      "t:  644  :episode:  0\n",
      "q_loss:  [0.11976217]\n",
      "t:  645  :episode:  0\n",
      "q_loss:  [0.36808854]\n",
      "t:  646  :episode:  0\n",
      "q_loss:  [0.32770428]\n",
      "t:  647  :episode:  0\n",
      "q_loss:  [0.14308077]\n",
      "t:  648  :episode:  0\n",
      "q_loss:  [0.3623916]\n",
      "t:  649  :episode:  0\n",
      "q_loss:  [0.13042259]\n",
      "t:  650  :episode:  0\n",
      "q_loss:  [0.3121106]\n",
      "t:  651  :episode:  0\n",
      "q_loss:  [0.25897837]\n",
      "t:  652  :episode:  0\n",
      "q_loss:  [0.26484507]\n",
      "t:  653  :episode:  0\n",
      "q_loss:  [0.02538399]\n",
      "t:  654  :episode:  0\n",
      "q_loss:  [0.18607691]\n",
      "t:  655  :episode:  0\n",
      "q_loss:  [0.48523068]\n",
      "t:  656  :episode:  0\n",
      "q_loss:  [0.32642725]\n",
      "t:  657  :episode:  0\n",
      "q_loss:  [0.32248265]\n",
      "t:  658  :episode:  0\n",
      "q_loss:  [0.7564893]\n",
      "t:  659  :episode:  0\n",
      "q_loss:  [0.07864636]\n",
      "t:  660  :episode:  0\n",
      "q_loss:  [0.24437273]\n",
      "t:  661  :episode:  0\n",
      "q_loss:  [0.26708096]\n",
      "t:  662  :episode:  0\n",
      "q_loss:  [0.1787234]\n",
      "t:  663  :episode:  0\n",
      "q_loss:  [0.4043677]\n",
      "t:  664  :episode:  0\n",
      "q_loss:  [0.59534067]\n",
      "t:  665  :episode:  0\n",
      "q_loss:  [0.42820364]\n",
      "t:  666  :episode:  0\n",
      "q_loss:  [0.61984414]\n",
      "t:  667  :episode:  0\n",
      "q_loss:  [0.35201395]\n",
      "t:  668  :episode:  0\n",
      "q_loss:  [0.29624644]\n",
      "t:  669  :episode:  0\n",
      "q_loss:  [0.3183204]\n",
      "t:  670  :episode:  0\n",
      "q_loss:  [0.5504035]\n",
      "t:  671  :episode:  0\n",
      "q_loss:  [0.3976634]\n",
      "t:  672  :episode:  0\n",
      "q_loss:  [0.25260183]\n",
      "t:  673  :episode:  0\n",
      "q_loss:  [0.27373803]\n",
      "t:  674  :episode:  0\n",
      "q_loss:  [0.39181042]\n",
      "t:  675  :episode:  0\n",
      "q_loss:  [0.2587216]\n",
      "t:  676  :episode:  0\n",
      "q_loss:  [0.11258692]\n",
      "t:  677  :episode:  0\n",
      "q_loss:  [0.20285603]\n",
      "t:  678  :episode:  0\n",
      "q_loss:  [1.1555536]\n",
      "t:  679  :episode:  0\n",
      "q_loss:  [0.6804327]\n",
      "t:  680  :episode:  0\n",
      "q_loss:  [0.27682447]\n",
      "t:  681  :episode:  0\n",
      "q_loss:  [0.1656694]\n",
      "t:  682  :episode:  0\n",
      "q_loss:  [0.3571784]\n",
      "t:  683  :episode:  0\n",
      "q_loss:  [0.25469103]\n",
      "t:  684  :episode:  0\n",
      "q_loss:  [0.521983]\n",
      "t:  685  :episode:  0\n",
      "q_loss:  [0.2979241]\n",
      "t:  686  :episode:  0\n",
      "q_loss:  [0.14725631]\n",
      "t:  687  :episode:  0\n",
      "q_loss:  [0.23411313]\n",
      "t:  688  :episode:  0\n",
      "q_loss:  [0.12052127]\n",
      "t:  689  :episode:  0\n",
      "q_loss:  [0.55780953]\n",
      "t:  690  :episode:  0\n",
      "q_loss:  [0.32340813]\n",
      "t:  691  :episode:  0\n",
      "q_loss:  [0.4817193]\n",
      "t:  692  :episode:  0\n",
      "q_loss:  [0.08438301]\n",
      "t:  693  :episode:  0\n",
      "q_loss:  [0.10540809]\n",
      "t:  694  :episode:  0\n",
      "q_loss:  [0.398193]\n",
      "t:  695  :episode:  0\n",
      "q_loss:  [0.19870006]\n",
      "t:  696  :episode:  0\n",
      "q_loss:  [0.18257843]\n",
      "t:  697  :episode:  0\n",
      "q_loss:  [0.98378444]\n",
      "t:  698  :episode:  0\n",
      "q_loss:  [0.36669576]\n",
      "t:  699  :episode:  0\n",
      "q_loss:  [0.16036962]\n",
      "t:  700  :episode:  0\n",
      "q_loss:  [0.692153]\n",
      "t:  701  :episode:  0\n",
      "q_loss:  [0.27812663]\n",
      "t:  702  :episode:  0\n",
      "q_loss:  [0.37451378]\n",
      "t:  703  :episode:  0\n",
      "q_loss:  [0.4416417]\n",
      "t:  704  :episode:  0\n",
      "q_loss:  [0.38455975]\n",
      "t:  705  :episode:  0\n",
      "q_loss:  [0.30431026]\n",
      "t:  706  :episode:  0\n",
      "q_loss:  [0.41321644]\n",
      "t:  707  :episode:  0\n",
      "q_loss:  [0.23155062]\n",
      "t:  708  :episode:  0\n",
      "q_loss:  [0.43652627]\n",
      "t:  709  :episode:  0\n",
      "q_loss:  [0.41925725]\n",
      "t:  710  :episode:  0\n",
      "q_loss:  [0.3246514]\n",
      "t:  711  :episode:  0\n",
      "q_loss:  [0.34640807]\n",
      "t:  712  :episode:  0\n",
      "q_loss:  [0.19584092]\n",
      "t:  713  :episode:  0\n",
      "q_loss:  [0.64734113]\n",
      "t:  714  :episode:  0\n",
      "q_loss:  [0.13010749]\n",
      "t:  715  :episode:  0\n",
      "q_loss:  [0.45064422]\n",
      "t:  716  :episode:  0\n",
      "q_loss:  [0.59755754]\n",
      "t:  717  :episode:  0\n",
      "q_loss:  [0.26138797]\n",
      "t:  718  :episode:  0\n",
      "q_loss:  [0.55511]\n",
      "t:  719  :episode:  0\n",
      "q_loss:  [0.4087978]\n",
      "t:  720  :episode:  0\n",
      "q_loss:  [0.3566779]\n",
      "t:  721  :episode:  0\n",
      "q_loss:  [0.3628738]\n",
      "t:  722  :episode:  0\n",
      "q_loss:  [0.26632452]\n",
      "t:  723  :episode:  0\n",
      "q_loss:  [0.3990388]\n",
      "t:  724  :episode:  0\n",
      "q_loss:  [0.35548174]\n",
      "t:  725  :episode:  0\n",
      "q_loss:  [0.23775274]\n",
      "t:  726  :episode:  0\n",
      "q_loss:  [0.6614227]\n",
      "t:  727  :episode:  0\n",
      "q_loss:  [0.2962606]\n",
      "t:  728  :episode:  0\n",
      "q_loss:  [0.14226353]\n",
      "t:  729  :episode:  0\n",
      "q_loss:  [0.28370526]\n",
      "t:  730  :episode:  0\n",
      "q_loss:  [0.2305855]\n",
      "t:  731  :episode:  0\n",
      "q_loss:  [0.35092726]\n",
      "t:  732  :episode:  0\n",
      "q_loss:  [0.2648527]\n",
      "t:  733  :episode:  0\n",
      "q_loss:  [0.22356692]\n",
      "t:  734  :episode:  0\n",
      "q_loss:  [0.20908146]\n",
      "t:  735  :episode:  0\n",
      "q_loss:  [0.15464331]\n",
      "t:  736  :episode:  0\n",
      "q_loss:  [0.4870508]\n",
      "t:  737  :episode:  0\n",
      "q_loss:  [1.0125635]\n",
      "t:  738  :episode:  0\n",
      "q_loss:  [0.66119564]\n",
      "t:  739  :episode:  0\n",
      "q_loss:  [0.21413508]\n",
      "t:  740  :episode:  0\n",
      "q_loss:  [0.09948662]\n",
      "t:  741  :episode:  0\n",
      "q_loss:  [0.33321]\n",
      "t:  742  :episode:  0\n",
      "q_loss:  [0.1888417]\n",
      "t:  743  :episode:  0\n",
      "q_loss:  [0.8366797]\n",
      "t:  744  :episode:  0\n",
      "q_loss:  [0.6002493]\n",
      "t:  745  :episode:  0\n",
      "q_loss:  [0.41228712]\n",
      "t:  746  :episode:  0\n",
      "q_loss:  [0.39065707]\n",
      "t:  747  :episode:  0\n",
      "q_loss:  [0.8078832]\n",
      "t:  748  :episode:  0\n",
      "q_loss:  [0.25233984]\n",
      "t:  749  :episode:  0\n",
      "q_loss:  [0.62809026]\n",
      "t:  750  :episode:  0\n",
      "q_loss:  [0.07105638]\n",
      "t:  751  :episode:  0\n",
      "q_loss:  [0.37400514]\n",
      "t:  752  :episode:  0\n",
      "q_loss:  [0.31927544]\n",
      "t:  753  :episode:  0\n",
      "q_loss:  [0.2260573]\n",
      "t:  754  :episode:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [0.2783656]\n",
      "t:  755  :episode:  0\n",
      "q_loss:  [0.26083264]\n",
      "t:  756  :episode:  0\n",
      "q_loss:  [0.4933945]\n",
      "t:  757  :episode:  0\n",
      "q_loss:  [0.17241612]\n",
      "t:  758  :episode:  0\n",
      "q_loss:  [0.31734514]\n",
      "t:  759  :episode:  0\n",
      "q_loss:  [0.12068719]\n",
      "t:  760  :episode:  0\n",
      "q_loss:  [0.09529025]\n",
      "t:  761  :episode:  0\n",
      "q_loss:  [0.37531328]\n",
      "t:  762  :episode:  0\n",
      "q_loss:  [0.19405104]\n",
      "t:  763  :episode:  0\n",
      "q_loss:  [0.8556369]\n",
      "t:  764  :episode:  0\n",
      "q_loss:  [0.23385231]\n",
      "t:  765  :episode:  0\n",
      "q_loss:  [0.6498941]\n",
      "t:  766  :episode:  0\n",
      "q_loss:  [0.20667768]\n",
      "t:  767  :episode:  0\n",
      "q_loss:  [0.31087857]\n",
      "t:  768  :episode:  0\n",
      "q_loss:  [0.42010856]\n",
      "t:  769  :episode:  0\n",
      "q_loss:  [0.26929468]\n",
      "t:  770  :episode:  0\n",
      "q_loss:  [0.9569495]\n",
      "t:  771  :episode:  0\n",
      "q_loss:  [0.44066507]\n",
      "t:  772  :episode:  0\n",
      "q_loss:  [0.447546]\n",
      "t:  773  :episode:  0\n",
      "q_loss:  [0.66086304]\n",
      "t:  774  :episode:  0\n",
      "q_loss:  [0.24704653]\n",
      "t:  775  :episode:  0\n",
      "q_loss:  [0.24218136]\n",
      "t:  776  :episode:  0\n",
      "q_loss:  [0.4513635]\n",
      "t:  777  :episode:  0\n",
      "q_loss:  [0.13084409]\n",
      "t:  778  :episode:  0\n",
      "q_loss:  [0.30013317]\n",
      "t:  779  :episode:  0\n",
      "q_loss:  [0.2500122]\n",
      "t:  780  :episode:  0\n",
      "q_loss:  [0.47623166]\n",
      "t:  781  :episode:  0\n",
      "q_loss:  [0.0887265]\n",
      "t:  782  :episode:  0\n",
      "q_loss:  [0.38785547]\n",
      "t:  783  :episode:  0\n",
      "q_loss:  [0.1286188]\n",
      "t:  784  :episode:  0\n",
      "q_loss:  [0.37314194]\n",
      "t:  785  :episode:  0\n",
      "q_loss:  [0.21802391]\n",
      "t:  786  :episode:  0\n",
      "q_loss:  [0.4305637]\n",
      "t:  787  :episode:  0\n",
      "q_loss:  [0.63160557]\n",
      "t:  788  :episode:  0\n",
      "q_loss:  [0.13145715]\n",
      "t:  789  :episode:  0\n",
      "q_loss:  [0.45996186]\n",
      "t:  790  :episode:  0\n",
      "q_loss:  [0.10242133]\n",
      "t:  791  :episode:  0\n",
      "q_loss:  [0.51165384]\n",
      "t:  792  :episode:  0\n",
      "q_loss:  [0.3032184]\n",
      "t:  793  :episode:  0\n",
      "q_loss:  [0.50177574]\n",
      "t:  794  :episode:  0\n",
      "q_loss:  [0.69464946]\n",
      "t:  795  :episode:  0\n",
      "q_loss:  [0.5563557]\n",
      "t:  796  :episode:  0\n",
      "q_loss:  [0.38569185]\n",
      "t:  797  :episode:  0\n",
      "q_loss:  [0.31161594]\n",
      "t:  798  :episode:  0\n",
      "q_loss:  [0.05683967]\n",
      "t:  799  :episode:  0\n",
      "q_loss:  [0.38385966]\n",
      "t:  800  :episode:  0\n",
      "q_loss:  [0.25622776]\n",
      "t:  801  :episode:  0\n",
      "q_loss:  [0.17650612]\n",
      "t:  802  :episode:  0\n",
      "q_loss:  [0.32040834]\n",
      "t:  803  :episode:  0\n",
      "q_loss:  [0.4258256]\n",
      "t:  804  :episode:  0\n",
      "q_loss:  [0.993034]\n",
      "t:  805  :episode:  0\n",
      "q_loss:  [0.05238312]\n",
      "t:  806  :episode:  0\n",
      "q_loss:  [0.18584327]\n",
      "t:  807  :episode:  0\n",
      "q_loss:  [0.31038016]\n",
      "t:  808  :episode:  0\n",
      "q_loss:  [0.16161707]\n",
      "t:  809  :episode:  0\n",
      "q_loss:  [0.40336746]\n",
      "t:  810  :episode:  0\n",
      "q_loss:  [0.614244]\n",
      "t:  811  :episode:  0\n",
      "q_loss:  [0.13622458]\n",
      "t:  812  :episode:  0\n",
      "q_loss:  [0.6140083]\n",
      "t:  813  :episode:  0\n",
      "q_loss:  [0.5212575]\n",
      "t:  814  :episode:  0\n",
      "q_loss:  [0.32903633]\n",
      "t:  815  :episode:  0\n",
      "q_loss:  [0.7896721]\n",
      "t:  816  :episode:  0\n",
      "q_loss:  [0.3798806]\n",
      "t:  817  :episode:  0\n",
      "q_loss:  [0.5323178]\n",
      "t:  818  :episode:  0\n",
      "q_loss:  [0.69912755]\n",
      "t:  819  :episode:  0\n",
      "q_loss:  [0.27362335]\n",
      "t:  820  :episode:  0\n",
      "q_loss:  [0.2522261]\n",
      "t:  821  :episode:  0\n",
      "q_loss:  [0.10145387]\n",
      "t:  822  :episode:  0\n",
      "q_loss:  [0.19913954]\n",
      "t:  823  :episode:  0\n",
      "q_loss:  [0.46157816]\n",
      "t:  824  :episode:  0\n",
      "q_loss:  [0.20059529]\n",
      "t:  825  :episode:  0\n",
      "q_loss:  [0.34938243]\n",
      "t:  826  :episode:  0\n",
      "q_loss:  [0.10116145]\n",
      "t:  827  :episode:  0\n",
      "q_loss:  [0.13778779]\n",
      "t:  828  :episode:  0\n",
      "q_loss:  [0.3987668]\n",
      "t:  829  :episode:  0\n",
      "q_loss:  [0.26896992]\n",
      "t:  830  :episode:  0\n",
      "q_loss:  [0.10409504]\n",
      "t:  831  :episode:  0\n",
      "q_loss:  [0.36075836]\n",
      "t:  832  :episode:  0\n",
      "q_loss:  [0.1595025]\n",
      "t:  833  :episode:  0\n",
      "q_loss:  [0.36785185]\n",
      "t:  834  :episode:  0\n",
      "q_loss:  [0.16505918]\n",
      "t:  835  :episode:  0\n",
      "q_loss:  [0.50668323]\n",
      "t:  836  :episode:  0\n",
      "q_loss:  [0.26196945]\n",
      "t:  837  :episode:  0\n",
      "q_loss:  [0.19644022]\n",
      "t:  838  :episode:  0\n",
      "q_loss:  [0.46958297]\n",
      "t:  839  :episode:  0\n",
      "q_loss:  [0.08185679]\n",
      "t:  840  :episode:  0\n",
      "q_loss:  [0.23099008]\n",
      "t:  841  :episode:  0\n",
      "q_loss:  [0.10482877]\n",
      "t:  842  :episode:  0\n",
      "q_loss:  [0.99057776]\n",
      "t:  843  :episode:  0\n",
      "q_loss:  [0.28440952]\n",
      "t:  844  :episode:  0\n",
      "q_loss:  [0.9302304]\n",
      "t:  845  :episode:  0\n",
      "q_loss:  [0.6732655]\n",
      "t:  846  :episode:  0\n",
      "q_loss:  [0.23333749]\n",
      "t:  847  :episode:  0\n",
      "q_loss:  [0.6116097]\n",
      "t:  848  :episode:  0\n",
      "q_loss:  [0.3164303]\n",
      "t:  849  :episode:  0\n",
      "q_loss:  [0.430075]\n",
      "t:  850  :episode:  0\n",
      "q_loss:  [0.49519616]\n",
      "t:  851  :episode:  0\n",
      "q_loss:  [0.21745533]\n",
      "t:  852  :episode:  0\n",
      "q_loss:  [0.49059767]\n",
      "t:  853  :episode:  0\n",
      "q_loss:  [0.29378778]\n",
      "t:  854  :episode:  0\n",
      "q_loss:  [0.16249725]\n",
      "t:  855  :episode:  0\n",
      "q_loss:  [0.11222439]\n",
      "t:  856  :episode:  0\n",
      "q_loss:  [0.5754554]\n",
      "t:  857  :episode:  0\n",
      "q_loss:  [0.3197083]\n",
      "t:  858  :episode:  0\n",
      "q_loss:  [0.3431018]\n",
      "t:  859  :episode:  0\n",
      "q_loss:  [0.4365822]\n",
      "t:  860  :episode:  0\n",
      "q_loss:  [0.23690371]\n",
      "t:  861  :episode:  0\n",
      "q_loss:  [0.6067052]\n",
      "t:  862  :episode:  0\n",
      "q_loss:  [0.39251357]\n",
      "t:  863  :episode:  0\n",
      "q_loss:  [0.41634113]\n",
      "t:  864  :episode:  0\n",
      "q_loss:  [0.72976446]\n",
      "t:  865  :episode:  0\n",
      "q_loss:  [0.2723105]\n",
      "t:  866  :episode:  0\n",
      "q_loss:  [0.22348347]\n",
      "t:  867  :episode:  0\n",
      "q_loss:  [0.2201949]\n",
      "t:  868  :episode:  0\n",
      "q_loss:  [0.2751493]\n",
      "t:  869  :episode:  0\n",
      "q_loss:  [0.8164906]\n",
      "t:  870  :episode:  0\n",
      "q_loss:  [0.32688087]\n",
      "t:  871  :episode:  0\n",
      "q_loss:  [0.43172032]\n",
      "t:  872  :episode:  0\n",
      "q_loss:  [0.86050117]\n",
      "t:  873  :episode:  0\n",
      "q_loss:  [0.15044671]\n",
      "t:  874  :episode:  0\n",
      "q_loss:  [0.09293926]\n",
      "t:  875  :episode:  0\n",
      "q_loss:  [0.4815478]\n",
      "t:  876  :episode:  0\n",
      "q_loss:  [0.2555833]\n",
      "t:  877  :episode:  0\n",
      "q_loss:  [0.1814925]\n",
      "t:  878  :episode:  0\n",
      "q_loss:  [0.06440828]\n",
      "t:  879  :episode:  0\n",
      "q_loss:  [0.12949713]\n",
      "t:  880  :episode:  0\n",
      "q_loss:  [0.36278546]\n",
      "t:  881  :episode:  0\n",
      "q_loss:  [0.3810248]\n",
      "t:  882  :episode:  0\n",
      "q_loss:  [0.15628384]\n",
      "t:  883  :episode:  0\n",
      "q_loss:  [0.19704437]\n",
      "t:  884  :episode:  0\n",
      "q_loss:  [0.7517139]\n",
      "t:  885  :episode:  0\n",
      "q_loss:  [0.15003532]\n",
      "t:  886  :episode:  0\n",
      "q_loss:  [0.23556705]\n",
      "t:  887  :episode:  0\n",
      "q_loss:  [0.43062764]\n",
      "t:  888  :episode:  0\n",
      "q_loss:  [0.25704458]\n",
      "t:  889  :episode:  0\n",
      "q_loss:  [0.90317035]\n",
      "t:  890  :episode:  0\n",
      "q_loss:  [0.86318547]\n",
      "t:  891  :episode:  0\n",
      "q_loss:  [0.30535394]\n",
      "t:  892  :episode:  0\n",
      "q_loss:  [0.44269252]\n",
      "t:  893  :episode:  0\n",
      "q_loss:  [0.6065403]\n",
      "t:  894  :episode:  0\n",
      "q_loss:  [0.20297903]\n",
      "t:  895  :episode:  0\n",
      "q_loss:  [0.31965828]\n",
      "t:  896  :episode:  0\n",
      "q_loss:  [0.13406834]\n",
      "t:  897  :episode:  0\n",
      "q_loss:  [0.29404628]\n",
      "t:  898  :episode:  0\n",
      "q_loss:  [0.30303428]\n",
      "t:  899  :episode:  0\n",
      "q_loss:  [0.09957162]\n",
      "t:  900  :episode:  0\n",
      "q_loss:  [0.28568253]\n",
      "t:  901  :episode:  0\n",
      "q_loss:  [0.31068513]\n",
      "t:  902  :episode:  0\n",
      "q_loss:  [0.11218844]\n",
      "t:  903  :episode:  0\n",
      "q_loss:  [0.1535186]\n",
      "t:  904  :episode:  0\n",
      "q_loss:  [0.20117131]\n",
      "t:  905  :episode:  0\n",
      "q_loss:  [0.5140017]\n",
      "t:  906  :episode:  0\n",
      "q_loss:  [0.29167545]\n",
      "t:  907  :episode:  0\n",
      "q_loss:  [0.27855277]\n",
      "t:  908  :episode:  0\n",
      "q_loss:  [0.43055743]\n",
      "t:  909  :episode:  0\n",
      "q_loss:  [0.24393147]\n",
      "t:  910  :episode:  0\n",
      "q_loss:  [0.2757903]\n",
      "t:  911  :episode:  0\n",
      "q_loss:  [0.16415337]\n",
      "t:  912  :episode:  0\n",
      "q_loss:  [0.42397276]\n",
      "t:  913  :episode:  0\n",
      "q_loss:  [0.17405729]\n",
      "t:  914  :episode:  0\n",
      "q_loss:  [0.4374379]\n",
      "t:  915  :episode:  0\n",
      "q_loss:  [0.59542334]\n",
      "t:  916  :episode:  0\n",
      "q_loss:  [0.18447813]\n",
      "t:  917  :episode:  0\n",
      "q_loss:  [0.52434444]\n",
      "t:  918  :episode:  0\n",
      "q_loss:  [0.22094916]\n",
      "t:  919  :episode:  0\n",
      "q_loss:  [0.37419367]\n",
      "t:  920  :episode:  0\n",
      "q_loss:  [0.69559366]\n",
      "t:  921  :episode:  0\n",
      "q_loss:  [0.1165992]\n",
      "t:  922  :episode:  0\n",
      "q_loss:  [0.6098186]\n",
      "t:  923  :episode:  0\n",
      "q_loss:  [0.07053167]\n",
      "t:  924  :episode:  0\n",
      "q_loss:  [0.28764495]\n",
      "t:  925  :episode:  0\n",
      "q_loss:  [0.5202408]\n",
      "t:  926  :episode:  0\n",
      "q_loss:  [0.20735013]\n",
      "t:  927  :episode:  0\n",
      "q_loss:  [0.25783134]\n",
      "t:  928  :episode:  0\n",
      "q_loss:  [0.36020064]\n",
      "t:  929  :episode:  0\n",
      "q_loss:  [0.21541941]\n",
      "t:  930  :episode:  0\n",
      "q_loss:  [0.38416722]\n",
      "t:  931  :episode:  0\n",
      "q_loss:  [0.14735082]\n",
      "t:  932  :episode:  0\n",
      "q_loss:  [0.5412334]\n",
      "t:  933  :episode:  0\n",
      "q_loss:  [0.4732837]\n",
      "t:  934  :episode:  0\n",
      "q_loss:  [0.1946561]\n",
      "t:  935  :episode:  0\n",
      "q_loss:  [0.27735803]\n",
      "t:  936  :episode:  0\n",
      "q_loss:  [0.0641929]\n",
      "t:  937  :episode:  0\n",
      "q_loss:  [0.48940846]\n",
      "t:  938  :episode:  0\n",
      "q_loss:  [0.06667932]\n",
      "t:  939  :episode:  0\n",
      "q_loss:  [0.39913452]\n",
      "t:  940  :episode:  0\n",
      "q_loss:  [0.41153666]\n",
      "t:  941  :episode:  0\n",
      "q_loss:  [0.11679797]\n",
      "t:  942  :episode:  0\n",
      "q_loss:  [0.07590868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  943  :episode:  0\n",
      "q_loss:  [0.985991]\n",
      "t:  944  :episode:  0\n",
      "q_loss:  [0.15569048]\n",
      "t:  945  :episode:  0\n",
      "q_loss:  [0.27025747]\n",
      "t:  946  :episode:  0\n",
      "q_loss:  [0.20685616]\n",
      "t:  947  :episode:  0\n",
      "q_loss:  [0.3228577]\n",
      "t:  948  :episode:  0\n",
      "q_loss:  [0.3228972]\n",
      "t:  949  :episode:  0\n",
      "q_loss:  [0.6637796]\n",
      "t:  950  :episode:  0\n",
      "q_loss:  [0.5454177]\n",
      "t:  951  :episode:  0\n",
      "q_loss:  [0.42882365]\n",
      "t:  952  :episode:  0\n",
      "q_loss:  [0.10533044]\n",
      "t:  953  :episode:  0\n",
      "q_loss:  [0.41614065]\n",
      "t:  954  :episode:  0\n",
      "q_loss:  [0.35339487]\n",
      "t:  955  :episode:  0\n",
      "q_loss:  [0.2417004]\n",
      "t:  956  :episode:  0\n",
      "q_loss:  [0.34362125]\n",
      "t:  957  :episode:  0\n",
      "q_loss:  [0.51961005]\n",
      "t:  958  :episode:  0\n",
      "q_loss:  [0.1848276]\n",
      "t:  959  :episode:  0\n",
      "q_loss:  [0.4304642]\n",
      "t:  960  :episode:  0\n",
      "q_loss:  [0.22080562]\n",
      "t:  961  :episode:  0\n",
      "q_loss:  [0.15128137]\n",
      "t:  962  :episode:  0\n",
      "q_loss:  [0.20165244]\n",
      "t:  963  :episode:  0\n",
      "q_loss:  [0.09778753]\n",
      "t:  964  :episode:  0\n",
      "q_loss:  [0.36964193]\n",
      "t:  965  :episode:  0\n",
      "q_loss:  [0.37887147]\n",
      "t:  966  :episode:  0\n",
      "q_loss:  [0.4740367]\n",
      "t:  967  :episode:  0\n",
      "q_loss:  [0.17512232]\n",
      "t:  968  :episode:  0\n",
      "q_loss:  [0.21267813]\n",
      "t:  969  :episode:  0\n",
      "q_loss:  [0.5295602]\n",
      "t:  970  :episode:  0\n",
      "q_loss:  [0.07578709]\n",
      "t:  971  :episode:  0\n",
      "q_loss:  [0.0607537]\n",
      "t:  972  :episode:  0\n",
      "q_loss:  [0.44322336]\n",
      "t:  973  :episode:  0\n",
      "q_loss:  [0.49749327]\n",
      "t:  974  :episode:  0\n",
      "q_loss:  [0.5751276]\n",
      "t:  975  :episode:  0\n",
      "q_loss:  [0.16260628]\n",
      "t:  976  :episode:  0\n",
      "q_loss:  [0.35859185]\n",
      "t:  977  :episode:  0\n",
      "q_loss:  [0.15506713]\n",
      "t:  978  :episode:  0\n",
      "q_loss:  [0.56465465]\n",
      "t:  979  :episode:  0\n",
      "q_loss:  [0.4963997]\n",
      "t:  980  :episode:  0\n",
      "q_loss:  [0.4444468]\n",
      "t:  981  :episode:  0\n",
      "q_loss:  [0.1348467]\n",
      "t:  982  :episode:  0\n",
      "q_loss:  [0.4639523]\n",
      "t:  983  :episode:  0\n",
      "q_loss:  [0.13756993]\n",
      "t:  984  :episode:  0\n",
      "q_loss:  [0.14974995]\n",
      "t:  985  :episode:  0\n",
      "q_loss:  [0.263278]\n",
      "t:  986  :episode:  0\n",
      "q_loss:  [0.14570665]\n",
      "t:  987  :episode:  0\n",
      "q_loss:  [0.21567293]\n",
      "t:  988  :episode:  0\n",
      "q_loss:  [0.16921973]\n",
      "t:  989  :episode:  0\n",
      "q_loss:  [0.287424]\n",
      "t:  990  :episode:  0\n",
      "q_loss:  [0.08102877]\n",
      "t:  991  :episode:  0\n",
      "q_loss:  [0.3352846]\n",
      "t:  992  :episode:  0\n",
      "q_loss:  [0.26075903]\n",
      "t:  993  :episode:  0\n",
      "q_loss:  [0.58029854]\n",
      "t:  994  :episode:  0\n",
      "q_loss:  [0.09043849]\n",
      "t:  995  :episode:  0\n",
      "q_loss:  [0.14137101]\n",
      "t:  996  :episode:  0\n",
      "q_loss:  [0.41915557]\n",
      "t:  997  :episode:  0\n",
      "q_loss:  [0.17084059]\n",
      "t:  998  :episode:  0\n",
      "q_loss:  [0.32692719]\n",
      "t:  999  :episode:  0\n",
      "q_loss:  [0.1500229]\n",
      "Episode 0 finished after 1000 timesteps with reward -1476.9166097111188\n",
      "t:  0  :episode:  1\n",
      "q_loss:  [0.4974269]\n",
      "t:  1  :episode:  1\n",
      "q_loss:  [0.14666857]\n",
      "t:  2  :episode:  1\n",
      "q_loss:  [0.22516441]\n",
      "t:  3  :episode:  1\n",
      "q_loss:  [0.80572116]\n",
      "t:  4  :episode:  1\n",
      "q_loss:  [0.2901203]\n",
      "t:  5  :episode:  1\n",
      "q_loss:  [0.5326328]\n",
      "t:  6  :episode:  1\n",
      "q_loss:  [0.52213866]\n",
      "t:  7  :episode:  1\n",
      "q_loss:  [0.13917787]\n",
      "t:  8  :episode:  1\n",
      "q_loss:  [0.9272791]\n",
      "t:  9  :episode:  1\n",
      "q_loss:  [0.3956192]\n",
      "t:  10  :episode:  1\n",
      "q_loss:  [0.38743687]\n",
      "t:  11  :episode:  1\n",
      "q_loss:  [0.646246]\n",
      "t:  12  :episode:  1\n",
      "q_loss:  [0.21023415]\n",
      "t:  13  :episode:  1\n",
      "q_loss:  [0.20966777]\n",
      "t:  14  :episode:  1\n",
      "q_loss:  [0.55658907]\n",
      "t:  15  :episode:  1\n",
      "q_loss:  [0.56418425]\n",
      "t:  16  :episode:  1\n",
      "q_loss:  [0.47805327]\n",
      "t:  17  :episode:  1\n",
      "q_loss:  [0.44835424]\n",
      "t:  18  :episode:  1\n",
      "q_loss:  [1.054893]\n",
      "t:  19  :episode:  1\n",
      "q_loss:  [0.10589295]\n",
      "t:  20  :episode:  1\n",
      "q_loss:  [0.27779663]\n",
      "t:  21  :episode:  1\n",
      "q_loss:  [0.15367247]\n",
      "t:  22  :episode:  1\n",
      "q_loss:  [0.10087912]\n",
      "t:  23  :episode:  1\n",
      "q_loss:  [0.3563184]\n",
      "t:  24  :episode:  1\n",
      "q_loss:  [0.27375856]\n",
      "t:  25  :episode:  1\n",
      "q_loss:  [0.10033223]\n",
      "t:  26  :episode:  1\n",
      "q_loss:  [0.25933552]\n",
      "t:  27  :episode:  1\n",
      "q_loss:  [0.443473]\n",
      "t:  28  :episode:  1\n",
      "q_loss:  [0.21738738]\n",
      "t:  29  :episode:  1\n",
      "q_loss:  [0.09356633]\n",
      "t:  30  :episode:  1\n",
      "q_loss:  [0.40623486]\n",
      "t:  31  :episode:  1\n",
      "q_loss:  [0.1648235]\n",
      "t:  32  :episode:  1\n",
      "q_loss:  [0.06365606]\n",
      "t:  33  :episode:  1\n",
      "q_loss:  [0.08584178]\n",
      "t:  34  :episode:  1\n",
      "q_loss:  [0.25357825]\n",
      "t:  35  :episode:  1\n",
      "q_loss:  [0.16850162]\n",
      "t:  36  :episode:  1\n",
      "q_loss:  [0.2637584]\n",
      "t:  37  :episode:  1\n",
      "q_loss:  [0.42978328]\n",
      "t:  38  :episode:  1\n",
      "q_loss:  [0.8969788]\n",
      "t:  39  :episode:  1\n",
      "q_loss:  [0.37592733]\n",
      "t:  40  :episode:  1\n",
      "q_loss:  [0.8389648]\n",
      "t:  41  :episode:  1\n",
      "q_loss:  [0.5760597]\n",
      "t:  42  :episode:  1\n",
      "q_loss:  [0.44682723]\n",
      "t:  43  :episode:  1\n",
      "q_loss:  [0.34282178]\n",
      "t:  44  :episode:  1\n",
      "q_loss:  [0.4107732]\n",
      "t:  45  :episode:  1\n",
      "q_loss:  [0.61545736]\n",
      "t:  46  :episode:  1\n",
      "q_loss:  [0.34939033]\n",
      "t:  47  :episode:  1\n",
      "q_loss:  [0.43313223]\n",
      "t:  48  :episode:  1\n",
      "q_loss:  [0.31567904]\n",
      "t:  49  :episode:  1\n",
      "q_loss:  [0.7280864]\n",
      "t:  50  :episode:  1\n",
      "q_loss:  [0.17190954]\n",
      "t:  51  :episode:  1\n",
      "q_loss:  [0.14950116]\n",
      "t:  52  :episode:  1\n",
      "q_loss:  [0.25568587]\n",
      "t:  53  :episode:  1\n",
      "q_loss:  [0.60949194]\n",
      "t:  54  :episode:  1\n",
      "q_loss:  [0.77603817]\n",
      "t:  55  :episode:  1\n",
      "q_loss:  [0.55290085]\n",
      "t:  56  :episode:  1\n",
      "q_loss:  [0.07514915]\n",
      "t:  57  :episode:  1\n",
      "q_loss:  [0.910384]\n",
      "t:  58  :episode:  1\n",
      "q_loss:  [0.04581928]\n",
      "t:  59  :episode:  1\n",
      "q_loss:  [0.36315635]\n",
      "t:  60  :episode:  1\n",
      "q_loss:  [0.2963627]\n",
      "t:  61  :episode:  1\n",
      "q_loss:  [0.4665135]\n",
      "t:  62  :episode:  1\n",
      "q_loss:  [0.25030333]\n",
      "t:  63  :episode:  1\n",
      "q_loss:  [0.51996815]\n",
      "t:  64  :episode:  1\n",
      "q_loss:  [0.12159431]\n",
      "t:  65  :episode:  1\n",
      "q_loss:  [0.34135857]\n",
      "t:  66  :episode:  1\n",
      "q_loss:  [0.19835411]\n",
      "t:  67  :episode:  1\n",
      "q_loss:  [0.272675]\n",
      "t:  68  :episode:  1\n",
      "q_loss:  [0.14411256]\n",
      "t:  69  :episode:  1\n",
      "q_loss:  [0.2905935]\n",
      "t:  70  :episode:  1\n",
      "q_loss:  [0.3902952]\n",
      "t:  71  :episode:  1\n",
      "q_loss:  [0.6105679]\n",
      "t:  72  :episode:  1\n",
      "q_loss:  [0.25840873]\n",
      "t:  73  :episode:  1\n",
      "q_loss:  [0.45688057]\n",
      "t:  74  :episode:  1\n",
      "q_loss:  [0.1304119]\n",
      "t:  75  :episode:  1\n",
      "q_loss:  [0.32167464]\n",
      "t:  76  :episode:  1\n",
      "q_loss:  [0.15435052]\n",
      "t:  77  :episode:  1\n",
      "q_loss:  [0.8041384]\n",
      "t:  78  :episode:  1\n",
      "q_loss:  [0.43499658]\n",
      "t:  79  :episode:  1\n",
      "q_loss:  [0.13607267]\n",
      "t:  80  :episode:  1\n",
      "q_loss:  [0.98645806]\n",
      "t:  81  :episode:  1\n",
      "q_loss:  [0.16729333]\n",
      "t:  82  :episode:  1\n",
      "q_loss:  [0.09233374]\n",
      "t:  83  :episode:  1\n",
      "q_loss:  [0.304331]\n",
      "t:  84  :episode:  1\n",
      "q_loss:  [0.35287428]\n",
      "t:  85  :episode:  1\n",
      "q_loss:  [0.03018147]\n",
      "t:  86  :episode:  1\n",
      "q_loss:  [0.6375965]\n",
      "t:  87  :episode:  1\n",
      "q_loss:  [0.88021374]\n",
      "t:  88  :episode:  1\n",
      "q_loss:  [0.7071164]\n",
      "t:  89  :episode:  1\n",
      "q_loss:  [0.4008066]\n",
      "t:  90  :episode:  1\n",
      "q_loss:  [0.21612214]\n",
      "t:  91  :episode:  1\n",
      "q_loss:  [0.48860478]\n",
      "t:  92  :episode:  1\n",
      "q_loss:  [0.29526275]\n",
      "t:  93  :episode:  1\n",
      "q_loss:  [0.2299313]\n",
      "t:  94  :episode:  1\n",
      "q_loss:  [0.4859361]\n",
      "t:  95  :episode:  1\n",
      "q_loss:  [0.11895935]\n",
      "t:  96  :episode:  1\n",
      "q_loss:  [0.32299381]\n",
      "t:  97  :episode:  1\n",
      "q_loss:  [0.1718415]\n",
      "t:  98  :episode:  1\n",
      "q_loss:  [0.09652639]\n",
      "t:  99  :episode:  1\n",
      "q_loss:  [0.36327252]\n",
      "t:  100  :episode:  1\n",
      "q_loss:  [0.31958833]\n",
      "t:  101  :episode:  1\n",
      "q_loss:  [0.71640354]\n",
      "t:  102  :episode:  1\n",
      "q_loss:  [0.19337173]\n",
      "t:  103  :episode:  1\n",
      "q_loss:  [0.23904665]\n",
      "t:  104  :episode:  1\n",
      "q_loss:  [1.2929008]\n",
      "t:  105  :episode:  1\n",
      "q_loss:  [0.27588436]\n",
      "t:  106  :episode:  1\n",
      "q_loss:  [0.47318128]\n",
      "t:  107  :episode:  1\n",
      "q_loss:  [0.3144316]\n",
      "t:  108  :episode:  1\n",
      "q_loss:  [0.5253436]\n",
      "t:  109  :episode:  1\n",
      "q_loss:  [0.05889013]\n",
      "t:  110  :episode:  1\n",
      "q_loss:  [0.5368874]\n",
      "t:  111  :episode:  1\n",
      "q_loss:  [0.48760715]\n",
      "t:  112  :episode:  1\n",
      "q_loss:  [0.37775946]\n",
      "t:  113  :episode:  1\n",
      "q_loss:  [0.4208544]\n",
      "t:  114  :episode:  1\n",
      "q_loss:  [0.5189233]\n",
      "t:  115  :episode:  1\n",
      "q_loss:  [0.43565273]\n",
      "t:  116  :episode:  1\n",
      "q_loss:  [0.31024164]\n",
      "t:  117  :episode:  1\n",
      "q_loss:  [0.4282916]\n",
      "t:  118  :episode:  1\n",
      "q_loss:  [0.11293575]\n",
      "t:  119  :episode:  1\n",
      "q_loss:  [0.19785704]\n",
      "t:  120  :episode:  1\n",
      "q_loss:  [0.20081776]\n",
      "t:  121  :episode:  1\n",
      "q_loss:  [0.6130972]\n",
      "t:  122  :episode:  1\n",
      "q_loss:  [0.5388938]\n",
      "t:  123  :episode:  1\n",
      "q_loss:  [0.7254552]\n",
      "t:  124  :episode:  1\n",
      "q_loss:  [0.37880576]\n",
      "t:  125  :episode:  1\n",
      "q_loss:  [0.07230667]\n",
      "t:  126  :episode:  1\n",
      "q_loss:  [0.5166155]\n",
      "t:  127  :episode:  1\n",
      "q_loss:  [0.40073574]\n",
      "t:  128  :episode:  1\n",
      "q_loss:  [0.60477173]\n",
      "t:  129  :episode:  1\n",
      "q_loss:  [0.16461986]\n",
      "t:  130  :episode:  1\n",
      "q_loss:  [0.2697137]\n",
      "t:  131  :episode:  1\n",
      "q_loss:  [0.49360585]\n",
      "t:  132  :episode:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [0.13579398]\n",
      "t:  133  :episode:  1\n",
      "q_loss:  [0.60538244]\n",
      "t:  134  :episode:  1\n",
      "q_loss:  [0.51041114]\n",
      "t:  135  :episode:  1\n",
      "q_loss:  [0.26611742]\n",
      "t:  136  :episode:  1\n",
      "q_loss:  [0.3463731]\n",
      "t:  137  :episode:  1\n",
      "q_loss:  [0.18610097]\n",
      "t:  138  :episode:  1\n",
      "q_loss:  [1.1074718]\n",
      "t:  139  :episode:  1\n",
      "q_loss:  [0.61795425]\n",
      "t:  140  :episode:  1\n",
      "q_loss:  [0.46850124]\n",
      "t:  141  :episode:  1\n",
      "q_loss:  [0.13682176]\n",
      "t:  142  :episode:  1\n",
      "q_loss:  [0.18108419]\n",
      "t:  143  :episode:  1\n",
      "q_loss:  [0.24007142]\n",
      "t:  144  :episode:  1\n",
      "q_loss:  [0.17772272]\n",
      "t:  145  :episode:  1\n",
      "q_loss:  [0.20282932]\n",
      "t:  146  :episode:  1\n",
      "q_loss:  [0.16051169]\n",
      "t:  147  :episode:  1\n",
      "q_loss:  [0.8172749]\n",
      "t:  148  :episode:  1\n",
      "q_loss:  [0.07862176]\n",
      "t:  149  :episode:  1\n",
      "q_loss:  [0.52075195]\n",
      "t:  150  :episode:  1\n",
      "q_loss:  [0.3820443]\n",
      "t:  151  :episode:  1\n",
      "q_loss:  [0.4118479]\n",
      "t:  152  :episode:  1\n",
      "q_loss:  [0.13151468]\n",
      "t:  153  :episode:  1\n",
      "q_loss:  [0.61805016]\n",
      "t:  154  :episode:  1\n",
      "q_loss:  [0.5197213]\n",
      "t:  155  :episode:  1\n",
      "q_loss:  [0.4382266]\n",
      "t:  156  :episode:  1\n",
      "q_loss:  [0.26171958]\n",
      "t:  157  :episode:  1\n",
      "q_loss:  [0.5027562]\n",
      "t:  158  :episode:  1\n",
      "q_loss:  [0.7418934]\n",
      "t:  159  :episode:  1\n",
      "q_loss:  [0.13125333]\n",
      "t:  160  :episode:  1\n",
      "q_loss:  [0.3547609]\n",
      "t:  161  :episode:  1\n",
      "q_loss:  [0.11040253]\n",
      "t:  162  :episode:  1\n",
      "q_loss:  [0.34657422]\n",
      "t:  163  :episode:  1\n",
      "q_loss:  [0.9204921]\n",
      "t:  164  :episode:  1\n",
      "q_loss:  [0.1337889]\n",
      "t:  165  :episode:  1\n",
      "q_loss:  [0.05332223]\n",
      "t:  166  :episode:  1\n",
      "q_loss:  [0.55268395]\n",
      "t:  167  :episode:  1\n",
      "q_loss:  [0.09443898]\n",
      "t:  168  :episode:  1\n",
      "q_loss:  [0.74509734]\n",
      "t:  169  :episode:  1\n",
      "q_loss:  [0.6788326]\n",
      "t:  170  :episode:  1\n",
      "q_loss:  [0.12605263]\n",
      "t:  171  :episode:  1\n",
      "q_loss:  [0.74091566]\n",
      "t:  172  :episode:  1\n",
      "q_loss:  [0.14196336]\n",
      "t:  173  :episode:  1\n",
      "q_loss:  [0.6633741]\n",
      "t:  174  :episode:  1\n",
      "q_loss:  [0.28954706]\n",
      "t:  175  :episode:  1\n",
      "q_loss:  [0.31514993]\n",
      "t:  176  :episode:  1\n",
      "q_loss:  [0.17830189]\n",
      "t:  177  :episode:  1\n",
      "q_loss:  [1.0778975]\n",
      "t:  178  :episode:  1\n",
      "q_loss:  [0.2309241]\n",
      "t:  179  :episode:  1\n",
      "q_loss:  [0.07678937]\n",
      "t:  180  :episode:  1\n",
      "q_loss:  [0.46610314]\n",
      "t:  181  :episode:  1\n",
      "q_loss:  [0.17012122]\n",
      "t:  182  :episode:  1\n",
      "q_loss:  [0.09170972]\n",
      "t:  183  :episode:  1\n",
      "q_loss:  [0.08504853]\n",
      "t:  184  :episode:  1\n",
      "q_loss:  [0.35264716]\n",
      "t:  185  :episode:  1\n",
      "q_loss:  [0.42356643]\n",
      "t:  186  :episode:  1\n",
      "q_loss:  [0.5215654]\n",
      "t:  187  :episode:  1\n",
      "q_loss:  [0.17575143]\n",
      "t:  188  :episode:  1\n",
      "q_loss:  [0.78281474]\n",
      "t:  189  :episode:  1\n",
      "q_loss:  [0.36651722]\n",
      "t:  190  :episode:  1\n",
      "q_loss:  [0.1965867]\n",
      "t:  191  :episode:  1\n",
      "q_loss:  [0.6135359]\n",
      "t:  192  :episode:  1\n",
      "q_loss:  [0.4974593]\n",
      "t:  193  :episode:  1\n",
      "q_loss:  [0.16442402]\n",
      "t:  194  :episode:  1\n",
      "q_loss:  [0.05044291]\n",
      "t:  195  :episode:  1\n",
      "q_loss:  [0.62094605]\n",
      "t:  196  :episode:  1\n",
      "q_loss:  [1.2483919]\n",
      "t:  197  :episode:  1\n",
      "q_loss:  [0.53046817]\n",
      "t:  198  :episode:  1\n",
      "q_loss:  [0.48743922]\n",
      "t:  199  :episode:  1\n",
      "q_loss:  [0.39199638]\n",
      "t:  200  :episode:  1\n",
      "q_loss:  [0.6420619]\n",
      "t:  201  :episode:  1\n",
      "q_loss:  [0.18725526]\n",
      "t:  202  :episode:  1\n",
      "q_loss:  [0.20183164]\n",
      "t:  203  :episode:  1\n",
      "q_loss:  [0.7978932]\n",
      "t:  204  :episode:  1\n",
      "q_loss:  [0.22863679]\n",
      "t:  205  :episode:  1\n",
      "q_loss:  [0.09002703]\n",
      "t:  206  :episode:  1\n",
      "q_loss:  [0.19419438]\n",
      "t:  207  :episode:  1\n",
      "q_loss:  [0.2507312]\n",
      "t:  208  :episode:  1\n",
      "q_loss:  [0.82016987]\n",
      "t:  209  :episode:  1\n",
      "q_loss:  [0.29934227]\n",
      "t:  210  :episode:  1\n",
      "q_loss:  [0.44082284]\n",
      "t:  211  :episode:  1\n",
      "q_loss:  [0.24403125]\n",
      "t:  212  :episode:  1\n",
      "q_loss:  [0.13679671]\n",
      "t:  213  :episode:  1\n",
      "q_loss:  [0.26986262]\n",
      "t:  214  :episode:  1\n",
      "q_loss:  [0.4551551]\n",
      "t:  215  :episode:  1\n",
      "q_loss:  [0.39729816]\n",
      "t:  216  :episode:  1\n",
      "q_loss:  [0.36002117]\n",
      "t:  217  :episode:  1\n",
      "q_loss:  [0.06035715]\n",
      "t:  218  :episode:  1\n",
      "q_loss:  [0.4791304]\n",
      "t:  219  :episode:  1\n",
      "q_loss:  [0.8189695]\n",
      "t:  220  :episode:  1\n",
      "q_loss:  [0.09744704]\n",
      "t:  221  :episode:  1\n",
      "q_loss:  [0.4017807]\n",
      "t:  222  :episode:  1\n",
      "q_loss:  [0.40950093]\n",
      "t:  223  :episode:  1\n",
      "q_loss:  [0.28198534]\n",
      "t:  224  :episode:  1\n",
      "q_loss:  [0.23392847]\n",
      "t:  225  :episode:  1\n",
      "q_loss:  [0.14504024]\n",
      "t:  226  :episode:  1\n",
      "q_loss:  [0.04394772]\n",
      "t:  227  :episode:  1\n",
      "q_loss:  [0.7545551]\n",
      "t:  228  :episode:  1\n",
      "q_loss:  [0.63819575]\n",
      "t:  229  :episode:  1\n",
      "q_loss:  [0.5691742]\n",
      "t:  230  :episode:  1\n",
      "q_loss:  [0.17620338]\n",
      "t:  231  :episode:  1\n",
      "q_loss:  [0.3353981]\n",
      "t:  232  :episode:  1\n",
      "q_loss:  [0.34558702]\n",
      "t:  233  :episode:  1\n",
      "q_loss:  [0.44468445]\n",
      "t:  234  :episode:  1\n",
      "q_loss:  [0.08323158]\n",
      "t:  235  :episode:  1\n",
      "q_loss:  [0.7107513]\n",
      "t:  236  :episode:  1\n",
      "q_loss:  [0.43575677]\n",
      "t:  237  :episode:  1\n",
      "q_loss:  [0.77540046]\n",
      "t:  238  :episode:  1\n",
      "q_loss:  [0.18478656]\n",
      "t:  239  :episode:  1\n",
      "q_loss:  [0.2580719]\n",
      "t:  240  :episode:  1\n",
      "q_loss:  [0.7673578]\n",
      "t:  241  :episode:  1\n",
      "q_loss:  [0.4188075]\n",
      "t:  242  :episode:  1\n",
      "q_loss:  [0.21471772]\n",
      "t:  243  :episode:  1\n",
      "q_loss:  [0.24711655]\n",
      "t:  244  :episode:  1\n",
      "q_loss:  [0.6260307]\n",
      "t:  245  :episode:  1\n",
      "q_loss:  [0.24813312]\n",
      "t:  246  :episode:  1\n",
      "q_loss:  [0.23104292]\n",
      "t:  247  :episode:  1\n",
      "q_loss:  [0.33670944]\n",
      "t:  248  :episode:  1\n",
      "q_loss:  [0.17291835]\n",
      "t:  249  :episode:  1\n",
      "q_loss:  [0.45405138]\n",
      "t:  250  :episode:  1\n",
      "q_loss:  [0.2543793]\n",
      "t:  251  :episode:  1\n",
      "q_loss:  [0.10603209]\n",
      "t:  252  :episode:  1\n",
      "q_loss:  [0.43849215]\n",
      "t:  253  :episode:  1\n",
      "q_loss:  [0.15391053]\n",
      "t:  254  :episode:  1\n",
      "q_loss:  [0.11729521]\n",
      "t:  255  :episode:  1\n",
      "q_loss:  [0.96044827]\n",
      "t:  256  :episode:  1\n",
      "q_loss:  [0.3294791]\n",
      "t:  257  :episode:  1\n",
      "q_loss:  [0.3921757]\n",
      "t:  258  :episode:  1\n",
      "q_loss:  [0.2577314]\n",
      "t:  259  :episode:  1\n",
      "q_loss:  [0.57048535]\n",
      "t:  260  :episode:  1\n",
      "q_loss:  [0.57224625]\n",
      "t:  261  :episode:  1\n",
      "q_loss:  [0.7081969]\n",
      "t:  262  :episode:  1\n",
      "q_loss:  [0.36478516]\n",
      "t:  263  :episode:  1\n",
      "q_loss:  [0.437637]\n",
      "t:  264  :episode:  1\n",
      "q_loss:  [0.23737586]\n",
      "t:  265  :episode:  1\n",
      "q_loss:  [0.6188821]\n",
      "t:  266  :episode:  1\n",
      "q_loss:  [0.45871925]\n",
      "t:  267  :episode:  1\n",
      "q_loss:  [0.26259208]\n",
      "t:  268  :episode:  1\n",
      "q_loss:  [0.12423214]\n",
      "t:  269  :episode:  1\n",
      "q_loss:  [0.37114945]\n",
      "t:  270  :episode:  1\n",
      "q_loss:  [0.27024296]\n",
      "t:  271  :episode:  1\n",
      "q_loss:  [0.48142606]\n",
      "t:  272  :episode:  1\n",
      "q_loss:  [0.1658751]\n",
      "t:  273  :episode:  1\n",
      "q_loss:  [0.2247186]\n",
      "t:  274  :episode:  1\n",
      "q_loss:  [0.89432585]\n",
      "t:  275  :episode:  1\n",
      "q_loss:  [0.5593475]\n",
      "t:  276  :episode:  1\n",
      "q_loss:  [0.6625891]\n",
      "t:  277  :episode:  1\n",
      "q_loss:  [0.04085851]\n",
      "t:  278  :episode:  1\n",
      "q_loss:  [0.17088787]\n",
      "t:  279  :episode:  1\n",
      "q_loss:  [0.12441652]\n",
      "t:  280  :episode:  1\n",
      "q_loss:  [0.4370528]\n",
      "t:  281  :episode:  1\n",
      "q_loss:  [0.7712202]\n",
      "t:  282  :episode:  1\n",
      "q_loss:  [0.5608334]\n",
      "t:  283  :episode:  1\n",
      "q_loss:  [0.25926906]\n",
      "t:  284  :episode:  1\n",
      "q_loss:  [0.47401324]\n",
      "t:  285  :episode:  1\n",
      "q_loss:  [0.13197905]\n",
      "t:  286  :episode:  1\n",
      "q_loss:  [0.6151508]\n",
      "t:  287  :episode:  1\n",
      "q_loss:  [0.5498048]\n",
      "t:  288  :episode:  1\n",
      "q_loss:  [0.32002664]\n",
      "t:  289  :episode:  1\n",
      "q_loss:  [0.75140536]\n",
      "t:  290  :episode:  1\n",
      "q_loss:  [0.4310425]\n",
      "t:  291  :episode:  1\n",
      "q_loss:  [0.2012777]\n",
      "t:  292  :episode:  1\n",
      "q_loss:  [0.17765512]\n",
      "t:  293  :episode:  1\n",
      "q_loss:  [0.15312389]\n",
      "t:  294  :episode:  1\n",
      "q_loss:  [0.18633983]\n",
      "t:  295  :episode:  1\n",
      "q_loss:  [0.82537377]\n",
      "t:  296  :episode:  1\n",
      "q_loss:  [0.07734969]\n",
      "t:  297  :episode:  1\n",
      "q_loss:  [0.28545615]\n",
      "t:  298  :episode:  1\n",
      "q_loss:  [1.3446779]\n",
      "t:  299  :episode:  1\n",
      "q_loss:  [0.19328952]\n",
      "t:  300  :episode:  1\n",
      "q_loss:  [0.15047798]\n",
      "t:  301  :episode:  1\n",
      "q_loss:  [0.26178676]\n",
      "t:  302  :episode:  1\n",
      "q_loss:  [0.3141158]\n",
      "t:  303  :episode:  1\n",
      "q_loss:  [0.8599832]\n",
      "t:  304  :episode:  1\n",
      "q_loss:  [0.11739495]\n",
      "t:  305  :episode:  1\n",
      "q_loss:  [0.678597]\n",
      "t:  306  :episode:  1\n",
      "q_loss:  [0.54697096]\n",
      "t:  307  :episode:  1\n",
      "q_loss:  [0.46392095]\n",
      "t:  308  :episode:  1\n",
      "q_loss:  [0.25655273]\n",
      "t:  309  :episode:  1\n",
      "q_loss:  [0.41079596]\n",
      "t:  310  :episode:  1\n",
      "q_loss:  [0.4574581]\n",
      "t:  311  :episode:  1\n",
      "q_loss:  [0.503848]\n",
      "t:  312  :episode:  1\n",
      "q_loss:  [0.9129704]\n",
      "t:  313  :episode:  1\n",
      "q_loss:  [0.284895]\n",
      "t:  314  :episode:  1\n",
      "q_loss:  [0.33981103]\n",
      "t:  315  :episode:  1\n",
      "q_loss:  [0.2987901]\n",
      "t:  316  :episode:  1\n",
      "q_loss:  [0.12137407]\n",
      "t:  317  :episode:  1\n",
      "q_loss:  [0.37447345]\n",
      "t:  318  :episode:  1\n",
      "q_loss:  [0.6037286]\n",
      "t:  319  :episode:  1\n",
      "q_loss:  [0.18714516]\n",
      "t:  320  :episode:  1\n",
      "q_loss:  [0.11738353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  321  :episode:  1\n",
      "q_loss:  [0.22546533]\n",
      "t:  322  :episode:  1\n",
      "q_loss:  [0.07973889]\n",
      "t:  323  :episode:  1\n",
      "q_loss:  [0.61611754]\n",
      "t:  324  :episode:  1\n",
      "q_loss:  [0.07907166]\n",
      "t:  325  :episode:  1\n",
      "q_loss:  [0.08194745]\n",
      "t:  326  :episode:  1\n",
      "q_loss:  [0.36794034]\n",
      "t:  327  :episode:  1\n",
      "q_loss:  [0.23961729]\n",
      "t:  328  :episode:  1\n",
      "q_loss:  [0.3833275]\n",
      "t:  329  :episode:  1\n",
      "q_loss:  [0.6760115]\n",
      "t:  330  :episode:  1\n",
      "q_loss:  [0.27335662]\n",
      "t:  331  :episode:  1\n",
      "q_loss:  [0.41202325]\n",
      "t:  332  :episode:  1\n",
      "q_loss:  [0.2569252]\n",
      "t:  333  :episode:  1\n",
      "q_loss:  [0.14954343]\n",
      "t:  334  :episode:  1\n",
      "q_loss:  [0.9347825]\n",
      "t:  335  :episode:  1\n",
      "q_loss:  [0.55682194]\n",
      "t:  336  :episode:  1\n",
      "q_loss:  [0.4666738]\n",
      "t:  337  :episode:  1\n",
      "q_loss:  [0.34631392]\n",
      "t:  338  :episode:  1\n",
      "q_loss:  [0.38662428]\n",
      "t:  339  :episode:  1\n",
      "q_loss:  [0.45384267]\n",
      "t:  340  :episode:  1\n",
      "q_loss:  [0.7072009]\n",
      "t:  341  :episode:  1\n",
      "q_loss:  [0.2177468]\n",
      "t:  342  :episode:  1\n",
      "q_loss:  [0.27221435]\n",
      "t:  343  :episode:  1\n",
      "q_loss:  [0.718436]\n",
      "t:  344  :episode:  1\n",
      "q_loss:  [0.9390101]\n",
      "t:  345  :episode:  1\n",
      "q_loss:  [0.10331278]\n",
      "t:  346  :episode:  1\n",
      "q_loss:  [0.38851678]\n",
      "t:  347  :episode:  1\n",
      "q_loss:  [0.12000589]\n",
      "t:  348  :episode:  1\n",
      "q_loss:  [0.16206068]\n",
      "t:  349  :episode:  1\n",
      "q_loss:  [0.13184378]\n",
      "t:  350  :episode:  1\n",
      "q_loss:  [0.42451602]\n",
      "t:  351  :episode:  1\n",
      "q_loss:  [0.2330122]\n",
      "t:  352  :episode:  1\n",
      "q_loss:  [0.16317141]\n",
      "t:  353  :episode:  1\n",
      "q_loss:  [0.39426994]\n",
      "t:  354  :episode:  1\n",
      "q_loss:  [0.1712223]\n",
      "t:  355  :episode:  1\n",
      "q_loss:  [0.24948275]\n",
      "t:  356  :episode:  1\n",
      "q_loss:  [0.41921288]\n",
      "t:  357  :episode:  1\n",
      "q_loss:  [0.07216926]\n",
      "t:  358  :episode:  1\n",
      "q_loss:  [0.5548377]\n",
      "t:  359  :episode:  1\n",
      "q_loss:  [0.54803413]\n",
      "t:  360  :episode:  1\n",
      "q_loss:  [0.531264]\n",
      "t:  361  :episode:  1\n",
      "q_loss:  [0.07955795]\n",
      "t:  362  :episode:  1\n",
      "q_loss:  [0.33291692]\n",
      "t:  363  :episode:  1\n",
      "q_loss:  [0.53419137]\n",
      "t:  364  :episode:  1\n",
      "q_loss:  [0.18169414]\n",
      "t:  365  :episode:  1\n",
      "q_loss:  [0.11014792]\n",
      "t:  366  :episode:  1\n",
      "q_loss:  [0.52353895]\n",
      "t:  367  :episode:  1\n",
      "q_loss:  [0.09153463]\n",
      "t:  368  :episode:  1\n",
      "q_loss:  [0.21287313]\n",
      "t:  369  :episode:  1\n",
      "q_loss:  [0.5363748]\n",
      "t:  370  :episode:  1\n",
      "q_loss:  [0.19838554]\n",
      "t:  371  :episode:  1\n",
      "q_loss:  [0.48090672]\n",
      "t:  372  :episode:  1\n",
      "q_loss:  [0.4394811]\n",
      "t:  373  :episode:  1\n",
      "q_loss:  [0.4874015]\n",
      "t:  374  :episode:  1\n",
      "q_loss:  [0.20395046]\n",
      "t:  375  :episode:  1\n",
      "q_loss:  [0.0411997]\n",
      "t:  376  :episode:  1\n",
      "q_loss:  [0.13475773]\n",
      "t:  377  :episode:  1\n",
      "q_loss:  [0.5114969]\n",
      "t:  378  :episode:  1\n",
      "q_loss:  [0.06715398]\n",
      "t:  379  :episode:  1\n",
      "q_loss:  [0.46272057]\n",
      "t:  380  :episode:  1\n",
      "q_loss:  [0.57696813]\n",
      "t:  381  :episode:  1\n",
      "q_loss:  [0.43361837]\n",
      "t:  382  :episode:  1\n",
      "q_loss:  [0.3616355]\n",
      "t:  383  :episode:  1\n",
      "q_loss:  [0.4690324]\n",
      "t:  384  :episode:  1\n",
      "q_loss:  [0.10108049]\n",
      "t:  385  :episode:  1\n",
      "q_loss:  [0.5640595]\n",
      "t:  386  :episode:  1\n",
      "q_loss:  [0.5201898]\n",
      "t:  387  :episode:  1\n",
      "q_loss:  [0.2903465]\n",
      "t:  388  :episode:  1\n",
      "q_loss:  [0.9828953]\n",
      "t:  389  :episode:  1\n",
      "q_loss:  [0.71299005]\n",
      "t:  390  :episode:  1\n",
      "q_loss:  [0.11387775]\n",
      "t:  391  :episode:  1\n",
      "q_loss:  [0.37075877]\n",
      "t:  392  :episode:  1\n",
      "q_loss:  [0.33312118]\n",
      "t:  393  :episode:  1\n",
      "q_loss:  [0.3851239]\n",
      "t:  394  :episode:  1\n",
      "q_loss:  [0.21889576]\n",
      "t:  395  :episode:  1\n",
      "q_loss:  [0.38757825]\n",
      "t:  396  :episode:  1\n",
      "q_loss:  [0.9247346]\n",
      "t:  397  :episode:  1\n",
      "q_loss:  [0.3306256]\n",
      "t:  398  :episode:  1\n",
      "q_loss:  [0.04331109]\n",
      "t:  399  :episode:  1\n",
      "q_loss:  [0.72815835]\n",
      "t:  400  :episode:  1\n",
      "q_loss:  [0.49804896]\n",
      "t:  401  :episode:  1\n",
      "q_loss:  [0.4698638]\n",
      "t:  402  :episode:  1\n",
      "q_loss:  [0.30858743]\n",
      "t:  403  :episode:  1\n",
      "q_loss:  [0.47885972]\n",
      "t:  404  :episode:  1\n",
      "q_loss:  [0.5553771]\n",
      "t:  405  :episode:  1\n",
      "q_loss:  [0.86109585]\n",
      "t:  406  :episode:  1\n",
      "q_loss:  [0.4590318]\n",
      "t:  407  :episode:  1\n",
      "q_loss:  [0.4704328]\n",
      "t:  408  :episode:  1\n",
      "q_loss:  [0.2330505]\n",
      "t:  409  :episode:  1\n",
      "q_loss:  [0.84826684]\n",
      "t:  410  :episode:  1\n",
      "q_loss:  [0.7889516]\n",
      "t:  411  :episode:  1\n",
      "q_loss:  [0.89410293]\n",
      "t:  412  :episode:  1\n",
      "q_loss:  [0.04511297]\n",
      "t:  413  :episode:  1\n",
      "q_loss:  [0.32471362]\n",
      "t:  414  :episode:  1\n",
      "q_loss:  [0.7117554]\n",
      "t:  415  :episode:  1\n",
      "q_loss:  [0.46811247]\n",
      "t:  416  :episode:  1\n",
      "q_loss:  [0.8123785]\n",
      "t:  417  :episode:  1\n",
      "q_loss:  [0.41016138]\n",
      "t:  418  :episode:  1\n",
      "q_loss:  [0.536021]\n",
      "t:  419  :episode:  1\n",
      "q_loss:  [0.8311695]\n",
      "t:  420  :episode:  1\n",
      "q_loss:  [0.23199502]\n",
      "t:  421  :episode:  1\n",
      "q_loss:  [0.47606024]\n",
      "t:  422  :episode:  1\n",
      "q_loss:  [0.07019362]\n",
      "t:  423  :episode:  1\n",
      "q_loss:  [0.43202722]\n",
      "t:  424  :episode:  1\n",
      "q_loss:  [0.33780023]\n",
      "t:  425  :episode:  1\n",
      "q_loss:  [0.05578449]\n",
      "t:  426  :episode:  1\n",
      "q_loss:  [0.5961958]\n",
      "t:  427  :episode:  1\n",
      "q_loss:  [0.34805417]\n",
      "t:  428  :episode:  1\n",
      "q_loss:  [0.5470077]\n",
      "t:  429  :episode:  1\n",
      "q_loss:  [0.14334649]\n",
      "t:  430  :episode:  1\n",
      "q_loss:  [0.3064444]\n",
      "t:  431  :episode:  1\n",
      "q_loss:  [1.1659253]\n",
      "t:  432  :episode:  1\n",
      "q_loss:  [0.12848076]\n",
      "t:  433  :episode:  1\n",
      "q_loss:  [0.22169214]\n",
      "t:  434  :episode:  1\n",
      "q_loss:  [0.18688358]\n",
      "t:  435  :episode:  1\n",
      "q_loss:  [0.19650358]\n",
      "t:  436  :episode:  1\n",
      "q_loss:  [0.20475015]\n",
      "t:  437  :episode:  1\n",
      "q_loss:  [0.27127135]\n",
      "t:  438  :episode:  1\n",
      "q_loss:  [0.33540213]\n",
      "t:  439  :episode:  1\n",
      "q_loss:  [0.17031533]\n",
      "t:  440  :episode:  1\n",
      "q_loss:  [0.2565007]\n",
      "t:  441  :episode:  1\n",
      "q_loss:  [0.7699505]\n",
      "t:  442  :episode:  1\n",
      "q_loss:  [0.3160008]\n",
      "t:  443  :episode:  1\n",
      "q_loss:  [0.4557779]\n",
      "t:  444  :episode:  1\n",
      "q_loss:  [0.24451533]\n",
      "t:  445  :episode:  1\n",
      "q_loss:  [0.28502005]\n",
      "t:  446  :episode:  1\n",
      "q_loss:  [0.14035727]\n",
      "t:  447  :episode:  1\n",
      "q_loss:  [0.1859839]\n",
      "t:  448  :episode:  1\n",
      "q_loss:  [0.2118332]\n",
      "t:  449  :episode:  1\n",
      "q_loss:  [0.26749292]\n",
      "t:  450  :episode:  1\n",
      "q_loss:  [0.10704075]\n",
      "t:  451  :episode:  1\n",
      "q_loss:  [0.0436056]\n",
      "t:  452  :episode:  1\n",
      "q_loss:  [0.15039384]\n",
      "t:  453  :episode:  1\n",
      "q_loss:  [0.21543077]\n",
      "t:  454  :episode:  1\n",
      "q_loss:  [0.57377696]\n",
      "t:  455  :episode:  1\n",
      "q_loss:  [0.8961091]\n",
      "t:  456  :episode:  1\n",
      "q_loss:  [0.27303952]\n",
      "t:  457  :episode:  1\n",
      "q_loss:  [0.49163538]\n",
      "t:  458  :episode:  1\n",
      "q_loss:  [0.03936517]\n",
      "t:  459  :episode:  1\n",
      "q_loss:  [0.4792139]\n",
      "t:  460  :episode:  1\n",
      "q_loss:  [0.23332676]\n",
      "t:  461  :episode:  1\n",
      "q_loss:  [0.18308163]\n",
      "t:  462  :episode:  1\n",
      "q_loss:  [0.5489663]\n",
      "t:  463  :episode:  1\n",
      "q_loss:  [0.9646338]\n",
      "t:  464  :episode:  1\n",
      "q_loss:  [1.4143417]\n",
      "t:  465  :episode:  1\n",
      "q_loss:  [0.3446361]\n",
      "t:  466  :episode:  1\n",
      "q_loss:  [0.12089055]\n",
      "t:  467  :episode:  1\n",
      "q_loss:  [0.37738314]\n",
      "t:  468  :episode:  1\n",
      "q_loss:  [0.6095402]\n",
      "t:  469  :episode:  1\n",
      "q_loss:  [0.18713571]\n",
      "t:  470  :episode:  1\n",
      "q_loss:  [0.16489603]\n",
      "t:  471  :episode:  1\n",
      "q_loss:  [0.5945405]\n",
      "t:  472  :episode:  1\n",
      "q_loss:  [0.13434884]\n",
      "t:  473  :episode:  1\n",
      "q_loss:  [0.22117597]\n",
      "t:  474  :episode:  1\n",
      "q_loss:  [0.09901311]\n",
      "t:  475  :episode:  1\n",
      "q_loss:  [0.5047859]\n",
      "t:  476  :episode:  1\n",
      "q_loss:  [0.20112467]\n",
      "t:  477  :episode:  1\n",
      "q_loss:  [0.38503113]\n",
      "t:  478  :episode:  1\n",
      "q_loss:  [0.6217201]\n",
      "t:  479  :episode:  1\n",
      "q_loss:  [0.2859432]\n",
      "t:  480  :episode:  1\n",
      "q_loss:  [0.3377406]\n",
      "t:  481  :episode:  1\n",
      "q_loss:  [0.5021857]\n",
      "t:  482  :episode:  1\n",
      "q_loss:  [0.32193372]\n",
      "t:  483  :episode:  1\n",
      "q_loss:  [0.87716603]\n",
      "t:  484  :episode:  1\n",
      "q_loss:  [0.9377276]\n",
      "t:  485  :episode:  1\n",
      "q_loss:  [0.1429563]\n",
      "t:  486  :episode:  1\n",
      "q_loss:  [0.0675693]\n",
      "t:  487  :episode:  1\n",
      "q_loss:  [0.61206967]\n",
      "t:  488  :episode:  1\n",
      "q_loss:  [0.443641]\n",
      "t:  489  :episode:  1\n",
      "q_loss:  [0.15753815]\n",
      "t:  490  :episode:  1\n",
      "q_loss:  [0.8251859]\n",
      "t:  491  :episode:  1\n",
      "q_loss:  [0.17561653]\n",
      "t:  492  :episode:  1\n",
      "q_loss:  [0.5973803]\n",
      "t:  493  :episode:  1\n",
      "q_loss:  [0.39738452]\n",
      "t:  494  :episode:  1\n",
      "q_loss:  [0.18933587]\n",
      "t:  495  :episode:  1\n",
      "q_loss:  [0.07413658]\n",
      "t:  496  :episode:  1\n",
      "q_loss:  [0.20023802]\n",
      "t:  497  :episode:  1\n",
      "q_loss:  [1.1258122]\n",
      "t:  498  :episode:  1\n",
      "q_loss:  [0.46594265]\n",
      "t:  499  :episode:  1\n",
      "q_loss:  [0.3992713]\n",
      "t:  500  :episode:  1\n",
      "q_loss:  [0.14724118]\n",
      "t:  501  :episode:  1\n",
      "q_loss:  [0.3482384]\n",
      "t:  502  :episode:  1\n",
      "q_loss:  [0.29992598]\n",
      "t:  503  :episode:  1\n",
      "q_loss:  [1.0437018]\n",
      "t:  504  :episode:  1\n",
      "q_loss:  [0.47233945]\n",
      "t:  505  :episode:  1\n",
      "q_loss:  [0.24269566]\n",
      "t:  506  :episode:  1\n",
      "q_loss:  [0.13632892]\n",
      "t:  507  :episode:  1\n",
      "q_loss:  [0.68026197]\n",
      "t:  508  :episode:  1\n",
      "q_loss:  [0.97689515]\n",
      "t:  509  :episode:  1\n",
      "q_loss:  [0.20936412]\n",
      "t:  510  :episode:  1\n",
      "q_loss:  [0.04185807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  511  :episode:  1\n",
      "q_loss:  [0.25367188]\n",
      "t:  512  :episode:  1\n",
      "q_loss:  [0.39077935]\n",
      "t:  513  :episode:  1\n",
      "q_loss:  [0.31286287]\n",
      "t:  514  :episode:  1\n",
      "q_loss:  [0.81115115]\n",
      "t:  515  :episode:  1\n",
      "q_loss:  [0.10181616]\n",
      "t:  516  :episode:  1\n",
      "q_loss:  [0.55512816]\n",
      "t:  517  :episode:  1\n",
      "q_loss:  [0.80285555]\n",
      "t:  518  :episode:  1\n",
      "q_loss:  [0.4079432]\n",
      "t:  519  :episode:  1\n",
      "q_loss:  [0.5706248]\n",
      "t:  520  :episode:  1\n",
      "q_loss:  [0.18004008]\n",
      "t:  521  :episode:  1\n",
      "q_loss:  [0.0852764]\n",
      "t:  522  :episode:  1\n",
      "q_loss:  [0.36275542]\n",
      "t:  523  :episode:  1\n",
      "q_loss:  [0.32539034]\n",
      "t:  524  :episode:  1\n",
      "q_loss:  [0.3497417]\n",
      "t:  525  :episode:  1\n",
      "q_loss:  [0.5181731]\n",
      "t:  526  :episode:  1\n",
      "q_loss:  [0.27144665]\n",
      "t:  527  :episode:  1\n",
      "q_loss:  [0.473222]\n",
      "t:  528  :episode:  1\n",
      "q_loss:  [0.09718169]\n",
      "t:  529  :episode:  1\n",
      "q_loss:  [0.1721015]\n",
      "t:  530  :episode:  1\n",
      "q_loss:  [0.42503732]\n",
      "t:  531  :episode:  1\n",
      "q_loss:  [0.70542085]\n",
      "t:  532  :episode:  1\n",
      "q_loss:  [0.14951164]\n",
      "t:  533  :episode:  1\n",
      "q_loss:  [0.5372667]\n",
      "t:  534  :episode:  1\n",
      "q_loss:  [0.8696413]\n",
      "t:  535  :episode:  1\n",
      "q_loss:  [0.27142733]\n",
      "t:  536  :episode:  1\n",
      "q_loss:  [0.9632984]\n",
      "t:  537  :episode:  1\n",
      "q_loss:  [0.71098155]\n",
      "t:  538  :episode:  1\n",
      "q_loss:  [0.46907106]\n",
      "t:  539  :episode:  1\n",
      "q_loss:  [0.15187612]\n",
      "t:  540  :episode:  1\n",
      "q_loss:  [0.28766143]\n",
      "t:  541  :episode:  1\n",
      "q_loss:  [0.44598156]\n",
      "t:  542  :episode:  1\n",
      "q_loss:  [0.04974978]\n",
      "t:  543  :episode:  1\n",
      "q_loss:  [0.49837568]\n",
      "t:  544  :episode:  1\n",
      "q_loss:  [0.20827845]\n",
      "t:  545  :episode:  1\n",
      "q_loss:  [0.34021857]\n",
      "t:  546  :episode:  1\n",
      "q_loss:  [0.21600628]\n",
      "t:  547  :episode:  1\n",
      "q_loss:  [1.0019468]\n",
      "t:  548  :episode:  1\n",
      "q_loss:  [0.16061705]\n",
      "t:  549  :episode:  1\n",
      "q_loss:  [0.22234595]\n",
      "t:  550  :episode:  1\n",
      "q_loss:  [0.609614]\n",
      "t:  551  :episode:  1\n",
      "q_loss:  [0.29216108]\n",
      "t:  552  :episode:  1\n",
      "q_loss:  [0.21309036]\n",
      "t:  553  :episode:  1\n",
      "q_loss:  [0.5868692]\n",
      "t:  554  :episode:  1\n",
      "q_loss:  [0.5333187]\n",
      "t:  555  :episode:  1\n",
      "q_loss:  [0.16679345]\n",
      "t:  556  :episode:  1\n",
      "q_loss:  [0.6622186]\n",
      "t:  557  :episode:  1\n",
      "q_loss:  [0.2470488]\n",
      "t:  558  :episode:  1\n",
      "q_loss:  [0.67766505]\n",
      "t:  559  :episode:  1\n",
      "q_loss:  [0.22868165]\n",
      "t:  560  :episode:  1\n",
      "q_loss:  [0.8191879]\n",
      "t:  561  :episode:  1\n",
      "q_loss:  [0.09955111]\n",
      "t:  562  :episode:  1\n",
      "q_loss:  [0.20038927]\n",
      "t:  563  :episode:  1\n",
      "q_loss:  [0.16991797]\n",
      "t:  564  :episode:  1\n",
      "q_loss:  [0.23225588]\n",
      "t:  565  :episode:  1\n",
      "q_loss:  [0.454532]\n",
      "t:  566  :episode:  1\n",
      "q_loss:  [0.6368085]\n",
      "t:  567  :episode:  1\n",
      "q_loss:  [0.13032866]\n",
      "t:  568  :episode:  1\n",
      "q_loss:  [0.17412055]\n",
      "t:  569  :episode:  1\n",
      "q_loss:  [0.23477769]\n",
      "t:  570  :episode:  1\n",
      "q_loss:  [1.071499]\n",
      "t:  571  :episode:  1\n",
      "q_loss:  [0.26880622]\n",
      "t:  572  :episode:  1\n",
      "q_loss:  [0.41544104]\n",
      "t:  573  :episode:  1\n",
      "q_loss:  [0.5530163]\n",
      "t:  574  :episode:  1\n",
      "q_loss:  [0.4211368]\n",
      "t:  575  :episode:  1\n",
      "q_loss:  [0.8029428]\n",
      "t:  576  :episode:  1\n",
      "q_loss:  [0.7335954]\n",
      "t:  577  :episode:  1\n",
      "q_loss:  [0.33501625]\n",
      "t:  578  :episode:  1\n",
      "q_loss:  [0.25223038]\n",
      "t:  579  :episode:  1\n",
      "q_loss:  [0.4231212]\n",
      "t:  580  :episode:  1\n",
      "q_loss:  [0.7014827]\n",
      "t:  581  :episode:  1\n",
      "q_loss:  [0.47057146]\n",
      "t:  582  :episode:  1\n",
      "q_loss:  [0.27391818]\n",
      "t:  583  :episode:  1\n",
      "q_loss:  [0.16631013]\n",
      "t:  584  :episode:  1\n",
      "q_loss:  [0.3232547]\n",
      "t:  585  :episode:  1\n",
      "q_loss:  [0.59655964]\n",
      "t:  586  :episode:  1\n",
      "q_loss:  [0.82275474]\n",
      "t:  587  :episode:  1\n",
      "q_loss:  [0.17994267]\n",
      "t:  588  :episode:  1\n",
      "q_loss:  [0.73163056]\n",
      "t:  589  :episode:  1\n",
      "q_loss:  [0.21160845]\n",
      "t:  590  :episode:  1\n",
      "q_loss:  [0.7411041]\n",
      "t:  591  :episode:  1\n",
      "q_loss:  [0.06022482]\n",
      "t:  592  :episode:  1\n",
      "q_loss:  [0.78912807]\n",
      "t:  593  :episode:  1\n",
      "q_loss:  [0.6656643]\n",
      "t:  594  :episode:  1\n",
      "q_loss:  [0.6403277]\n",
      "t:  595  :episode:  1\n",
      "q_loss:  [0.2060346]\n",
      "t:  596  :episode:  1\n",
      "q_loss:  [0.2953928]\n",
      "t:  597  :episode:  1\n",
      "q_loss:  [0.07729806]\n",
      "t:  598  :episode:  1\n",
      "q_loss:  [0.09439635]\n",
      "t:  599  :episode:  1\n",
      "q_loss:  [0.18214044]\n",
      "t:  600  :episode:  1\n",
      "q_loss:  [1.0357561]\n",
      "t:  601  :episode:  1\n",
      "q_loss:  [0.39476]\n",
      "t:  602  :episode:  1\n",
      "q_loss:  [0.2442923]\n",
      "t:  603  :episode:  1\n",
      "q_loss:  [0.15985012]\n",
      "t:  604  :episode:  1\n",
      "q_loss:  [0.50022]\n",
      "t:  605  :episode:  1\n",
      "q_loss:  [0.16027048]\n",
      "t:  606  :episode:  1\n",
      "q_loss:  [0.5689739]\n",
      "t:  607  :episode:  1\n",
      "q_loss:  [0.23725386]\n",
      "t:  608  :episode:  1\n",
      "q_loss:  [0.34410658]\n",
      "t:  609  :episode:  1\n",
      "q_loss:  [0.5918372]\n",
      "t:  610  :episode:  1\n",
      "q_loss:  [0.38407338]\n",
      "t:  611  :episode:  1\n",
      "q_loss:  [0.46410328]\n",
      "t:  612  :episode:  1\n",
      "q_loss:  [0.17091203]\n",
      "t:  613  :episode:  1\n",
      "q_loss:  [0.4102256]\n",
      "t:  614  :episode:  1\n",
      "q_loss:  [0.3516376]\n",
      "t:  615  :episode:  1\n",
      "q_loss:  [0.06759676]\n",
      "t:  616  :episode:  1\n",
      "q_loss:  [1.051149]\n",
      "t:  617  :episode:  1\n",
      "q_loss:  [0.18032426]\n",
      "t:  618  :episode:  1\n",
      "q_loss:  [0.16951019]\n",
      "t:  619  :episode:  1\n",
      "q_loss:  [0.6612699]\n",
      "t:  620  :episode:  1\n",
      "q_loss:  [0.14543355]\n",
      "t:  621  :episode:  1\n",
      "q_loss:  [0.21109238]\n",
      "t:  622  :episode:  1\n",
      "q_loss:  [0.31450266]\n",
      "t:  623  :episode:  1\n",
      "q_loss:  [0.07614259]\n",
      "t:  624  :episode:  1\n",
      "q_loss:  [0.23358089]\n",
      "t:  625  :episode:  1\n",
      "q_loss:  [0.17863835]\n",
      "t:  626  :episode:  1\n",
      "q_loss:  [0.26273093]\n",
      "t:  627  :episode:  1\n",
      "q_loss:  [0.3400694]\n",
      "t:  628  :episode:  1\n",
      "q_loss:  [0.68480635]\n",
      "t:  629  :episode:  1\n",
      "q_loss:  [0.09001096]\n",
      "t:  630  :episode:  1\n",
      "q_loss:  [0.220793]\n",
      "t:  631  :episode:  1\n",
      "q_loss:  [0.10906631]\n",
      "t:  632  :episode:  1\n",
      "q_loss:  [0.22787389]\n",
      "t:  633  :episode:  1\n",
      "q_loss:  [0.18990792]\n",
      "t:  634  :episode:  1\n",
      "q_loss:  [0.04918166]\n",
      "t:  635  :episode:  1\n",
      "q_loss:  [0.40921623]\n",
      "t:  636  :episode:  1\n",
      "q_loss:  [0.31557092]\n",
      "t:  637  :episode:  1\n",
      "q_loss:  [0.31529078]\n",
      "t:  638  :episode:  1\n",
      "q_loss:  [0.069637]\n",
      "t:  639  :episode:  1\n",
      "q_loss:  [0.2465137]\n",
      "t:  640  :episode:  1\n",
      "q_loss:  [0.89526165]\n",
      "t:  641  :episode:  1\n",
      "q_loss:  [0.10074328]\n",
      "t:  642  :episode:  1\n",
      "q_loss:  [0.40769526]\n",
      "t:  643  :episode:  1\n",
      "q_loss:  [0.16394176]\n",
      "t:  644  :episode:  1\n",
      "q_loss:  [0.8760558]\n",
      "t:  645  :episode:  1\n",
      "q_loss:  [0.5644914]\n",
      "t:  646  :episode:  1\n",
      "q_loss:  [0.73598605]\n",
      "t:  647  :episode:  1\n",
      "q_loss:  [0.25805205]\n",
      "t:  648  :episode:  1\n",
      "q_loss:  [0.37927115]\n",
      "t:  649  :episode:  1\n",
      "q_loss:  [0.5886408]\n",
      "t:  650  :episode:  1\n",
      "q_loss:  [0.2582889]\n",
      "t:  651  :episode:  1\n",
      "q_loss:  [0.4717378]\n",
      "t:  652  :episode:  1\n",
      "q_loss:  [1.1435223]\n",
      "t:  653  :episode:  1\n",
      "q_loss:  [1.6845621]\n",
      "t:  654  :episode:  1\n",
      "q_loss:  [0.406135]\n",
      "t:  655  :episode:  1\n",
      "q_loss:  [0.23396084]\n",
      "t:  656  :episode:  1\n",
      "q_loss:  [0.13050154]\n",
      "t:  657  :episode:  1\n",
      "q_loss:  [0.7842177]\n",
      "t:  658  :episode:  1\n",
      "q_loss:  [0.2910464]\n",
      "t:  659  :episode:  1\n",
      "q_loss:  [0.40460268]\n",
      "t:  660  :episode:  1\n",
      "q_loss:  [0.19373652]\n",
      "t:  661  :episode:  1\n",
      "q_loss:  [1.1743115]\n",
      "t:  662  :episode:  1\n",
      "q_loss:  [0.12509108]\n",
      "t:  663  :episode:  1\n",
      "q_loss:  [0.1987357]\n",
      "t:  664  :episode:  1\n",
      "q_loss:  [0.95729434]\n",
      "t:  665  :episode:  1\n",
      "q_loss:  [0.17657556]\n",
      "t:  666  :episode:  1\n",
      "q_loss:  [0.5276137]\n",
      "t:  667  :episode:  1\n",
      "q_loss:  [0.1299881]\n",
      "t:  668  :episode:  1\n",
      "q_loss:  [0.26282233]\n",
      "t:  669  :episode:  1\n",
      "q_loss:  [0.8393362]\n",
      "t:  670  :episode:  1\n",
      "q_loss:  [0.23828407]\n",
      "t:  671  :episode:  1\n",
      "q_loss:  [0.14350724]\n",
      "t:  672  :episode:  1\n",
      "q_loss:  [0.12778547]\n",
      "t:  673  :episode:  1\n",
      "q_loss:  [0.30780563]\n",
      "t:  674  :episode:  1\n",
      "q_loss:  [0.6989631]\n",
      "t:  675  :episode:  1\n",
      "q_loss:  [0.8118336]\n",
      "t:  676  :episode:  1\n",
      "q_loss:  [0.7333232]\n",
      "t:  677  :episode:  1\n",
      "q_loss:  [0.42236978]\n",
      "t:  678  :episode:  1\n",
      "q_loss:  [0.69570327]\n",
      "t:  679  :episode:  1\n",
      "q_loss:  [0.2794541]\n",
      "t:  680  :episode:  1\n",
      "q_loss:  [0.530547]\n",
      "t:  681  :episode:  1\n",
      "q_loss:  [0.12646101]\n",
      "t:  682  :episode:  1\n",
      "q_loss:  [0.4530074]\n",
      "t:  683  :episode:  1\n",
      "q_loss:  [0.442488]\n",
      "t:  684  :episode:  1\n",
      "q_loss:  [0.54275006]\n",
      "t:  685  :episode:  1\n",
      "q_loss:  [0.36853734]\n",
      "t:  686  :episode:  1\n",
      "q_loss:  [0.9554684]\n",
      "t:  687  :episode:  1\n",
      "q_loss:  [0.652122]\n",
      "t:  688  :episode:  1\n",
      "q_loss:  [0.68837726]\n",
      "t:  689  :episode:  1\n",
      "q_loss:  [0.05829502]\n",
      "t:  690  :episode:  1\n",
      "q_loss:  [0.787635]\n",
      "t:  691  :episode:  1\n",
      "q_loss:  [0.18967436]\n",
      "t:  692  :episode:  1\n",
      "q_loss:  [0.2589057]\n",
      "t:  693  :episode:  1\n",
      "q_loss:  [1.1548401]\n",
      "t:  694  :episode:  1\n",
      "q_loss:  [0.48508495]\n",
      "t:  695  :episode:  1\n",
      "q_loss:  [0.10013273]\n",
      "t:  696  :episode:  1\n",
      "q_loss:  [0.1238222]\n",
      "t:  697  :episode:  1\n",
      "q_loss:  [0.35094243]\n",
      "t:  698  :episode:  1\n",
      "q_loss:  [0.8616272]\n",
      "t:  699  :episode:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [0.33828676]\n",
      "t:  700  :episode:  1\n",
      "q_loss:  [0.76869154]\n",
      "t:  701  :episode:  1\n",
      "q_loss:  [0.74844706]\n",
      "t:  702  :episode:  1\n",
      "q_loss:  [0.26945886]\n",
      "t:  703  :episode:  1\n",
      "q_loss:  [0.6340186]\n",
      "t:  704  :episode:  1\n",
      "q_loss:  [0.35649568]\n",
      "t:  705  :episode:  1\n",
      "q_loss:  [0.19860683]\n",
      "t:  706  :episode:  1\n",
      "q_loss:  [0.16239345]\n",
      "t:  707  :episode:  1\n",
      "q_loss:  [0.34829617]\n",
      "t:  708  :episode:  1\n",
      "q_loss:  [0.26312923]\n",
      "t:  709  :episode:  1\n",
      "q_loss:  [0.32471576]\n",
      "t:  710  :episode:  1\n",
      "q_loss:  [0.4265706]\n",
      "t:  711  :episode:  1\n",
      "q_loss:  [0.93304473]\n",
      "t:  712  :episode:  1\n",
      "q_loss:  [0.2810093]\n",
      "t:  713  :episode:  1\n",
      "q_loss:  [0.3364042]\n",
      "t:  714  :episode:  1\n",
      "q_loss:  [0.91521776]\n",
      "t:  715  :episode:  1\n",
      "q_loss:  [0.3881004]\n",
      "t:  716  :episode:  1\n",
      "q_loss:  [0.07619562]\n",
      "t:  717  :episode:  1\n",
      "q_loss:  [0.47402877]\n",
      "t:  718  :episode:  1\n",
      "q_loss:  [0.4159404]\n",
      "t:  719  :episode:  1\n",
      "q_loss:  [1.0440333]\n",
      "t:  720  :episode:  1\n",
      "q_loss:  [0.41988936]\n",
      "t:  721  :episode:  1\n",
      "q_loss:  [0.20240188]\n",
      "t:  722  :episode:  1\n",
      "q_loss:  [0.17242129]\n",
      "t:  723  :episode:  1\n",
      "q_loss:  [0.8636459]\n",
      "t:  724  :episode:  1\n",
      "q_loss:  [0.7461703]\n",
      "t:  725  :episode:  1\n",
      "q_loss:  [0.14348133]\n",
      "t:  726  :episode:  1\n",
      "q_loss:  [0.16426936]\n",
      "t:  727  :episode:  1\n",
      "q_loss:  [0.69771993]\n",
      "t:  728  :episode:  1\n",
      "q_loss:  [0.25999779]\n",
      "t:  729  :episode:  1\n",
      "q_loss:  [0.39252043]\n",
      "t:  730  :episode:  1\n",
      "q_loss:  [0.4377162]\n",
      "t:  731  :episode:  1\n",
      "q_loss:  [0.29036012]\n",
      "t:  732  :episode:  1\n",
      "q_loss:  [0.14208241]\n",
      "t:  733  :episode:  1\n",
      "q_loss:  [0.33930224]\n",
      "t:  734  :episode:  1\n",
      "q_loss:  [0.2380516]\n",
      "t:  735  :episode:  1\n",
      "q_loss:  [0.7256157]\n",
      "t:  736  :episode:  1\n",
      "q_loss:  [0.10822348]\n",
      "t:  737  :episode:  1\n",
      "q_loss:  [0.42513043]\n",
      "t:  738  :episode:  1\n",
      "q_loss:  [0.5961523]\n",
      "t:  739  :episode:  1\n",
      "q_loss:  [0.6533104]\n",
      "t:  740  :episode:  1\n",
      "q_loss:  [0.3409018]\n",
      "t:  741  :episode:  1\n",
      "q_loss:  [0.08841348]\n",
      "t:  742  :episode:  1\n",
      "q_loss:  [0.22463359]\n",
      "t:  743  :episode:  1\n",
      "q_loss:  [0.48699033]\n",
      "t:  744  :episode:  1\n",
      "q_loss:  [0.31927305]\n",
      "t:  745  :episode:  1\n",
      "q_loss:  [0.08551742]\n",
      "t:  746  :episode:  1\n",
      "q_loss:  [0.28408667]\n",
      "t:  747  :episode:  1\n",
      "q_loss:  [0.918715]\n",
      "t:  748  :episode:  1\n",
      "q_loss:  [0.16498177]\n",
      "t:  749  :episode:  1\n",
      "q_loss:  [0.31767958]\n",
      "t:  750  :episode:  1\n",
      "q_loss:  [0.6516928]\n",
      "t:  751  :episode:  1\n",
      "q_loss:  [0.43272957]\n",
      "t:  752  :episode:  1\n",
      "q_loss:  [0.52953476]\n",
      "t:  753  :episode:  1\n",
      "q_loss:  [0.16812025]\n",
      "t:  754  :episode:  1\n",
      "q_loss:  [0.44644094]\n",
      "t:  755  :episode:  1\n",
      "q_loss:  [0.12698895]\n",
      "t:  756  :episode:  1\n",
      "q_loss:  [0.27655724]\n",
      "t:  757  :episode:  1\n",
      "q_loss:  [0.71129483]\n",
      "t:  758  :episode:  1\n",
      "q_loss:  [0.72904176]\n",
      "t:  759  :episode:  1\n",
      "q_loss:  [0.20152968]\n",
      "t:  760  :episode:  1\n",
      "q_loss:  [1.329371]\n",
      "t:  761  :episode:  1\n",
      "q_loss:  [0.51766026]\n",
      "t:  762  :episode:  1\n",
      "q_loss:  [0.17962943]\n",
      "t:  763  :episode:  1\n",
      "q_loss:  [0.05727249]\n",
      "t:  764  :episode:  1\n",
      "q_loss:  [0.35586402]\n",
      "t:  765  :episode:  1\n",
      "q_loss:  [0.20465039]\n",
      "t:  766  :episode:  1\n",
      "q_loss:  [0.19562155]\n",
      "t:  767  :episode:  1\n",
      "q_loss:  [0.5049577]\n",
      "t:  768  :episode:  1\n",
      "q_loss:  [0.1368058]\n",
      "t:  769  :episode:  1\n",
      "q_loss:  [0.08356646]\n",
      "t:  770  :episode:  1\n",
      "q_loss:  [0.43493852]\n",
      "t:  771  :episode:  1\n",
      "q_loss:  [0.47367513]\n",
      "t:  772  :episode:  1\n",
      "q_loss:  [0.33212534]\n",
      "t:  773  :episode:  1\n",
      "q_loss:  [0.5316913]\n",
      "t:  774  :episode:  1\n",
      "q_loss:  [0.46813703]\n",
      "t:  775  :episode:  1\n",
      "q_loss:  [0.26211387]\n",
      "t:  776  :episode:  1\n",
      "q_loss:  [0.6183356]\n",
      "t:  777  :episode:  1\n",
      "q_loss:  [0.3091824]\n",
      "t:  778  :episode:  1\n",
      "q_loss:  [0.13075289]\n",
      "t:  779  :episode:  1\n",
      "q_loss:  [0.42935678]\n",
      "t:  780  :episode:  1\n",
      "q_loss:  [0.8574151]\n",
      "t:  781  :episode:  1\n",
      "q_loss:  [0.14140636]\n",
      "t:  782  :episode:  1\n",
      "q_loss:  [0.13287398]\n",
      "t:  783  :episode:  1\n",
      "q_loss:  [0.39082876]\n",
      "t:  784  :episode:  1\n",
      "q_loss:  [0.8320746]\n",
      "t:  785  :episode:  1\n",
      "q_loss:  [0.31847045]\n",
      "t:  786  :episode:  1\n",
      "q_loss:  [0.48891553]\n",
      "t:  787  :episode:  1\n",
      "q_loss:  [0.10649989]\n",
      "t:  788  :episode:  1\n",
      "q_loss:  [0.63843423]\n",
      "t:  789  :episode:  1\n",
      "q_loss:  [0.20760414]\n",
      "t:  790  :episode:  1\n",
      "q_loss:  [0.11896805]\n",
      "t:  791  :episode:  1\n",
      "q_loss:  [0.21770921]\n",
      "t:  792  :episode:  1\n",
      "q_loss:  [0.3852756]\n",
      "t:  793  :episode:  1\n",
      "q_loss:  [0.13802023]\n",
      "t:  794  :episode:  1\n",
      "q_loss:  [0.4199382]\n",
      "t:  795  :episode:  1\n",
      "q_loss:  [0.28777844]\n",
      "t:  796  :episode:  1\n",
      "q_loss:  [0.38843808]\n",
      "t:  797  :episode:  1\n",
      "q_loss:  [0.31362286]\n",
      "t:  798  :episode:  1\n",
      "q_loss:  [0.8448783]\n",
      "t:  799  :episode:  1\n",
      "q_loss:  [0.294496]\n",
      "t:  800  :episode:  1\n",
      "q_loss:  [0.20149526]\n",
      "t:  801  :episode:  1\n",
      "q_loss:  [0.1685904]\n",
      "t:  802  :episode:  1\n",
      "q_loss:  [0.55522954]\n",
      "t:  803  :episode:  1\n",
      "q_loss:  [0.45019826]\n",
      "t:  804  :episode:  1\n",
      "q_loss:  [0.5202739]\n",
      "t:  805  :episode:  1\n",
      "q_loss:  [0.14454882]\n",
      "t:  806  :episode:  1\n",
      "q_loss:  [1.0066743]\n",
      "t:  807  :episode:  1\n",
      "q_loss:  [0.5279506]\n",
      "t:  808  :episode:  1\n",
      "q_loss:  [0.18779491]\n",
      "t:  809  :episode:  1\n",
      "q_loss:  [0.59388393]\n",
      "t:  810  :episode:  1\n",
      "q_loss:  [0.18206778]\n",
      "t:  811  :episode:  1\n",
      "q_loss:  [0.80971843]\n",
      "t:  812  :episode:  1\n",
      "q_loss:  [0.7621014]\n",
      "t:  813  :episode:  1\n",
      "q_loss:  [0.15596816]\n",
      "t:  814  :episode:  1\n",
      "q_loss:  [0.09445149]\n",
      "t:  815  :episode:  1\n",
      "q_loss:  [0.2552827]\n",
      "t:  816  :episode:  1\n",
      "q_loss:  [0.22344765]\n",
      "t:  817  :episode:  1\n",
      "q_loss:  [1.0558583]\n",
      "t:  818  :episode:  1\n",
      "q_loss:  [0.5285787]\n",
      "t:  819  :episode:  1\n",
      "q_loss:  [0.5239647]\n",
      "t:  820  :episode:  1\n",
      "q_loss:  [0.29894]\n",
      "t:  821  :episode:  1\n",
      "q_loss:  [0.17174712]\n",
      "t:  822  :episode:  1\n",
      "q_loss:  [0.48174018]\n",
      "t:  823  :episode:  1\n",
      "q_loss:  [0.8030007]\n",
      "t:  824  :episode:  1\n",
      "q_loss:  [0.51222813]\n",
      "t:  825  :episode:  1\n",
      "q_loss:  [0.6418378]\n",
      "t:  826  :episode:  1\n",
      "q_loss:  [1.0885222]\n",
      "t:  827  :episode:  1\n",
      "q_loss:  [0.25087258]\n",
      "t:  828  :episode:  1\n",
      "q_loss:  [0.58137196]\n",
      "t:  829  :episode:  1\n",
      "q_loss:  [0.5754326]\n",
      "t:  830  :episode:  1\n",
      "q_loss:  [0.6605061]\n",
      "t:  831  :episode:  1\n",
      "q_loss:  [0.15950865]\n",
      "t:  832  :episode:  1\n",
      "q_loss:  [0.37882203]\n",
      "t:  833  :episode:  1\n",
      "q_loss:  [0.10678595]\n",
      "t:  834  :episode:  1\n",
      "q_loss:  [0.5660635]\n",
      "t:  835  :episode:  1\n",
      "q_loss:  [1.6320753]\n",
      "t:  836  :episode:  1\n",
      "q_loss:  [0.08937402]\n",
      "t:  837  :episode:  1\n",
      "q_loss:  [0.32741708]\n",
      "t:  838  :episode:  1\n",
      "q_loss:  [0.751752]\n",
      "t:  839  :episode:  1\n",
      "q_loss:  [0.05969839]\n",
      "t:  840  :episode:  1\n",
      "q_loss:  [0.37530655]\n",
      "t:  841  :episode:  1\n",
      "q_loss:  [0.4208348]\n",
      "t:  842  :episode:  1\n",
      "q_loss:  [0.85665953]\n",
      "t:  843  :episode:  1\n",
      "q_loss:  [0.82713985]\n",
      "t:  844  :episode:  1\n",
      "q_loss:  [0.41843107]\n",
      "t:  845  :episode:  1\n",
      "q_loss:  [0.8505815]\n",
      "t:  846  :episode:  1\n",
      "q_loss:  [0.15448835]\n",
      "t:  847  :episode:  1\n",
      "q_loss:  [0.15819287]\n",
      "t:  848  :episode:  1\n",
      "q_loss:  [0.46337405]\n",
      "t:  849  :episode:  1\n",
      "q_loss:  [0.1748154]\n",
      "t:  850  :episode:  1\n",
      "q_loss:  [0.6278937]\n",
      "t:  851  :episode:  1\n",
      "q_loss:  [0.46964562]\n",
      "t:  852  :episode:  1\n",
      "q_loss:  [0.70772815]\n",
      "t:  853  :episode:  1\n",
      "q_loss:  [0.29236257]\n",
      "t:  854  :episode:  1\n",
      "q_loss:  [0.8792761]\n",
      "t:  855  :episode:  1\n",
      "q_loss:  [0.5011193]\n",
      "t:  856  :episode:  1\n",
      "q_loss:  [0.07525103]\n",
      "t:  857  :episode:  1\n",
      "q_loss:  [0.07755731]\n",
      "t:  858  :episode:  1\n",
      "q_loss:  [1.3804054]\n",
      "t:  859  :episode:  1\n",
      "q_loss:  [0.35639703]\n",
      "t:  860  :episode:  1\n",
      "q_loss:  [0.08734526]\n",
      "t:  861  :episode:  1\n",
      "q_loss:  [0.1399574]\n",
      "t:  862  :episode:  1\n",
      "q_loss:  [0.23642218]\n",
      "t:  863  :episode:  1\n",
      "q_loss:  [0.57661986]\n",
      "t:  864  :episode:  1\n",
      "q_loss:  [0.28830308]\n",
      "t:  865  :episode:  1\n",
      "q_loss:  [0.10509309]\n",
      "t:  866  :episode:  1\n",
      "q_loss:  [0.14326379]\n",
      "t:  867  :episode:  1\n",
      "q_loss:  [0.6763339]\n",
      "t:  868  :episode:  1\n",
      "q_loss:  [0.44182065]\n",
      "t:  869  :episode:  1\n",
      "q_loss:  [0.5233319]\n",
      "t:  870  :episode:  1\n",
      "q_loss:  [0.9954566]\n",
      "t:  871  :episode:  1\n",
      "q_loss:  [0.1699113]\n",
      "t:  872  :episode:  1\n",
      "q_loss:  [0.36701554]\n",
      "t:  873  :episode:  1\n",
      "q_loss:  [0.12815824]\n",
      "t:  874  :episode:  1\n",
      "q_loss:  [0.45905066]\n",
      "t:  875  :episode:  1\n",
      "q_loss:  [1.1275792]\n",
      "t:  876  :episode:  1\n",
      "q_loss:  [0.45170507]\n",
      "t:  877  :episode:  1\n",
      "q_loss:  [0.50074774]\n",
      "t:  878  :episode:  1\n",
      "q_loss:  [0.15516269]\n",
      "t:  879  :episode:  1\n",
      "q_loss:  [0.11706851]\n",
      "t:  880  :episode:  1\n",
      "q_loss:  [0.14796922]\n",
      "t:  881  :episode:  1\n",
      "q_loss:  [0.21190642]\n",
      "t:  882  :episode:  1\n",
      "q_loss:  [0.06506826]\n",
      "t:  883  :episode:  1\n",
      "q_loss:  [0.67868733]\n",
      "t:  884  :episode:  1\n",
      "q_loss:  [0.16777167]\n",
      "t:  885  :episode:  1\n",
      "q_loss:  [0.51884365]\n",
      "t:  886  :episode:  1\n",
      "q_loss:  [0.1883481]\n",
      "t:  887  :episode:  1\n",
      "q_loss:  [0.98533905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  888  :episode:  1\n",
      "q_loss:  [0.25549787]\n",
      "t:  889  :episode:  1\n",
      "q_loss:  [0.1971623]\n",
      "t:  890  :episode:  1\n",
      "q_loss:  [0.45550364]\n",
      "t:  891  :episode:  1\n",
      "q_loss:  [1.7693313]\n",
      "t:  892  :episode:  1\n",
      "q_loss:  [0.36417282]\n",
      "t:  893  :episode:  1\n",
      "q_loss:  [1.1021805]\n",
      "t:  894  :episode:  1\n",
      "q_loss:  [1.1572198]\n",
      "t:  895  :episode:  1\n",
      "q_loss:  [0.92263556]\n",
      "t:  896  :episode:  1\n",
      "q_loss:  [0.04970239]\n",
      "t:  897  :episode:  1\n",
      "q_loss:  [0.7968219]\n",
      "t:  898  :episode:  1\n",
      "q_loss:  [0.16236791]\n",
      "t:  899  :episode:  1\n",
      "q_loss:  [0.17300555]\n",
      "t:  900  :episode:  1\n",
      "q_loss:  [0.20632024]\n",
      "t:  901  :episode:  1\n",
      "q_loss:  [0.32507306]\n",
      "t:  902  :episode:  1\n",
      "q_loss:  [1.9933193]\n",
      "t:  903  :episode:  1\n",
      "q_loss:  [0.22402443]\n",
      "t:  904  :episode:  1\n",
      "q_loss:  [0.406246]\n",
      "t:  905  :episode:  1\n",
      "q_loss:  [1.2910872]\n",
      "t:  906  :episode:  1\n",
      "q_loss:  [0.34480605]\n",
      "t:  907  :episode:  1\n",
      "q_loss:  [1.233081]\n",
      "t:  908  :episode:  1\n",
      "q_loss:  [0.32900137]\n",
      "t:  909  :episode:  1\n",
      "q_loss:  [0.16854987]\n",
      "t:  910  :episode:  1\n",
      "q_loss:  [0.46953112]\n",
      "t:  911  :episode:  1\n",
      "q_loss:  [0.17805575]\n",
      "t:  912  :episode:  1\n",
      "q_loss:  [0.18171744]\n",
      "t:  913  :episode:  1\n",
      "q_loss:  [0.5086271]\n",
      "t:  914  :episode:  1\n",
      "q_loss:  [0.12322722]\n",
      "t:  915  :episode:  1\n",
      "q_loss:  [0.29118007]\n",
      "t:  916  :episode:  1\n",
      "q_loss:  [0.30091554]\n",
      "t:  917  :episode:  1\n",
      "q_loss:  [1.0654902]\n",
      "t:  918  :episode:  1\n",
      "q_loss:  [0.2661745]\n",
      "t:  919  :episode:  1\n",
      "q_loss:  [0.32040837]\n",
      "t:  920  :episode:  1\n",
      "q_loss:  [0.7535044]\n",
      "t:  921  :episode:  1\n",
      "q_loss:  [0.9716124]\n",
      "t:  922  :episode:  1\n",
      "q_loss:  [0.7005575]\n",
      "t:  923  :episode:  1\n",
      "q_loss:  [0.42197824]\n",
      "t:  924  :episode:  1\n",
      "q_loss:  [0.22002855]\n",
      "t:  925  :episode:  1\n",
      "q_loss:  [0.98162293]\n",
      "t:  926  :episode:  1\n",
      "q_loss:  [1.0373819]\n",
      "t:  927  :episode:  1\n",
      "q_loss:  [0.38979736]\n",
      "t:  928  :episode:  1\n",
      "q_loss:  [0.2710789]\n",
      "t:  929  :episode:  1\n",
      "q_loss:  [0.623423]\n",
      "t:  930  :episode:  1\n",
      "q_loss:  [0.77182037]\n",
      "t:  931  :episode:  1\n",
      "q_loss:  [0.820019]\n",
      "t:  932  :episode:  1\n",
      "q_loss:  [0.97878426]\n",
      "t:  933  :episode:  1\n",
      "q_loss:  [0.1301118]\n",
      "t:  934  :episode:  1\n",
      "q_loss:  [0.5753269]\n",
      "t:  935  :episode:  1\n",
      "q_loss:  [0.06038844]\n",
      "t:  936  :episode:  1\n",
      "q_loss:  [1.2546684]\n",
      "t:  937  :episode:  1\n",
      "q_loss:  [0.98383343]\n",
      "t:  938  :episode:  1\n",
      "q_loss:  [0.23347105]\n",
      "t:  939  :episode:  1\n",
      "q_loss:  [0.41320616]\n",
      "t:  940  :episode:  1\n",
      "q_loss:  [0.28626114]\n",
      "t:  941  :episode:  1\n",
      "q_loss:  [0.76532567]\n",
      "t:  942  :episode:  1\n",
      "q_loss:  [0.7246661]\n",
      "t:  943  :episode:  1\n",
      "q_loss:  [0.2166143]\n",
      "t:  944  :episode:  1\n",
      "q_loss:  [0.398108]\n",
      "t:  945  :episode:  1\n",
      "q_loss:  [0.11153552]\n",
      "t:  946  :episode:  1\n",
      "q_loss:  [0.6440433]\n",
      "t:  947  :episode:  1\n",
      "q_loss:  [0.2603511]\n",
      "t:  948  :episode:  1\n",
      "q_loss:  [0.11155525]\n",
      "t:  949  :episode:  1\n",
      "q_loss:  [0.64425766]\n",
      "t:  950  :episode:  1\n",
      "q_loss:  [0.69209826]\n",
      "t:  951  :episode:  1\n",
      "q_loss:  [0.7043241]\n",
      "t:  952  :episode:  1\n",
      "q_loss:  [0.39710915]\n",
      "t:  953  :episode:  1\n",
      "q_loss:  [0.3948418]\n",
      "t:  954  :episode:  1\n",
      "q_loss:  [0.41209066]\n",
      "t:  955  :episode:  1\n",
      "q_loss:  [0.23481521]\n",
      "t:  956  :episode:  1\n",
      "q_loss:  [0.7116171]\n",
      "t:  957  :episode:  1\n",
      "q_loss:  [0.885319]\n",
      "t:  958  :episode:  1\n",
      "q_loss:  [0.15809843]\n",
      "t:  959  :episode:  1\n",
      "q_loss:  [0.36992297]\n",
      "t:  960  :episode:  1\n",
      "q_loss:  [0.49612612]\n",
      "t:  961  :episode:  1\n",
      "q_loss:  [0.35723236]\n",
      "t:  962  :episode:  1\n",
      "q_loss:  [0.4051376]\n",
      "t:  963  :episode:  1\n",
      "q_loss:  [0.47325164]\n",
      "t:  964  :episode:  1\n",
      "q_loss:  [0.32563013]\n",
      "t:  965  :episode:  1\n",
      "q_loss:  [0.49165198]\n",
      "t:  966  :episode:  1\n",
      "q_loss:  [1.0817722]\n",
      "t:  967  :episode:  1\n",
      "q_loss:  [0.10607416]\n",
      "t:  968  :episode:  1\n",
      "q_loss:  [1.7814966]\n",
      "t:  969  :episode:  1\n",
      "q_loss:  [0.2531834]\n",
      "t:  970  :episode:  1\n",
      "q_loss:  [0.3885476]\n",
      "t:  971  :episode:  1\n",
      "q_loss:  [0.2515413]\n",
      "t:  972  :episode:  1\n",
      "q_loss:  [0.34454626]\n",
      "t:  973  :episode:  1\n",
      "q_loss:  [0.09968151]\n",
      "t:  974  :episode:  1\n",
      "q_loss:  [0.38345695]\n",
      "t:  975  :episode:  1\n",
      "q_loss:  [0.70007926]\n",
      "t:  976  :episode:  1\n",
      "q_loss:  [0.09007505]\n",
      "t:  977  :episode:  1\n",
      "q_loss:  [0.53769547]\n",
      "t:  978  :episode:  1\n",
      "q_loss:  [0.222931]\n",
      "t:  979  :episode:  1\n",
      "q_loss:  [0.46716937]\n",
      "t:  980  :episode:  1\n",
      "q_loss:  [1.2377076]\n",
      "t:  981  :episode:  1\n",
      "q_loss:  [0.10168888]\n",
      "t:  982  :episode:  1\n",
      "q_loss:  [0.0729796]\n",
      "t:  983  :episode:  1\n",
      "q_loss:  [0.7354334]\n",
      "t:  984  :episode:  1\n",
      "q_loss:  [0.18620424]\n",
      "t:  985  :episode:  1\n",
      "q_loss:  [0.18210348]\n",
      "t:  986  :episode:  1\n",
      "q_loss:  [0.09207736]\n",
      "t:  987  :episode:  1\n",
      "q_loss:  [0.2495222]\n",
      "t:  988  :episode:  1\n",
      "q_loss:  [0.32569188]\n",
      "t:  989  :episode:  1\n",
      "q_loss:  [0.28157145]\n",
      "t:  990  :episode:  1\n",
      "q_loss:  [0.17971826]\n",
      "t:  991  :episode:  1\n",
      "q_loss:  [0.44163436]\n",
      "t:  992  :episode:  1\n",
      "q_loss:  [0.18816346]\n",
      "t:  993  :episode:  1\n",
      "q_loss:  [0.10371125]\n",
      "t:  994  :episode:  1\n",
      "q_loss:  [0.9184663]\n",
      "t:  995  :episode:  1\n",
      "q_loss:  [0.06871128]\n",
      "t:  996  :episode:  1\n",
      "q_loss:  [0.20955218]\n",
      "t:  997  :episode:  1\n",
      "q_loss:  [0.15928167]\n",
      "t:  998  :episode:  1\n",
      "q_loss:  [0.32002506]\n",
      "t:  999  :episode:  1\n",
      "q_loss:  [0.69468296]\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to rename: ./baseline_model_temp_92295b6cabce4921b49e049ecac00827/part-00001-of-00002.data-00000-of-00001 to: ./baseline_model.data-00001-of-00002 : Access is denied.\r\n; Input/output error [Op:MergeV2Checkpoints]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-410f2283a9a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;31m#rewards[episode] = sumreward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0msac\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'/baseline_model'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Episode {} finished after {} timesteps with reward {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepisode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msumreward\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mwriter_reward\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-93c596bf4ea9>\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    239\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 241\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    242\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_actor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_critic\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave_weights\u001b[1;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[0;32m   1121\u001b[0m              'saved.\\n\\nConsider using a TensorFlow optimizer from `tf.train`.')\n\u001b[0;32m   1122\u001b[0m             % (optimizer,))\n\u001b[1;32m-> 1123\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trackable_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1124\u001b[0m       \u001b[1;31m# Record this checkpoint so it's visible from tf.train.latest_checkpoint.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1125\u001b[0m       checkpoint_management.update_checkpoint_state_internal(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix, checkpoint_number, session)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecursive_create_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m     save_path, new_feed_additions = self._save_cached_when_graph_building(\n\u001b[1;32m-> 1168\u001b[1;33m         file_prefix=file_prefix_tensor, object_graph_tensor=object_graph_tensor)\n\u001b[0m\u001b[0;32m   1169\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m       \u001b[0mfeed_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_feed_additions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\util.py\u001b[0m in \u001b[0;36m_save_cached_when_graph_building\u001b[1;34m(self, file_prefix, object_graph_tensor)\u001b[0m\n\u001b[0;32m   1114\u001b[0m         or context.executing_eagerly() or ops.inside_function()):\n\u001b[0;32m   1115\u001b[0m       \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunctional_saver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDeviceSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnamed_saveable_objects\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1116\u001b[1;33m       \u001b[0msave_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1117\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/cpu:0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1118\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msave_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\training\\saving\\functional_saver.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, file_prefix)\u001b[0m\n\u001b[0;32m    236\u001b[0m         \u001b[1;31m# attempts to delete the temporary directory, \"<user-fed prefix>_temp\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         return gen_io_ops.merge_v2_checkpoints(\n\u001b[1;32m--> 238\u001b[1;33m             sharded_prefixes, file_prefix, delete_old_dirs=True)\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints\u001b[1;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name)\u001b[0m\n\u001b[0;32m    497\u001b[0m         return merge_v2_checkpoints_eager_fallback(\n\u001b[0;32m    498\u001b[0m             \u001b[0mcheckpoint_prefixes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdestination_prefix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m             delete_old_dirs=delete_old_dirs, name=name, ctx=_ctx)\n\u001b[0m\u001b[0;32m    500\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_SymbolicException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m         \u001b[1;32mpass\u001b[0m  \u001b[1;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_io_ops.py\u001b[0m in \u001b[0;36mmerge_v2_checkpoints_eager_fallback\u001b[1;34m(checkpoint_prefixes, destination_prefix, delete_old_dirs, name, ctx)\u001b[0m\n\u001b[0;32m    523\u001b[0m   \u001b[0m_attrs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"delete_old_dirs\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelete_old_dirs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m   _result = _execute.execute(b\"MergeV2Checkpoints\", 0, inputs=_inputs_flat,\n\u001b[1;32m--> 525\u001b[1;33m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0m\u001b[0;32m    526\u001b[0m   \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m: Failed to rename: ./baseline_model_temp_92295b6cabce4921b49e049ecac00827/part-00001-of-00002.data-00000-of-00001 to: ./baseline_model.data-00001-of-00002 : Access is denied.\r\n; Input/output error [Op:MergeV2Checkpoints]"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "sac = SAC(action_space=action_space,\n",
    "          state_space=state_space,\n",
    "          capacity = buffer_size,\n",
    "          batch = batch_size,\n",
    "          tau = 0.999,\n",
    "          gamma = 0.99,\n",
    "          actor_lr = 0.0001,\n",
    "          critic_lr = 0.001,\n",
    "          variance = 0.3)\n",
    "\n",
    "#fill replay buffer\n",
    "env._max_episode_steps = buffer_size\n",
    "sac.replay_buffer.fill_buffer(buffer_size, state, episode_steps) # self,timesteps,state,prev_timesteps\n",
    "env._max_episode_steps = episode_steps\n",
    "\n",
    "\n",
    "env = gym.wrappers.Monitor(env, \"baseline_training\", video_callable=lambda episode: True, force=\"true\")\n",
    "state = env.reset()\n",
    "\n",
    "for episode in range(episodes):\n",
    "    sumreward = 0\n",
    "    for step in range(episode_steps):\n",
    "        #print(observation)\n",
    "        print('t: ',step, ' :episode: ',episode)\n",
    "        #print('state: ',state)\n",
    "        \n",
    "        # get action\n",
    "        state = tf.cast(tf.reshape(state,(1,1,state_space)),dtype='float32')\n",
    "        #print(state)\n",
    "        tensor_action = sac.actor(state)+sac.actor.continous_noise()\n",
    "        action = tensor_action[0][0]\n",
    "        #print('action: ',action)\n",
    "        \n",
    "        #get loss\n",
    "        #q_loss = sac.critic(state,tensor_action)\n",
    "        \n",
    "        \n",
    "        # execute action\n",
    "        next_state, reward, done, info = env.step(action)\n",
    "        sumreward += reward\n",
    "\n",
    "        # store transitions\n",
    "        sac.store_replay(state,next_state,action,reward,done)\n",
    "        \n",
    "        #print('state: ',state)\n",
    "        #print('next_state: ',next_state)\n",
    "        #print('action: ',action)\n",
    "        #print('reward: ',reward)\n",
    "\n",
    "        #sample minibatch from data\n",
    "        states,next_states,actions,rewards,not_done = sac.replay_buffer.sample()\n",
    "        \n",
    "        #set labels y_i\n",
    "        y = sac.set_labels(states,next_states,actions,rewards)\n",
    "        \n",
    "        # update critic net\n",
    "        q_loss = sac.critic.update(states, actions, y)\n",
    "\n",
    "        print('q_loss: ', q_loss[0][0].numpy())\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('Squared QLosses (qtarget - qval)^2', q_loss[0][0][0].numpy(),\n",
    "                              step=episode * episode_steps + step + 1)\n",
    "        \n",
    "        #losses[episode*timesteps + t] = loss\n",
    "        #losses[i_episode*timesteps+] = history.history\n",
    "        \n",
    "        #update actor net\n",
    "        sac.actor.update(states,actions)\n",
    "        #print('weight check: ',rl.actor.get_weights(),'\\n')\n",
    "        \n",
    "        #update target nets\n",
    "        sac.update_target_weights()\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "            #rewards[episode] = sumreward\n",
    "            #sac.save(base_dir+'/baseline_model')\n",
    "            print(\"Episode {} finished after {} timesteps with reward {}\".format(episode,step+1,sumreward))\n",
    "            with writer_reward.as_default():\n",
    "                tf.summary.scalar('Episode sum reward', sumreward,step=episode)\n",
    "            break\n",
    "print('done') \n",
    "sac.save(base_dir+'/baseline_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aFHYhHwRxH6"
   },
   "source": [
    " https://datascience.stackexchange.com/questions/13216/intuitive-explanation-of-noise-contrastive-estimation-nce-loss(InfoNCE Loss )\n",
    "<br>\n",
    "Representation Learning with Contrastive Predictive Coding\n",
    "<br>\n",
    "https://github.com/gdao-research/cpc/blob/master/cpc/data_handler.py (CPC)\n",
    "<br>\n",
    "https://github.com/davidtellez/contrastive-predictive-coding/blob/master/train_model.py (CPC)\n",
    "<br>\n",
    "https://github.com/MishaLaskin/curl/blob/23b0880708c29b078b0a25e62ff31fb587587b18/utils.py#L123 (replay buffer and SAC)\n",
    "<br>\n",
    "https://github.com/marload/DeepRL-TensorFlow2/blob/master/A2C/A2C_Discrete.py (A2C)\n",
    "<br>\n",
    "https://github.com/germain-hug/Deep-RL-Keras/blob/master/A3C/a3c.py (A3C)\n",
    "<br>\n",
    "https://github.com/tensorflow/agents/blob/v0.5.0/tf_agents/agents/sac/sac_agent.py (SAC)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CPCprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:csci-7000-rl] *",
   "language": "python",
   "name": "conda-env-csci-7000-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
