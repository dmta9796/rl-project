{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "z57IXf9q1Ovh",
    "outputId": "1b2cbade-88b2-48d7-b64c-3ab7d29c1715"
   },
   "outputs": [],
   "source": [
    "# if colab\n",
    "\n",
    "# !pip install pybullet\n",
    "# !pip install gym\n",
    "# !apt-get install python-opengl -y\n",
    "# !apt install xvfb -y\n",
    "# !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
    "# !pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3t8ezUpd1SIy"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np \n",
    "import gym\n",
    "from gym import logger as gymlogger\n",
    "from gym.wrappers import Monitor\n",
    "import pybullet_envs\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import math\n",
    "import glob\n",
    "import io\n",
    "import base64\n",
    "from IPython.display import HTML\n",
    "from IPython import display as ipythondisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "y0_9dbk8Cbnv",
    "outputId": "4cdb116a-5cec-4456-dc79-f07bb48d9fe3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 654765645\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "# check if GPU\n",
    "tf.config.list_physical_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "hG1Ruv5FCgDv",
    "outputId": "4fe5a6b2-b4e6-4241-e5ca-c412cf4637a7"
   },
   "outputs": [],
   "source": [
    "# colab\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# root_dir = \"drive/My Drive/\"\n",
    "# base_dir = root_dir + 'CPCtesting'\n",
    "# os.makedirs(base_dir,exist_ok=True)\n",
    "\n",
    "# train_dir = base_dir + '/train'\n",
    "# os.makedirs(train_dir,exist_ok=True)\n",
    "\n",
    "# model_dir = base_dir + '/model'\n",
    "# os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "# if local machine\n",
    "base_dir = os.getcwd()\n",
    "\n",
    "train_dir = os.path.join(base_dir , 'train')\n",
    "os.makedirs(train_dir,exist_ok=True)\n",
    "\n",
    "model_dir = os.path.join(base_dir , 'model')\n",
    "os.makedirs(model_dir,exist_ok=True)\n",
    "\n",
    "# logs_base_dir = os.path.join(base_dir , 'logs')\n",
    "\n",
    "log_dir = os.path.join(base_dir , 'training_logs_save')\n",
    "reward_dir = os.path.join(base_dir , 'training_rewards_save')\n",
    "\n",
    "#remove old logs\n",
    "fileList1 = glob.glob(os.path.join(log_dir , \"events.*\"))\n",
    "fileList2 = glob.glob(os.path.join(reward_dir , \"events.*\"))\n",
    "\n",
    "for filePath in fileList1:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except:\n",
    "        print(\"Error while deleting file : \", filePath)\n",
    "        \n",
    "for filePath in fileList2:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except:\n",
    "        print(\"Error while deleting file : \", filePath)\n",
    "\n",
    "\n",
    "# tensorboard directories\n",
    "# %load_ext tensorboard\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "os.makedirs(reward_dir,exist_ok=True)\n",
    "# %tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWEWANi66t_w"
   },
   "outputs": [],
   "source": [
    "# get data\n",
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oIKY-VyC1bsu"
   },
   "outputs": [],
   "source": [
    "class CPCModel(tf.keras.Model):\n",
    "    def __init__(self,code_size, predict_terms, terms=4, units=256, image_size=64, channels=3):\n",
    "        super(CPCModel, self).__init__()\n",
    "        self.code_size = code_size\n",
    "        self.predict_terms = predict_terms\n",
    "        self.terms = terms\n",
    "        self.units = units\n",
    "        self.image_size = image_size\n",
    "        self.channels = channels\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu1 = tf.keras.layers.LeakyReLU()\n",
    "        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu2 = tf.keras.layers.LeakyReLU()\n",
    "        self.conv3 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu3 = tf.keras.layers.LeakyReLU()\n",
    "        self.conv4 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, strides=2, activation='linear')\n",
    "        self.bn4 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu4 = tf.keras.layers.LeakyReLU()\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.dense5 = tf.keras.layers.Dense(units=256, activation='linear')\n",
    "        self.bn5 = tf.keras.layers.BatchNormalization()\n",
    "        self.lrelu5 = tf.keras.layers.LeakyReLU()\n",
    "        self.dense6 = tf.keras.layers.Dense(units=code_size, activation='linear', name='encoder_embedding')\n",
    "\n",
    "        self.gru = tf.keras.layers.GRU(units, return_sequences=False, name='ar_context')\n",
    "        self.linear = tf.keras.layers.Dense(predict_terms*code_size, activation='linear')    \n",
    "   \n",
    "    def encoding(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.lrelu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.lrelu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.lrelu3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = self.lrelu4(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = self.lrelu5(x)\n",
    "        z = self.dense6(x)\n",
    "        return z\n",
    "  \n",
    "    def get_context(self, x):\n",
    "        z = self.encoding(x)\n",
    "        z = tf.reshape(z, [-1, self.terms, self.code_size])\n",
    "        c = self.gru(z)\n",
    "        return c\n",
    "    def get_prediction(self, x):\n",
    "        c = self.get_context(x)\n",
    "        z_hats = self.linear(c)\n",
    "        z_hat = tf.reshape(z_hats, [-1, self.predict_terms, self.code_size])\n",
    "        return z_hat\n",
    "\n",
    "    def optimizer(self):\n",
    "        pass\n",
    "\n",
    "    def loss(self,weights,biases,labels,inputs,num_samples,num_classes): \n",
    "        loss = tf.nn.nce_loss(\n",
    "        weights, biases, labels, inputs, num_sampled, num_classes, num_true=1,\n",
    "        sampled_values=None, remove_accidental_hits=False, name='nce_loss')\n",
    "        return loss\n",
    "  \n",
    "    def call(self,inputs):\n",
    "        x_tm, x_tp = inputs\n",
    "        x_tm = tf.reshape(x_tm, [-1, self.image_size, self.image_size, self.channels])\n",
    "        x_tp = tf.reshape(x_tp, [-1, self.image_size, self.image_size, self.channels])\n",
    "        z_hat = self.get_prediction(x_tm)\n",
    "        z_tp = self.encoding(x_tp)\n",
    "        z_tp = tf.reshape(z_tp, [-1, self.predict_terms, self.code_size])\n",
    "        dot_prods = tf.reduce_mean(tf.reduce_mean(z_hat*z_tp, axis=-1), axis=-1, keepdims=True)\n",
    "        probs = tf.sigmoid(dot_prods)\n",
    "        return probs\n",
    "\n",
    "\n",
    "  # def save(self):\n",
    "  #       f1 = os.path.join(folder,'target_actor')\n",
    "  #       f2 = os.path.join(folder, 'target_critic')\n",
    "  #       f3 = os.path.join(folder, 'actor')\n",
    "  #       f4 = os.path.join(folder, 'critic')\n",
    "  #       self.target_actor.save(f1)\n",
    "  #       self.target_critic.save(f2)\n",
    "  #       self.actor.save(f3)\n",
    "  #       self.critic.save(f4)\n",
    "\n",
    "\n",
    "  # def load(self):\n",
    "  #   pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wW6bj9SJkd20"
   },
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self,state_space,action_space,capacity,batch):\n",
    "        self.capacity = capacity\n",
    "        self.batch = batch\n",
    "        self.elements = 0\n",
    "        \n",
    "        self.avaliable_batch = 0\n",
    "        self.idx = 0\n",
    "        self.entries = 0 \n",
    "        \n",
    "        self.states = np.empty((self.capacity,state_space),dtype = np.float32)\n",
    "        self.next_states = np.empty((self.capacity,state_space),dtype = np.float32)\n",
    "        self.actions = np.empty((self.capacity,action_space),dtype = np.float32)\n",
    "        self.rewards = np.empty((self.capacity,1),dtype = np.float32)\n",
    "        self.not_dones = np.empty((self.capacity, 1), dtype=np.float32)\n",
    "        \n",
    "    def add(self,state,next_state,action,reward,done):\n",
    "        np.copyto(self.states[self.idx], state)\n",
    "        np.copyto(self.actions[self.idx], action)\n",
    "        np.copyto(self.rewards[self.idx], reward)\n",
    "        np.copyto(self.next_states[self.idx], next_state)\n",
    "        np.copyto(self.not_dones[self.idx], not done)\n",
    "        #self.avaliable_batch= (self.avaliable_batch + 1) if self.avaliable_batch < self.batch else self.batch\n",
    "        #self.entries = (self.entries + 1) if self.entries < self.capacity else self.capacity\n",
    "        self.idx = (self.idx + 1) % self.capacity\n",
    "        self.entries = np.minimum(self.entries + 1, self.capacity)\n",
    "        \n",
    "    def sample(self):\n",
    "        num = self.entries\n",
    "        if(num > self.batch):\n",
    "            num = self.batch\n",
    "        #print('avaliable_batch: ',self.avaliable_batch, \"entries: \", self.entries,'capacity: ', self.capacity)\n",
    "        idx = np.random.choice(self.entries,size = num,replace=False)\n",
    "        #print('test idx: ', idx)\n",
    "        \n",
    "        states = tf.convert_to_tensor(self.states[idx])\n",
    "        next_states = tf.convert_to_tensor(self.next_states[idx])\n",
    "        actions = tf.convert_to_tensor(self.actions[idx])\n",
    "        rewards = tf.convert_to_tensor(self.rewards[idx])\n",
    "        not_dones = tf.convert_to_tensor(self.not_dones[idx])\n",
    "        \n",
    "        return states,next_states,actions,rewards,not_dones\n",
    "    \n",
    "    def fill_buffer(self,timesteps,state,prev_timesteps):\n",
    "        print('sim test: ',env._max_episode_steps,\":\",timesteps)\n",
    "        for step in range(timesteps):\n",
    "            action = env.action_space.sample()\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            np.copyto(self.states[step], state)\n",
    "            np.copyto(self.actions[step], action)\n",
    "            np.copyto(self.rewards[step], reward)\n",
    "            np.copyto(self.next_states[step], next_state)\n",
    "            np.copyto(self.not_dones[step], not done)\n",
    "            state = next_state\n",
    "            if(done):\n",
    "                print(\"step: \", step)\n",
    "                state = env.reset()\n",
    "                print('done seeding replay buffer')            \n",
    "            \n",
    "        \n",
    "\n",
    "class Actor(tf.keras.Model):\n",
    "    def __init__(self,state_space,action_space,critic,actor_lr = 0.001,variance = 0.2):\n",
    "        super(Actor,self).__init__()\n",
    "        \n",
    "        #params\n",
    "        self.std = np.sqrt(variance)\n",
    "        self.noise_flag = 1.0\n",
    "        self.action_space = action_space\n",
    "        \n",
    "        #optimizer\n",
    "        self.opt = tf.keras.optimizers.Adam(actor_lr)\n",
    "        self.critic = critic\n",
    "       \n",
    "        #model\n",
    "        self.dense1 = tf.keras.layers.Dense(400,\n",
    "                                            #input_shape = (1,1,state_space),\n",
    "                                            activation = 'relu',\n",
    "                                            #bias_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003),\n",
    "                                            bias_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                     mode='fan_in', \n",
    "                                                                                                     distribution='uniform', \n",
    "                                                                                                     seed=seed\n",
    "                                                                                                    ),\n",
    "                                            kernel_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                       mode='fan_in', \n",
    "                                                                                                       distribution='uniform', \n",
    "                                                                                                       seed=seed)\n",
    "                                           )\n",
    "        self.dense2 = tf.keras.layers.Dense(300,\n",
    "                                            activation='relu',\n",
    "                                            #bias_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003),\n",
    "                                            bias_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                       mode='fan_in', \n",
    "                                                                                                       distribution='uniform', \n",
    "                                                                                                       seed=seed),\n",
    "                                            kernel_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                       mode='fan_in', \n",
    "                                                                                                       distribution='uniform', \n",
    "                                                                                                       seed=seed)\n",
    "                                            )\n",
    "        self.dense3 = tf.keras.layers.Dense(self.action_space,\n",
    "                                            bias_initializer = tf.random_uniform_initializer(minval=-0.003, \n",
    "                                                                                             maxval=0.003,\n",
    "                                                                                             seed = seed\n",
    "                                                                                            ),\n",
    "                                            kernel_initializer = tf.random_uniform_initializer(minval=-0.003, \n",
    "                                                                                               maxval=0.003,\n",
    "                                                                                               seed = seed\n",
    "                                                                                              )\n",
    "                                           )\n",
    "        \n",
    "    def loss(self,states,actions):\n",
    "        actions = self(states)\n",
    "        #stateactions = tf.concat([states,actions],-1)\n",
    "        #print(\"state,action shape: \",states.shape,actions.shape)\n",
    "        Q = self.critic(states,actions)\n",
    "        loss = - tf.reduce_mean(Q)\n",
    "        return loss\n",
    "    \n",
    "    def update(self,states,actions):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss(states,actions)\n",
    "\n",
    "        grad = tape.gradient(loss,self.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grad, self.trainable_variables))\n",
    "        #print('actor loss: ', loss ,\"\\n\" )\n",
    "        return loss\n",
    "    \n",
    "    def set_noise_flag(self,num):\n",
    "        self.noise_flag = np.float32(not not num)\n",
    "    \n",
    "    def continous_noise(self):\n",
    "        #num = np.random.normal(0,self.std)\n",
    "        #result = np.full((self.action_space,),num)\n",
    "        result = np.random.normal(0,self.std,size=(self.action_space,))\n",
    "        return self.noise_flag * np.clip(result,a_min = -1.0, a_max = 1.0)\n",
    "    \n",
    "    def call(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "    def __init__(self,combined_space,critic_lr = 0.001):\n",
    "        super(Critic,self).__init__()\n",
    "        \n",
    "        # optimizer\n",
    "        self.opt = tf.keras.optimizers.Adam(critic_lr)\n",
    "        \n",
    "        # loss\n",
    "        #self.loss = tf.keras.losses.MSE\n",
    "        \n",
    "        \n",
    "        # layers\n",
    "        self.dense1 = tf.keras.layers.Dense(400,\n",
    "                                            #input_shape=(1,1,combined_space),\n",
    "                                            activation = 'relu',\n",
    "                                            #bias_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003),\n",
    "                                            bias_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                     mode='fan_in', \n",
    "                                                                                                     distribution='uniform', \n",
    "                                                                                                     seed=seed\n",
    "                                                                                                    ),\n",
    "                                            kernel_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                       mode='fan_in', \n",
    "                                                                                                       distribution='uniform', \n",
    "                                                                                                       seed=seed),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                                           )\n",
    "\n",
    "        self.dense2 = tf.keras.layers.Dense(300,\n",
    "                                            activation='relu',\n",
    "                                            #bias_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003),\n",
    "                                            bias_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                     mode='fan_in', \n",
    "                                                                                                     distribution='uniform', \n",
    "                                                                                                     seed=seed\n",
    "                                                                                                    ),\n",
    "                                            kernel_initializer = tf.keras.initializers.VarianceScaling(scale=1.0, \n",
    "                                                                                                       mode='fan_in', \n",
    "                                                                                                       distribution='uniform', \n",
    "                                                                                                       seed=seed\n",
    "                                                                                                      ),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                                            )\n",
    "        self.dense3 = tf.keras.layers.Dense(1,\n",
    "                                            bias_initializer = tf.random_uniform_initializer(minval=-0.003, maxval=0.003),\n",
    "                                            kernel_initializer = tf.random_uniform_initializer(minval=-0.003, \n",
    "                                                                                               maxval=0.003,\n",
    "                                                                                               seed = seed\n",
    "                                                                                              ),\n",
    "                                            kernel_regularizer=tf.keras.regularizers.l2(0.01)\n",
    "                                            ) \n",
    "        \n",
    "    #loss\n",
    "    def loss(self,actual,pred):\n",
    "        result = tf.keras.losses.MSE(actual,pred)\n",
    "        #print('result: ', result)\n",
    "        #print('actual: ', actual.shape) # shape (16,1)\n",
    "        #print('pred: ',pred.shape) # shape (16,1,1,1)\n",
    "        return result\n",
    "    \n",
    "    def update(self,states_i,actions_i,Q_h):\n",
    "        match = Q_h.shape[0]\n",
    "        with tf.GradientTape() as tape:\n",
    "            Q = self.call(states_i,actions_i)\n",
    "            Q = tf.reshape(Q,(1,1,1,match))\n",
    "            Q_h = tf.reshape(Q_h,(1,1,1,match))\n",
    "            loss = self.loss(Q,Q_h)\n",
    "\n",
    "        grad = tape.gradient(loss,self.trainable_variables)\n",
    "        #grad_magnitude = tf.reduce_sum(grad)\n",
    "        self.opt.apply_gradients(zip(grad, self.trainable_variables))\n",
    "        #print('critic loss: ', loss ,\"\\n\" )\n",
    "        #print(\"check exploding gradient: \", grad)\n",
    "        return loss\n",
    "    \n",
    "    #predict\n",
    "    def call(self,states,actions):\n",
    "        #x = tf.concat([states,actions],-1)\n",
    "        x = self.dense1(states)\n",
    "        x = tf.concat([x,actions],-1)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dense3(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class SAC(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 state_space,\n",
    "                 action_space,\n",
    "                 capacity = 1000,\n",
    "                 batch = 1, \n",
    "                 tau=0.999,\n",
    "                 gamma=0.99,\n",
    "                 actor_lr = 0.001, \n",
    "                 critic_lr = 0.0001,\n",
    "                 variance = 1.0):\n",
    "        super(SAC,self).__init__()\n",
    "        # tensorboard callbacks\n",
    "        self.cb = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=1/3, patience=2, min_lr=1e-4),\n",
    "                   tf.keras.callbacks.ModelCheckpoint('weights/weights.{epoch:02d}-{val_binary_accuracy:.2f}.cpkt',\n",
    "                                          monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True),\n",
    "                   tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3),\n",
    "                   tf.keras.callbacks.TensorBoard()]\n",
    "        \n",
    "        \n",
    "        #hyperparameters\n",
    "        self.batch = batch\n",
    "        self.tau = tau\n",
    "        self.gamma = gamma\n",
    "        self.actor_lr = actor_lr\n",
    "        self.critic_lr = critic_lr\n",
    "        self.noise_flag = 1\n",
    "        self.std = np.sqrt(variance)\n",
    "        \n",
    "        \n",
    "        #spaces\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.combined_space = self.action_space + self.state_space\n",
    "        \n",
    "        # replay buffer\n",
    "        self.replay_buffer = ReplayBuffer(self.state_space,self.action_space,capacity,self.batch)\n",
    "        \n",
    "        # models\n",
    "        self.critic = Critic(combined_space = self.combined_space,\n",
    "                             critic_lr = critic_lr\n",
    "                            )        \n",
    "        self.actor = Actor(self.state_space,\n",
    "                           self.action_space,\n",
    "                           actor_lr=actor_lr,\n",
    "                           critic = self.critic\n",
    "                          )\n",
    "        #self.critic.compile(optimizer = self.critic.opt,loss = self.critic.loss)\n",
    "        #self.actor.compile(optimizer = self.actor.opt,loss = self.actor.loss)\n",
    "        \n",
    "        # target models\n",
    "        self.target_actor = Actor(self.state_space,\n",
    "                                  self.action_space,\n",
    "                                  actor_lr=actor_lr,\n",
    "                                  critic = self.critic\n",
    "                                 )\n",
    "        self.target_critic = Critic(combined_space = self.combined_space,\n",
    "                                    critic_lr = critic_lr\n",
    "                                   )         \n",
    "        self.target_actor.set_weights(self.actor.get_weights())\n",
    "        self.target_critic.set_weights(self.critic.get_weights())\n",
    "        \n",
    "        #cpc\n",
    "        #self.cpc = CPC(code_size=128, predict_terms=4, terms=4, units=256, image_size=64, channels=3)\n",
    "    \n",
    "    def store_replay(self,state,next_state,action,reward,done):\n",
    "        self.replay_buffer.add(state,next_state,action,reward,done)\n",
    "    \n",
    "    def set_labels(self,states_i,next_states_i,actions_i,rewards_i,terminal_i):\n",
    "        mu = self.target_actor(next_states_i)\n",
    "        #print('ends: ', terminal)\n",
    "        #print(mu,states)\n",
    "#         stateactions = tf.concat([states,mu],1)\n",
    "        Q_h = self.target_critic(next_states_i,mu)\n",
    "        y = rewards_i + terminal_i*self.gamma * Q_h\n",
    "        #y = np.concatenate(self.y,0).astype('float32') #.reshape((self.minibatch_size,1,1,1))\n",
    "        #print('y: ',self.y)\n",
    "        #y = tf.reshape(y,(self.replay_buffer.batch,1,1,1))\n",
    "        return y \n",
    "    \n",
    "        \n",
    "    def discrete_random_noise(self):\n",
    "        pass\n",
    "    \n",
    "    def update_target_weights(self):   \n",
    "        tgt_critic_weight = self.target_critic.get_weights()\n",
    "        tgt_actor_weight = self.target_actor.get_weights()\n",
    "        actor_weight = self.actor.get_weights()\n",
    "        critic_weight = self.target_actor.get_weights()\n",
    "        \n",
    "        for idx,(part_tgt,part_net) in enumerate(zip(tgt_critic_weight,critic_weight)):\n",
    "            tgt_critic_weight[idx] = self.tau*part_tgt + (1.0-self.tau)*part_net\n",
    "        \n",
    "        for idx,(part_tgt,part_net) in enumerate(zip(tgt_actor_weight,actor_weight)):\n",
    "            tgt_actor_weight[idx] = self.tau*part_tgt + (1.0-self.tau)*part_net\n",
    "            \n",
    "        self.target_actor.set_weights(tgt_actor_weight)\n",
    "        self.target_critic.set_weights(tgt_critic_weight)\n",
    "            \n",
    "    def save(self,filename):\n",
    "        self.actor.save_weights(filename)\n",
    "        self.critic.save_weights(filename)\n",
    "        self.target_actor.save_weights(filename)\n",
    "        self.target_critic.save_weights(filename)\n",
    "    \n",
    "    def load(self,filename):\n",
    "        self.actor.load_weights(filename)\n",
    "        self.critic.load_weights(filename)\n",
    "        self.target_actor.load_weights(filename)\n",
    "        self.target_critic.load_weights(filename)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "StY2xL3E73ea"
   },
   "outputs": [],
   "source": [
    "class DataHandler:\n",
    "    def __init__(self, batch_size, terms, predict_terms=1, image_size=64, color=False, rescale=True, aug=True, is_training=True, method='cpc'):\n",
    "        self.batch_size = batch_size\n",
    "        self.terms = terms\n",
    "        self.predict_terms = predict_terms\n",
    "        self.image_size = image_size\n",
    "        self.color = color\n",
    "        self.rescale = rescale\n",
    "        self.aug = aug\n",
    "        self.is_training = is_training\n",
    "        self.method = method\n",
    "        self.lena = cv2.imread(os.path.join(base_dir,'lena.jpg'))\n",
    "        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "        if self.is_training:\n",
    "            self.x = x_train/255.0\n",
    "            self.y = y_train\n",
    "        else:\n",
    "            self.x = x_test/255.0\n",
    "            self.y = y_test\n",
    "        self.idxs = []\n",
    "        for i in range(10):\n",
    "            y = y_train if self.is_training else y_test\n",
    "            self.idxs.append(np.where(y == i)[0])\n",
    "        self.n_samples = len(self.y)//terms if self.method == 'cpc' else len(self.y)\n",
    "        self.shape = self.x.shape\n",
    "        self.n_batches = self.n_samples//batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        return self.cpc_batch() if self.method == 'cpc' else self.benchmark_batch()\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_batches\n",
    "\n",
    "    def cpc_batch(self):\n",
    "        img_labels = np.zeros((self.batch_size, self.terms + self.predict_terms))\n",
    "        sentence_labels = np.ones((self.batch_size, 1)).astype('int32')\n",
    "        for bi in range(self.batch_size):\n",
    "            seed = np.random.randint(10)\n",
    "            sentence = np.arange(seed, seed + self.terms + self.predict_terms) % 10\n",
    "            if bi < self.batch_size//2:\n",
    "                num = np.arange(10)\n",
    "                predicted = sentence[-self.predict_terms:]\n",
    "                for i, p in enumerate(predicted):\n",
    "                    predicted[i] = np.random.choice(num[num != p], 1)\n",
    "                sentence[-self.predict_terms:] = predicted % 10\n",
    "                sentence_labels[bi, :] = 0\n",
    "            img_labels[bi, :] = sentence\n",
    "        images = self.get_samples(img_labels).reshape((self.batch_size, self.terms+self.predict_terms, self.image_size, self.image_size, 3))\n",
    "        x_images = images[:, :-self.predict_terms, ...]\n",
    "        y_images = images[:, -self.predict_terms:, ...]\n",
    "        idx = np.random.choice(self.batch_size, self.batch_size, replace=False)\n",
    "        return [x_images[idx], y_images[idx]], sentence_labels[idx]\n",
    "\n",
    "    def get_samples(self, img_labels):\n",
    "        idx = []\n",
    "        for label in img_labels.flatten():\n",
    "            idx.append(np.random.choice(self.idxs[int(label)], 1)[0])\n",
    "        img_batch = self.x[idx, :, :]\n",
    "        if self.aug:\n",
    "            img_batch = self._aug_batch(img_batch)\n",
    "        return img_batch\n",
    "\n",
    "    def _aug_batch(self, img_batch):\n",
    "        if self.image_size != 28:\n",
    "            resized = []\n",
    "            for i in range(img_batch.shape[0]):\n",
    "                resized.append(cv2.resize(img_batch[i], (self.image_size, self.image_size)))\n",
    "            img_batch = np.stack(resized)\n",
    "        img_batch = img_batch.reshape((img_batch.shape[0], 1, self.image_size, self.image_size))\n",
    "        img_batch = np.concatenate([img_batch, img_batch, img_batch], axis=1)\n",
    "\n",
    "        if self.color:\n",
    "            img_batch[img_batch >= 0.5] = 1\n",
    "            img_batch[img_batch < 0.5] = 0\n",
    "            for i in range(img_batch.shape[0]):\n",
    "                x_c = np.random.randint(0, self.lena.shape[0] - self.image_size)\n",
    "                y_c = np.random.randint(0, self.lena.shape[1] - self.image_size)\n",
    "                img = self.lena[x_c:x_c+self.image_size, y_c:y_c+self.image_size]\n",
    "                img = np.array(img).transpose((2, 0, 1))/255.0\n",
    "                for j in range(3):\n",
    "                    img[j, :, :] = (img[j, :, :] + np.random.uniform(0, 1))/2.0\n",
    "                img[img_batch[i, :, :, :] == 1] = 1 - img[img_batch[i, :, :, :] == 1]\n",
    "                img_batch[i, :, :, :] = img\n",
    "\n",
    "        if self.rescale:\n",
    "            img_batch = img_batch * 2 - 1\n",
    "        img_batch = img_batch.transpose((0, 2, 3, 1))\n",
    "        return img_batch\n",
    "\n",
    "    def benchmark_batch(self):\n",
    "        idx = np.random.choice(len(self.x), self.batch_size, replace=False)\n",
    "        img_batch = self.x[idx]\n",
    "        label_batch = self.y[idx]\n",
    "        if self.aug:\n",
    "            img_batch = self._aug_batch(img_batch)\n",
    "        label_batch = label_batch.reshape((-1, 1))\n",
    "        return img_batch, label_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "TbyX3qlk1b4g",
    "outputId": "5ee8316c-0a96-4277-b003-e9937032d726"
   },
   "outputs": [],
   "source": [
    "# #train loop\n",
    "# dh_train = DataHandler(64, 4, predict_terms=4, image_size=64, color=True, rescale=True, aug=True, is_training=True, method='cpc')\n",
    "# dh_test = DataHandler(64, 4, predict_terms=4, image_size=64, color=True, rescale=True, aug=True, is_training=False, method='cpc')\n",
    "# accuracy_metric_train = tf.keras.metrics.BinaryAccuracy()\n",
    "# loss_metric_train = tf.keras.metrics.BinaryCrossentropy()\n",
    "# accuracy_metric_test = tf.keras.metrics.BinaryAccuracy()\n",
    "# loss_metric_test = tf.keras.metrics.BinaryCrossentropy()\n",
    "# cpc = CPCModel(code_size=128, predict_terms=4, terms=4, units=256, image_size=64, channels=3)\n",
    "# optim = tf.keras.optimizers.Adam(1e-3)\n",
    "# cb = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=1/3, patience=2, min_lr=1e-4),\n",
    "#       tf.keras.callbacks.ModelCheckpoint('weights/weights.{epoch:02d}-{val_binary_accuracy:.2f}.cpkt',\n",
    "#                                           monitor='val_binary_accuracy', save_best_only=True, save_weights_only=True),\n",
    "#       tf.keras.callbacks.EarlyStopping(monitor='val_binary_accuracy', patience=3),\n",
    "#       tf.keras.callbacks.TensorBoard()]\n",
    "# cpc.compile(optimizer=optim, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
    "# cpc.fit(x=dh_train, epochs=10, validation_data=dh_test, steps_per_epoch=60000//64, validation_steps=10000//64, callbacks=cb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vn5Hapce1cE5"
   },
   "outputs": [],
   "source": [
    "#%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dtara\\anaconda3\\envs\\csci-7000-rl\\lib\\site-packages\\gym\\logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# train loop params\n",
    "\n",
    "\n",
    "episodes = 200\n",
    "episode_steps = 1000\n",
    "buffer_size = 100000\n",
    "batch_size = 16\n",
    "\n",
    "# pybullet setup\n",
    "env = gym.make('HalfCheetahBulletEnv-v0')\n",
    "env.render(mode = 'human')\n",
    "env._max_episode_steps = episode_steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 6\n"
     ]
    }
   ],
   "source": [
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "writer_reward = tf.summary.create_file_writer(reward_dir)\n",
    "\n",
    "#get spaces\n",
    "state_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.shape[0]\n",
    "print(state_space,action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0eguufNR5p4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  0  :episode:  0\n",
      "q_loss:  [[[0.51214576]]]\n",
      "t:  1  :episode:  0\n",
      "q_loss:  [[[0.32530105]]]\n",
      "t:  2  :episode:  0\n",
      "q_loss:  [[[0.19346547]]]\n",
      "t:  3  :episode:  0\n",
      "q_loss:  [[[0.2349267]]]\n",
      "t:  4  :episode:  0\n",
      "q_loss:  [[[0.15801728]]]\n",
      "t:  5  :episode:  0\n",
      "q_loss:  [[[0.09860212]]]\n",
      "t:  6  :episode:  0\n",
      "q_loss:  [[[0.1298646]]]\n",
      "t:  7  :episode:  0\n",
      "q_loss:  [[[0.15899816]]]\n",
      "t:  8  :episode:  0\n",
      "q_loss:  [[[0.18582213]]]\n",
      "t:  9  :episode:  0\n",
      "q_loss:  [[[0.17287856]]]\n",
      "t:  10  :episode:  0\n",
      "q_loss:  [[[0.14272122]]]\n",
      "t:  11  :episode:  0\n",
      "q_loss:  [[[0.11208106]]]\n",
      "t:  12  :episode:  0\n",
      "q_loss:  [[[0.0888068]]]\n",
      "t:  13  :episode:  0\n",
      "q_loss:  [[[0.07490087]]]\n",
      "t:  14  :episode:  0\n",
      "q_loss:  [[[0.06721821]]]\n",
      "t:  15  :episode:  0\n",
      "q_loss:  [[[0.47394645]]]\n",
      "t:  16  :episode:  0\n",
      "q_loss:  [[[0.4625653]]]\n",
      "t:  17  :episode:  0\n",
      "q_loss:  [[[0.8621845]]]\n",
      "t:  18  :episode:  0\n",
      "q_loss:  [[[0.96047574]]]\n",
      "t:  19  :episode:  0\n",
      "q_loss:  [[[1.218885]]]\n",
      "t:  20  :episode:  0\n",
      "q_loss:  [[[1.167798]]]\n",
      "t:  21  :episode:  0\n",
      "q_loss:  [[[1.1877313]]]\n",
      "t:  22  :episode:  0\n",
      "q_loss:  [[[0.81427693]]]\n",
      "t:  23  :episode:  0\n",
      "q_loss:  [[[0.9303474]]]\n",
      "t:  24  :episode:  0\n",
      "q_loss:  [[[0.65979296]]]\n",
      "t:  25  :episode:  0\n",
      "q_loss:  [[[0.88377476]]]\n",
      "t:  26  :episode:  0\n",
      "q_loss:  [[[0.78764236]]]\n",
      "t:  27  :episode:  0\n",
      "q_loss:  [[[0.6052228]]]\n",
      "t:  28  :episode:  0\n",
      "q_loss:  [[[0.7387289]]]\n",
      "t:  29  :episode:  0\n",
      "q_loss:  [[[0.39789364]]]\n",
      "t:  30  :episode:  0\n",
      "q_loss:  [[[0.62733024]]]\n",
      "t:  31  :episode:  0\n",
      "q_loss:  [[[0.5976453]]]\n",
      "t:  32  :episode:  0\n",
      "q_loss:  [[[0.30002493]]]\n",
      "t:  33  :episode:  0\n",
      "q_loss:  [[[0.29141104]]]\n",
      "t:  34  :episode:  0\n",
      "q_loss:  [[[0.2290833]]]\n",
      "t:  35  :episode:  0\n",
      "q_loss:  [[[0.2780732]]]\n",
      "t:  36  :episode:  0\n",
      "q_loss:  [[[0.2288]]]\n",
      "t:  37  :episode:  0\n",
      "q_loss:  [[[0.20348215]]]\n",
      "t:  38  :episode:  0\n",
      "q_loss:  [[[0.4796904]]]\n",
      "t:  39  :episode:  0\n",
      "q_loss:  [[[0.29629976]]]\n",
      "t:  40  :episode:  0\n",
      "q_loss:  [[[0.41186842]]]\n",
      "t:  41  :episode:  0\n",
      "q_loss:  [[[0.15163234]]]\n",
      "t:  42  :episode:  0\n",
      "q_loss:  [[[0.17938884]]]\n",
      "t:  43  :episode:  0\n",
      "q_loss:  [[[0.17109819]]]\n",
      "t:  44  :episode:  0\n",
      "q_loss:  [[[0.1906094]]]\n",
      "t:  45  :episode:  0\n",
      "q_loss:  [[[0.09766527]]]\n",
      "t:  46  :episode:  0\n",
      "q_loss:  [[[0.25581968]]]\n",
      "t:  47  :episode:  0\n",
      "q_loss:  [[[0.49060205]]]\n",
      "t:  48  :episode:  0\n",
      "q_loss:  [[[0.26830903]]]\n",
      "t:  49  :episode:  0\n",
      "q_loss:  [[[0.16250215]]]\n",
      "t:  50  :episode:  0\n",
      "q_loss:  [[[0.21043915]]]\n",
      "t:  51  :episode:  0\n",
      "q_loss:  [[[0.25574315]]]\n",
      "t:  52  :episode:  0\n",
      "q_loss:  [[[0.20302373]]]\n",
      "t:  53  :episode:  0\n",
      "q_loss:  [[[0.42748913]]]\n",
      "t:  54  :episode:  0\n",
      "q_loss:  [[[0.23546556]]]\n",
      "t:  55  :episode:  0\n",
      "q_loss:  [[[0.77935624]]]\n",
      "t:  56  :episode:  0\n",
      "q_loss:  [[[0.28589374]]]\n",
      "t:  57  :episode:  0\n",
      "q_loss:  [[[0.6348079]]]\n",
      "t:  58  :episode:  0\n",
      "q_loss:  [[[0.46388212]]]\n",
      "t:  59  :episode:  0\n",
      "q_loss:  [[[0.26158625]]]\n",
      "t:  60  :episode:  0\n",
      "q_loss:  [[[0.32290643]]]\n",
      "t:  61  :episode:  0\n",
      "q_loss:  [[[0.5064484]]]\n",
      "t:  62  :episode:  0\n",
      "q_loss:  [[[0.23583013]]]\n",
      "t:  63  :episode:  0\n",
      "q_loss:  [[[0.38694066]]]\n",
      "t:  64  :episode:  0\n",
      "q_loss:  [[[0.58756006]]]\n",
      "t:  65  :episode:  0\n",
      "q_loss:  [[[0.16791284]]]\n",
      "t:  66  :episode:  0\n",
      "q_loss:  [[[0.3752493]]]\n",
      "t:  67  :episode:  0\n",
      "q_loss:  [[[0.4320998]]]\n",
      "t:  68  :episode:  0\n",
      "q_loss:  [[[0.08133313]]]\n",
      "t:  69  :episode:  0\n",
      "q_loss:  [[[0.13557418]]]\n",
      "t:  70  :episode:  0\n",
      "q_loss:  [[[0.33797815]]]\n",
      "t:  71  :episode:  0\n",
      "q_loss:  [[[0.08044891]]]\n",
      "t:  72  :episode:  0\n",
      "q_loss:  [[[0.23928475]]]\n",
      "t:  73  :episode:  0\n",
      "q_loss:  [[[0.09122229]]]\n",
      "t:  74  :episode:  0\n",
      "q_loss:  [[[0.22239757]]]\n",
      "t:  75  :episode:  0\n",
      "q_loss:  [[[0.21121281]]]\n",
      "t:  76  :episode:  0\n",
      "q_loss:  [[[0.25554347]]]\n",
      "t:  77  :episode:  0\n",
      "q_loss:  [[[0.40494412]]]\n",
      "t:  78  :episode:  0\n",
      "q_loss:  [[[0.37506813]]]\n",
      "t:  79  :episode:  0\n",
      "q_loss:  [[[0.05105551]]]\n",
      "t:  80  :episode:  0\n",
      "q_loss:  [[[0.08863354]]]\n",
      "t:  81  :episode:  0\n",
      "q_loss:  [[[0.17263137]]]\n",
      "t:  82  :episode:  0\n",
      "q_loss:  [[[0.09614678]]]\n",
      "t:  83  :episode:  0\n",
      "q_loss:  [[[0.11266674]]]\n",
      "t:  84  :episode:  0\n",
      "q_loss:  [[[0.19772144]]]\n",
      "t:  85  :episode:  0\n",
      "q_loss:  [[[0.18094668]]]\n",
      "t:  86  :episode:  0\n",
      "q_loss:  [[[0.13680041]]]\n",
      "t:  87  :episode:  0\n",
      "q_loss:  [[[0.16284809]]]\n",
      "t:  88  :episode:  0\n",
      "q_loss:  [[[0.10047322]]]\n",
      "t:  89  :episode:  0\n",
      "q_loss:  [[[0.13825464]]]\n",
      "t:  90  :episode:  0\n",
      "q_loss:  [[[0.08941586]]]\n",
      "t:  91  :episode:  0\n",
      "q_loss:  [[[0.10740307]]]\n",
      "t:  92  :episode:  0\n",
      "q_loss:  [[[0.22879979]]]\n",
      "t:  93  :episode:  0\n",
      "q_loss:  [[[0.21693143]]]\n",
      "t:  94  :episode:  0\n",
      "q_loss:  [[[0.08410101]]]\n",
      "t:  95  :episode:  0\n",
      "q_loss:  [[[0.06987923]]]\n",
      "t:  96  :episode:  0\n",
      "q_loss:  [[[0.15111858]]]\n",
      "t:  97  :episode:  0\n",
      "q_loss:  [[[0.27391398]]]\n",
      "t:  98  :episode:  0\n",
      "q_loss:  [[[0.30940652]]]\n",
      "t:  99  :episode:  0\n",
      "q_loss:  [[[0.09312766]]]\n",
      "t:  100  :episode:  0\n",
      "q_loss:  [[[0.05963293]]]\n",
      "t:  101  :episode:  0\n",
      "q_loss:  [[[0.17168072]]]\n",
      "t:  102  :episode:  0\n",
      "q_loss:  [[[0.11936217]]]\n",
      "t:  103  :episode:  0\n",
      "q_loss:  [[[0.22042625]]]\n",
      "t:  104  :episode:  0\n",
      "q_loss:  [[[0.093771]]]\n",
      "t:  105  :episode:  0\n",
      "q_loss:  [[[0.10828044]]]\n",
      "t:  106  :episode:  0\n",
      "q_loss:  [[[0.19487861]]]\n",
      "t:  107  :episode:  0\n",
      "q_loss:  [[[0.30168763]]]\n",
      "t:  108  :episode:  0\n",
      "q_loss:  [[[0.16328703]]]\n",
      "t:  109  :episode:  0\n",
      "q_loss:  [[[0.10671604]]]\n",
      "t:  110  :episode:  0\n",
      "q_loss:  [[[0.799056]]]\n",
      "t:  111  :episode:  0\n",
      "q_loss:  [[[0.6968495]]]\n",
      "t:  112  :episode:  0\n",
      "q_loss:  [[[0.40326348]]]\n",
      "t:  113  :episode:  0\n",
      "q_loss:  [[[1.0644798]]]\n",
      "t:  114  :episode:  0\n",
      "q_loss:  [[[0.87890047]]]\n",
      "t:  115  :episode:  0\n",
      "q_loss:  [[[1.0215019]]]\n",
      "t:  116  :episode:  0\n",
      "q_loss:  [[[0.22110063]]]\n",
      "t:  117  :episode:  0\n",
      "q_loss:  [[[0.8934939]]]\n",
      "t:  118  :episode:  0\n",
      "q_loss:  [[[0.37194774]]]\n",
      "t:  119  :episode:  0\n",
      "q_loss:  [[[1.3594542]]]\n",
      "t:  120  :episode:  0\n",
      "q_loss:  [[[0.25993097]]]\n",
      "t:  121  :episode:  0\n",
      "q_loss:  [[[1.3159642]]]\n",
      "t:  122  :episode:  0\n",
      "q_loss:  [[[0.12981491]]]\n",
      "t:  123  :episode:  0\n",
      "q_loss:  [[[0.8073572]]]\n",
      "t:  124  :episode:  0\n",
      "q_loss:  [[[0.28781366]]]\n",
      "t:  125  :episode:  0\n",
      "q_loss:  [[[0.22845702]]]\n",
      "t:  126  :episode:  0\n",
      "q_loss:  [[[0.31663656]]]\n",
      "t:  127  :episode:  0\n",
      "q_loss:  [[[0.20451313]]]\n",
      "t:  128  :episode:  0\n",
      "q_loss:  [[[0.18434659]]]\n",
      "t:  129  :episode:  0\n",
      "q_loss:  [[[0.59099525]]]\n",
      "t:  130  :episode:  0\n",
      "q_loss:  [[[0.3974386]]]\n",
      "t:  131  :episode:  0\n",
      "q_loss:  [[[0.29682803]]]\n",
      "t:  132  :episode:  0\n",
      "q_loss:  [[[0.26228207]]]\n",
      "t:  133  :episode:  0\n",
      "q_loss:  [[[0.4507631]]]\n",
      "t:  134  :episode:  0\n",
      "q_loss:  [[[0.21423152]]]\n",
      "t:  135  :episode:  0\n",
      "q_loss:  [[[0.22985294]]]\n",
      "t:  136  :episode:  0\n",
      "q_loss:  [[[0.19873212]]]\n",
      "t:  137  :episode:  0\n",
      "q_loss:  [[[0.26587155]]]\n",
      "t:  138  :episode:  0\n",
      "q_loss:  [[[0.08660689]]]\n",
      "t:  139  :episode:  0\n",
      "q_loss:  [[[0.1497301]]]\n",
      "t:  140  :episode:  0\n",
      "q_loss:  [[[0.07804562]]]\n",
      "t:  141  :episode:  0\n",
      "q_loss:  [[[0.24946739]]]\n",
      "t:  142  :episode:  0\n",
      "q_loss:  [[[0.70321643]]]\n",
      "t:  143  :episode:  0\n",
      "q_loss:  [[[0.19614959]]]\n",
      "t:  144  :episode:  0\n",
      "q_loss:  [[[0.1670797]]]\n",
      "t:  145  :episode:  0\n",
      "q_loss:  [[[0.54639727]]]\n",
      "t:  146  :episode:  0\n",
      "q_loss:  [[[0.54026103]]]\n",
      "t:  147  :episode:  0\n",
      "q_loss:  [[[0.1841165]]]\n",
      "t:  148  :episode:  0\n",
      "q_loss:  [[[0.23684296]]]\n",
      "t:  149  :episode:  0\n",
      "q_loss:  [[[0.24853802]]]\n",
      "t:  150  :episode:  0\n",
      "q_loss:  [[[0.10748924]]]\n",
      "t:  151  :episode:  0\n",
      "q_loss:  [[[0.11706088]]]\n",
      "t:  152  :episode:  0\n",
      "q_loss:  [[[0.06673558]]]\n",
      "t:  153  :episode:  0\n",
      "q_loss:  [[[0.9261309]]]\n",
      "t:  154  :episode:  0\n",
      "q_loss:  [[[0.2027426]]]\n",
      "t:  155  :episode:  0\n",
      "q_loss:  [[[0.51996845]]]\n",
      "t:  156  :episode:  0\n",
      "q_loss:  [[[0.566188]]]\n",
      "t:  157  :episode:  0\n",
      "q_loss:  [[[0.05961426]]]\n",
      "t:  158  :episode:  0\n",
      "q_loss:  [[[0.26239613]]]\n",
      "t:  159  :episode:  0\n",
      "q_loss:  [[[0.17233773]]]\n",
      "t:  160  :episode:  0\n",
      "q_loss:  [[[0.18895215]]]\n",
      "t:  161  :episode:  0\n",
      "q_loss:  [[[0.3257494]]]\n",
      "t:  162  :episode:  0\n",
      "q_loss:  [[[0.2716575]]]\n",
      "t:  163  :episode:  0\n",
      "q_loss:  [[[0.48008442]]]\n",
      "t:  164  :episode:  0\n",
      "q_loss:  [[[0.15939316]]]\n",
      "t:  165  :episode:  0\n",
      "q_loss:  [[[0.40678823]]]\n",
      "t:  166  :episode:  0\n",
      "q_loss:  [[[0.18964246]]]\n",
      "t:  167  :episode:  0\n",
      "q_loss:  [[[0.39290884]]]\n",
      "t:  168  :episode:  0\n",
      "q_loss:  [[[0.1272271]]]\n",
      "t:  169  :episode:  0\n",
      "q_loss:  [[[0.46709093]]]\n",
      "t:  170  :episode:  0\n",
      "q_loss:  [[[0.09073535]]]\n",
      "t:  171  :episode:  0\n",
      "q_loss:  [[[0.09557411]]]\n",
      "t:  172  :episode:  0\n",
      "q_loss:  [[[0.08455098]]]\n",
      "t:  173  :episode:  0\n",
      "q_loss:  [[[0.2650481]]]\n",
      "t:  174  :episode:  0\n",
      "q_loss:  [[[0.13139586]]]\n",
      "t:  175  :episode:  0\n",
      "q_loss:  [[[0.1259071]]]\n",
      "t:  176  :episode:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [[[0.1136747]]]\n",
      "t:  177  :episode:  0\n",
      "q_loss:  [[[0.06861548]]]\n",
      "t:  178  :episode:  0\n",
      "q_loss:  [[[0.49416927]]]\n",
      "t:  179  :episode:  0\n",
      "q_loss:  [[[0.1210062]]]\n",
      "t:  180  :episode:  0\n",
      "q_loss:  [[[0.04252842]]]\n",
      "t:  181  :episode:  0\n",
      "q_loss:  [[[0.04372288]]]\n",
      "t:  182  :episode:  0\n",
      "q_loss:  [[[0.14988744]]]\n",
      "t:  183  :episode:  0\n",
      "q_loss:  [[[0.18525183]]]\n",
      "t:  184  :episode:  0\n",
      "q_loss:  [[[0.301201]]]\n",
      "t:  185  :episode:  0\n",
      "q_loss:  [[[0.2611261]]]\n",
      "t:  186  :episode:  0\n",
      "q_loss:  [[[0.13142455]]]\n",
      "t:  187  :episode:  0\n",
      "q_loss:  [[[0.05618998]]]\n",
      "t:  188  :episode:  0\n",
      "q_loss:  [[[0.13297567]]]\n",
      "t:  189  :episode:  0\n",
      "q_loss:  [[[0.30005333]]]\n",
      "t:  190  :episode:  0\n",
      "q_loss:  [[[0.4395577]]]\n",
      "t:  191  :episode:  0\n",
      "q_loss:  [[[0.3201246]]]\n",
      "t:  192  :episode:  0\n",
      "q_loss:  [[[0.23862687]]]\n",
      "t:  193  :episode:  0\n",
      "q_loss:  [[[0.17535277]]]\n",
      "t:  194  :episode:  0\n",
      "q_loss:  [[[0.08263938]]]\n",
      "t:  195  :episode:  0\n",
      "q_loss:  [[[0.06569918]]]\n",
      "t:  196  :episode:  0\n",
      "q_loss:  [[[0.29899076]]]\n",
      "t:  197  :episode:  0\n",
      "q_loss:  [[[0.4887807]]]\n",
      "t:  198  :episode:  0\n",
      "q_loss:  [[[0.26172286]]]\n",
      "t:  199  :episode:  0\n",
      "q_loss:  [[[0.2700168]]]\n",
      "t:  200  :episode:  0\n",
      "q_loss:  [[[0.17755438]]]\n",
      "t:  201  :episode:  0\n",
      "q_loss:  [[[0.09359244]]]\n",
      "t:  202  :episode:  0\n",
      "q_loss:  [[[0.29747233]]]\n",
      "t:  203  :episode:  0\n",
      "q_loss:  [[[0.17306529]]]\n",
      "t:  204  :episode:  0\n",
      "q_loss:  [[[0.3050362]]]\n",
      "t:  205  :episode:  0\n",
      "q_loss:  [[[0.18090326]]]\n",
      "t:  206  :episode:  0\n",
      "q_loss:  [[[0.16162044]]]\n",
      "t:  207  :episode:  0\n",
      "q_loss:  [[[0.58936065]]]\n",
      "t:  208  :episode:  0\n",
      "q_loss:  [[[0.07481736]]]\n",
      "t:  209  :episode:  0\n",
      "q_loss:  [[[0.3104744]]]\n",
      "t:  210  :episode:  0\n",
      "q_loss:  [[[0.19860098]]]\n",
      "t:  211  :episode:  0\n",
      "q_loss:  [[[0.6541404]]]\n",
      "t:  212  :episode:  0\n",
      "q_loss:  [[[0.26206237]]]\n",
      "t:  213  :episode:  0\n",
      "q_loss:  [[[0.30579165]]]\n",
      "t:  214  :episode:  0\n",
      "q_loss:  [[[0.21072577]]]\n",
      "t:  215  :episode:  0\n",
      "q_loss:  [[[0.302438]]]\n",
      "t:  216  :episode:  0\n",
      "q_loss:  [[[0.3278625]]]\n",
      "t:  217  :episode:  0\n",
      "q_loss:  [[[0.16026945]]]\n",
      "t:  218  :episode:  0\n",
      "q_loss:  [[[0.35076]]]\n",
      "t:  219  :episode:  0\n",
      "q_loss:  [[[0.645672]]]\n",
      "t:  220  :episode:  0\n",
      "q_loss:  [[[0.29918945]]]\n",
      "t:  221  :episode:  0\n",
      "q_loss:  [[[0.24321905]]]\n",
      "t:  222  :episode:  0\n",
      "q_loss:  [[[0.27613804]]]\n",
      "t:  223  :episode:  0\n",
      "q_loss:  [[[0.23888946]]]\n",
      "t:  224  :episode:  0\n",
      "q_loss:  [[[0.29314166]]]\n",
      "t:  225  :episode:  0\n",
      "q_loss:  [[[0.27356303]]]\n",
      "t:  226  :episode:  0\n",
      "q_loss:  [[[0.44514778]]]\n",
      "t:  227  :episode:  0\n",
      "q_loss:  [[[0.16488533]]]\n",
      "t:  228  :episode:  0\n",
      "q_loss:  [[[0.08381678]]]\n",
      "t:  229  :episode:  0\n",
      "q_loss:  [[[0.12299549]]]\n",
      "t:  230  :episode:  0\n",
      "q_loss:  [[[0.24918845]]]\n",
      "t:  231  :episode:  0\n",
      "q_loss:  [[[0.36938396]]]\n",
      "t:  232  :episode:  0\n",
      "q_loss:  [[[0.13708058]]]\n",
      "t:  233  :episode:  0\n",
      "q_loss:  [[[0.2643566]]]\n",
      "t:  234  :episode:  0\n",
      "q_loss:  [[[0.28764504]]]\n",
      "t:  235  :episode:  0\n",
      "q_loss:  [[[0.258977]]]\n",
      "t:  236  :episode:  0\n",
      "q_loss:  [[[0.428124]]]\n",
      "t:  237  :episode:  0\n",
      "q_loss:  [[[0.18980187]]]\n",
      "t:  238  :episode:  0\n",
      "q_loss:  [[[0.34203336]]]\n",
      "t:  239  :episode:  0\n",
      "q_loss:  [[[0.13444576]]]\n",
      "t:  240  :episode:  0\n",
      "q_loss:  [[[0.1396662]]]\n",
      "t:  241  :episode:  0\n",
      "q_loss:  [[[0.19818473]]]\n",
      "t:  242  :episode:  0\n",
      "q_loss:  [[[0.06266914]]]\n",
      "t:  243  :episode:  0\n",
      "q_loss:  [[[0.51747775]]]\n",
      "t:  244  :episode:  0\n",
      "q_loss:  [[[0.23304488]]]\n",
      "t:  245  :episode:  0\n",
      "q_loss:  [[[0.42484838]]]\n",
      "t:  246  :episode:  0\n",
      "q_loss:  [[[0.16752413]]]\n",
      "t:  247  :episode:  0\n",
      "q_loss:  [[[0.21806964]]]\n",
      "t:  248  :episode:  0\n",
      "q_loss:  [[[0.28835255]]]\n",
      "t:  249  :episode:  0\n",
      "q_loss:  [[[0.10972408]]]\n",
      "t:  250  :episode:  0\n",
      "q_loss:  [[[0.28222346]]]\n",
      "t:  251  :episode:  0\n",
      "q_loss:  [[[0.718564]]]\n",
      "t:  252  :episode:  0\n",
      "q_loss:  [[[0.18510634]]]\n",
      "t:  253  :episode:  0\n",
      "q_loss:  [[[0.09478377]]]\n",
      "t:  254  :episode:  0\n",
      "q_loss:  [[[0.15921685]]]\n",
      "t:  255  :episode:  0\n",
      "q_loss:  [[[0.12693846]]]\n",
      "t:  256  :episode:  0\n",
      "q_loss:  [[[0.31972218]]]\n",
      "t:  257  :episode:  0\n",
      "q_loss:  [[[0.2883567]]]\n",
      "t:  258  :episode:  0\n",
      "q_loss:  [[[0.5800765]]]\n",
      "t:  259  :episode:  0\n",
      "q_loss:  [[[0.04726616]]]\n",
      "t:  260  :episode:  0\n",
      "q_loss:  [[[1.689556]]]\n",
      "t:  261  :episode:  0\n",
      "q_loss:  [[[0.49693733]]]\n",
      "t:  262  :episode:  0\n",
      "q_loss:  [[[0.45213094]]]\n",
      "t:  263  :episode:  0\n",
      "q_loss:  [[[0.24248269]]]\n",
      "t:  264  :episode:  0\n",
      "q_loss:  [[[0.17286372]]]\n",
      "t:  265  :episode:  0\n",
      "q_loss:  [[[0.16883382]]]\n",
      "t:  266  :episode:  0\n",
      "q_loss:  [[[0.12554136]]]\n",
      "t:  267  :episode:  0\n",
      "q_loss:  [[[0.5964672]]]\n",
      "t:  268  :episode:  0\n",
      "q_loss:  [[[0.4292556]]]\n",
      "t:  269  :episode:  0\n",
      "q_loss:  [[[0.24577296]]]\n",
      "t:  270  :episode:  0\n",
      "q_loss:  [[[0.2902659]]]\n",
      "t:  271  :episode:  0\n",
      "q_loss:  [[[0.6649006]]]\n",
      "t:  272  :episode:  0\n",
      "q_loss:  [[[0.2857027]]]\n",
      "t:  273  :episode:  0\n",
      "q_loss:  [[[0.61164606]]]\n",
      "t:  274  :episode:  0\n",
      "q_loss:  [[[0.85637814]]]\n",
      "t:  275  :episode:  0\n",
      "q_loss:  [[[0.3168942]]]\n",
      "t:  276  :episode:  0\n",
      "q_loss:  [[[0.08964071]]]\n",
      "t:  277  :episode:  0\n",
      "q_loss:  [[[0.09728148]]]\n",
      "t:  278  :episode:  0\n",
      "q_loss:  [[[0.2123569]]]\n",
      "t:  279  :episode:  0\n",
      "q_loss:  [[[0.37551922]]]\n",
      "t:  280  :episode:  0\n",
      "q_loss:  [[[0.45699662]]]\n",
      "t:  281  :episode:  0\n",
      "q_loss:  [[[0.6671178]]]\n",
      "t:  282  :episode:  0\n",
      "q_loss:  [[[0.33967096]]]\n",
      "t:  283  :episode:  0\n",
      "q_loss:  [[[0.34924552]]]\n",
      "t:  284  :episode:  0\n",
      "q_loss:  [[[0.4488305]]]\n",
      "t:  285  :episode:  0\n",
      "q_loss:  [[[0.1724784]]]\n",
      "t:  286  :episode:  0\n",
      "q_loss:  [[[0.75885427]]]\n",
      "t:  287  :episode:  0\n",
      "q_loss:  [[[0.32800224]]]\n",
      "t:  288  :episode:  0\n",
      "q_loss:  [[[0.17594454]]]\n",
      "t:  289  :episode:  0\n",
      "q_loss:  [[[0.14166844]]]\n",
      "t:  290  :episode:  0\n",
      "q_loss:  [[[0.4595489]]]\n",
      "t:  291  :episode:  0\n",
      "q_loss:  [[[0.5340058]]]\n",
      "t:  292  :episode:  0\n",
      "q_loss:  [[[0.06517711]]]\n",
      "t:  293  :episode:  0\n",
      "q_loss:  [[[0.16375424]]]\n",
      "t:  294  :episode:  0\n",
      "q_loss:  [[[0.18459249]]]\n",
      "t:  295  :episode:  0\n",
      "q_loss:  [[[0.20981061]]]\n",
      "t:  296  :episode:  0\n",
      "q_loss:  [[[0.2508975]]]\n",
      "t:  297  :episode:  0\n",
      "q_loss:  [[[0.09063947]]]\n",
      "t:  298  :episode:  0\n",
      "q_loss:  [[[0.30860215]]]\n",
      "t:  299  :episode:  0\n",
      "q_loss:  [[[0.6134391]]]\n",
      "t:  300  :episode:  0\n",
      "q_loss:  [[[0.44943824]]]\n",
      "t:  301  :episode:  0\n",
      "q_loss:  [[[0.25036627]]]\n",
      "t:  302  :episode:  0\n",
      "q_loss:  [[[0.12500505]]]\n",
      "t:  303  :episode:  0\n",
      "q_loss:  [[[0.29500657]]]\n",
      "t:  304  :episode:  0\n",
      "q_loss:  [[[0.16599166]]]\n",
      "t:  305  :episode:  0\n",
      "q_loss:  [[[0.39115676]]]\n",
      "t:  306  :episode:  0\n",
      "q_loss:  [[[0.338689]]]\n",
      "t:  307  :episode:  0\n",
      "q_loss:  [[[0.0541311]]]\n",
      "t:  308  :episode:  0\n",
      "q_loss:  [[[0.10668756]]]\n",
      "t:  309  :episode:  0\n",
      "q_loss:  [[[0.34513712]]]\n",
      "t:  310  :episode:  0\n",
      "q_loss:  [[[0.29853413]]]\n",
      "t:  311  :episode:  0\n",
      "q_loss:  [[[0.29549325]]]\n",
      "t:  312  :episode:  0\n",
      "q_loss:  [[[0.25476858]]]\n",
      "t:  313  :episode:  0\n",
      "q_loss:  [[[0.21949065]]]\n",
      "t:  314  :episode:  0\n",
      "q_loss:  [[[0.19877775]]]\n",
      "t:  315  :episode:  0\n",
      "q_loss:  [[[0.2525253]]]\n",
      "t:  316  :episode:  0\n",
      "q_loss:  [[[0.1975446]]]\n",
      "t:  317  :episode:  0\n",
      "q_loss:  [[[0.21855415]]]\n",
      "t:  318  :episode:  0\n",
      "q_loss:  [[[0.12046777]]]\n",
      "t:  319  :episode:  0\n",
      "q_loss:  [[[0.24383688]]]\n",
      "t:  320  :episode:  0\n",
      "q_loss:  [[[0.19651584]]]\n",
      "t:  321  :episode:  0\n",
      "q_loss:  [[[0.17432626]]]\n",
      "t:  322  :episode:  0\n",
      "q_loss:  [[[0.20443588]]]\n",
      "t:  323  :episode:  0\n",
      "q_loss:  [[[0.09335195]]]\n",
      "t:  324  :episode:  0\n",
      "q_loss:  [[[0.53593946]]]\n",
      "t:  325  :episode:  0\n",
      "q_loss:  [[[0.19681165]]]\n",
      "t:  326  :episode:  0\n",
      "q_loss:  [[[0.3503399]]]\n",
      "t:  327  :episode:  0\n",
      "q_loss:  [[[0.21296306]]]\n",
      "t:  328  :episode:  0\n",
      "q_loss:  [[[0.11049712]]]\n",
      "t:  329  :episode:  0\n",
      "q_loss:  [[[0.09271684]]]\n",
      "t:  330  :episode:  0\n",
      "q_loss:  [[[0.2680505]]]\n",
      "t:  331  :episode:  0\n",
      "q_loss:  [[[0.8082179]]]\n",
      "t:  332  :episode:  0\n",
      "q_loss:  [[[0.05705065]]]\n",
      "t:  333  :episode:  0\n",
      "q_loss:  [[[0.47520658]]]\n",
      "t:  334  :episode:  0\n",
      "q_loss:  [[[0.2600156]]]\n",
      "t:  335  :episode:  0\n",
      "q_loss:  [[[0.4178829]]]\n",
      "t:  336  :episode:  0\n",
      "q_loss:  [[[0.26738477]]]\n",
      "t:  337  :episode:  0\n",
      "q_loss:  [[[0.9487711]]]\n",
      "t:  338  :episode:  0\n",
      "q_loss:  [[[0.13050322]]]\n",
      "t:  339  :episode:  0\n",
      "q_loss:  [[[0.40741706]]]\n",
      "t:  340  :episode:  0\n",
      "q_loss:  [[[0.05912106]]]\n",
      "t:  341  :episode:  0\n",
      "q_loss:  [[[0.36632225]]]\n",
      "t:  342  :episode:  0\n",
      "q_loss:  [[[0.1551235]]]\n",
      "t:  343  :episode:  0\n",
      "q_loss:  [[[0.38600254]]]\n",
      "t:  344  :episode:  0\n",
      "q_loss:  [[[0.15190513]]]\n",
      "t:  345  :episode:  0\n",
      "q_loss:  [[[0.33332393]]]\n",
      "t:  346  :episode:  0\n",
      "q_loss:  [[[0.10358888]]]\n",
      "t:  347  :episode:  0\n",
      "q_loss:  [[[0.4033937]]]\n",
      "t:  348  :episode:  0\n",
      "q_loss:  [[[0.14109649]]]\n",
      "t:  349  :episode:  0\n",
      "q_loss:  [[[0.2958833]]]\n",
      "t:  350  :episode:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [[[0.18571508]]]\n",
      "t:  351  :episode:  0\n",
      "q_loss:  [[[0.08135073]]]\n",
      "t:  352  :episode:  0\n",
      "q_loss:  [[[0.24254662]]]\n",
      "t:  353  :episode:  0\n",
      "q_loss:  [[[0.12684877]]]\n",
      "t:  354  :episode:  0\n",
      "q_loss:  [[[0.39597043]]]\n",
      "t:  355  :episode:  0\n",
      "q_loss:  [[[0.45330146]]]\n",
      "t:  356  :episode:  0\n",
      "q_loss:  [[[0.24661848]]]\n",
      "t:  357  :episode:  0\n",
      "q_loss:  [[[0.07059251]]]\n",
      "t:  358  :episode:  0\n",
      "q_loss:  [[[0.05086918]]]\n",
      "t:  359  :episode:  0\n",
      "q_loss:  [[[0.3070537]]]\n",
      "t:  360  :episode:  0\n",
      "q_loss:  [[[0.0923961]]]\n",
      "t:  361  :episode:  0\n",
      "q_loss:  [[[0.17109261]]]\n",
      "t:  362  :episode:  0\n",
      "q_loss:  [[[0.19715388]]]\n",
      "t:  363  :episode:  0\n",
      "q_loss:  [[[0.31088287]]]\n",
      "t:  364  :episode:  0\n",
      "q_loss:  [[[0.21144226]]]\n",
      "t:  365  :episode:  0\n",
      "q_loss:  [[[0.25664216]]]\n",
      "t:  366  :episode:  0\n",
      "q_loss:  [[[0.24182035]]]\n",
      "t:  367  :episode:  0\n",
      "q_loss:  [[[0.17585957]]]\n",
      "t:  368  :episode:  0\n",
      "q_loss:  [[[0.29477245]]]\n",
      "t:  369  :episode:  0\n",
      "q_loss:  [[[0.08915579]]]\n",
      "t:  370  :episode:  0\n",
      "q_loss:  [[[0.04178256]]]\n",
      "t:  371  :episode:  0\n",
      "q_loss:  [[[0.27498347]]]\n",
      "t:  372  :episode:  0\n",
      "q_loss:  [[[0.08004207]]]\n",
      "t:  373  :episode:  0\n",
      "q_loss:  [[[0.23889235]]]\n",
      "t:  374  :episode:  0\n",
      "q_loss:  [[[0.1766564]]]\n",
      "t:  375  :episode:  0\n",
      "q_loss:  [[[0.35272968]]]\n",
      "t:  376  :episode:  0\n",
      "q_loss:  [[[0.22048618]]]\n",
      "t:  377  :episode:  0\n",
      "q_loss:  [[[0.5527798]]]\n",
      "t:  378  :episode:  0\n",
      "q_loss:  [[[0.25396562]]]\n",
      "t:  379  :episode:  0\n",
      "q_loss:  [[[0.21647918]]]\n",
      "t:  380  :episode:  0\n",
      "q_loss:  [[[0.15281641]]]\n",
      "t:  381  :episode:  0\n",
      "q_loss:  [[[0.06988849]]]\n",
      "t:  382  :episode:  0\n",
      "q_loss:  [[[0.17447503]]]\n",
      "t:  383  :episode:  0\n",
      "q_loss:  [[[0.15106338]]]\n",
      "t:  384  :episode:  0\n",
      "q_loss:  [[[0.02206099]]]\n",
      "t:  385  :episode:  0\n",
      "q_loss:  [[[0.23757058]]]\n",
      "t:  386  :episode:  0\n",
      "q_loss:  [[[0.05340894]]]\n",
      "t:  387  :episode:  0\n",
      "q_loss:  [[[0.13566434]]]\n",
      "t:  388  :episode:  0\n",
      "q_loss:  [[[0.09076762]]]\n",
      "t:  389  :episode:  0\n",
      "q_loss:  [[[0.10582004]]]\n",
      "t:  390  :episode:  0\n",
      "q_loss:  [[[0.19396941]]]\n",
      "t:  391  :episode:  0\n",
      "q_loss:  [[[0.07493697]]]\n",
      "t:  392  :episode:  0\n",
      "q_loss:  [[[0.34968784]]]\n",
      "t:  393  :episode:  0\n",
      "q_loss:  [[[0.33862698]]]\n",
      "t:  394  :episode:  0\n",
      "q_loss:  [[[0.290783]]]\n",
      "t:  395  :episode:  0\n",
      "q_loss:  [[[0.10111067]]]\n",
      "t:  396  :episode:  0\n",
      "q_loss:  [[[0.10192446]]]\n",
      "t:  397  :episode:  0\n",
      "q_loss:  [[[0.12719941]]]\n",
      "t:  398  :episode:  0\n",
      "q_loss:  [[[0.21062008]]]\n",
      "t:  399  :episode:  0\n",
      "q_loss:  [[[0.03940065]]]\n",
      "t:  400  :episode:  0\n",
      "q_loss:  [[[0.17089513]]]\n",
      "t:  401  :episode:  0\n",
      "q_loss:  [[[0.18002905]]]\n",
      "t:  402  :episode:  0\n",
      "q_loss:  [[[0.28439417]]]\n",
      "t:  403  :episode:  0\n",
      "q_loss:  [[[0.08305322]]]\n",
      "t:  404  :episode:  0\n",
      "q_loss:  [[[0.05498181]]]\n",
      "t:  405  :episode:  0\n",
      "q_loss:  [[[0.1955812]]]\n",
      "t:  406  :episode:  0\n",
      "q_loss:  [[[0.2376633]]]\n",
      "t:  407  :episode:  0\n",
      "q_loss:  [[[0.09929656]]]\n",
      "t:  408  :episode:  0\n",
      "q_loss:  [[[0.07975614]]]\n",
      "t:  409  :episode:  0\n",
      "q_loss:  [[[0.16177882]]]\n",
      "t:  410  :episode:  0\n",
      "q_loss:  [[[0.01983282]]]\n",
      "t:  411  :episode:  0\n",
      "q_loss:  [[[0.07433693]]]\n",
      "t:  412  :episode:  0\n",
      "q_loss:  [[[0.028584]]]\n",
      "t:  413  :episode:  0\n",
      "q_loss:  [[[0.23180704]]]\n",
      "t:  414  :episode:  0\n",
      "q_loss:  [[[0.11777547]]]\n",
      "t:  415  :episode:  0\n",
      "q_loss:  [[[0.1218572]]]\n",
      "t:  416  :episode:  0\n",
      "q_loss:  [[[0.24781686]]]\n",
      "t:  417  :episode:  0\n",
      "q_loss:  [[[0.11698668]]]\n",
      "t:  418  :episode:  0\n",
      "q_loss:  [[[0.24991384]]]\n",
      "t:  419  :episode:  0\n",
      "q_loss:  [[[0.22705695]]]\n",
      "t:  420  :episode:  0\n",
      "q_loss:  [[[0.22982487]]]\n",
      "t:  421  :episode:  0\n",
      "q_loss:  [[[0.14432774]]]\n",
      "t:  422  :episode:  0\n",
      "q_loss:  [[[0.29410005]]]\n",
      "t:  423  :episode:  0\n",
      "q_loss:  [[[0.26104763]]]\n",
      "t:  424  :episode:  0\n",
      "q_loss:  [[[0.4436523]]]\n",
      "t:  425  :episode:  0\n",
      "q_loss:  [[[0.10189474]]]\n",
      "t:  426  :episode:  0\n",
      "q_loss:  [[[0.0605761]]]\n",
      "t:  427  :episode:  0\n",
      "q_loss:  [[[0.03247826]]]\n",
      "t:  428  :episode:  0\n",
      "q_loss:  [[[0.48670962]]]\n",
      "t:  429  :episode:  0\n",
      "q_loss:  [[[0.20163302]]]\n",
      "t:  430  :episode:  0\n",
      "q_loss:  [[[0.13242055]]]\n",
      "t:  431  :episode:  0\n",
      "q_loss:  [[[0.10967731]]]\n",
      "t:  432  :episode:  0\n",
      "q_loss:  [[[0.45013556]]]\n",
      "t:  433  :episode:  0\n",
      "q_loss:  [[[0.29657137]]]\n",
      "t:  434  :episode:  0\n",
      "q_loss:  [[[0.16547804]]]\n",
      "t:  435  :episode:  0\n",
      "q_loss:  [[[0.12487604]]]\n",
      "t:  436  :episode:  0\n",
      "q_loss:  [[[0.443642]]]\n",
      "t:  437  :episode:  0\n",
      "q_loss:  [[[0.34678307]]]\n",
      "t:  438  :episode:  0\n",
      "q_loss:  [[[0.05133538]]]\n",
      "t:  439  :episode:  0\n",
      "q_loss:  [[[0.06086315]]]\n",
      "t:  440  :episode:  0\n",
      "q_loss:  [[[0.16596669]]]\n",
      "t:  441  :episode:  0\n",
      "q_loss:  [[[0.11391743]]]\n",
      "t:  442  :episode:  0\n",
      "q_loss:  [[[0.41822708]]]\n",
      "t:  443  :episode:  0\n",
      "q_loss:  [[[0.35317862]]]\n",
      "t:  444  :episode:  0\n",
      "q_loss:  [[[0.10298838]]]\n",
      "t:  445  :episode:  0\n",
      "q_loss:  [[[0.14801604]]]\n",
      "t:  446  :episode:  0\n",
      "q_loss:  [[[0.08804112]]]\n",
      "t:  447  :episode:  0\n",
      "q_loss:  [[[0.15687859]]]\n",
      "t:  448  :episode:  0\n",
      "q_loss:  [[[0.1799691]]]\n",
      "t:  449  :episode:  0\n",
      "q_loss:  [[[0.04972327]]]\n",
      "t:  450  :episode:  0\n",
      "q_loss:  [[[0.20340472]]]\n",
      "t:  451  :episode:  0\n",
      "q_loss:  [[[0.09823509]]]\n",
      "t:  452  :episode:  0\n",
      "q_loss:  [[[0.03727134]]]\n",
      "t:  453  :episode:  0\n",
      "q_loss:  [[[0.24258101]]]\n",
      "t:  454  :episode:  0\n",
      "q_loss:  [[[0.12147027]]]\n",
      "t:  455  :episode:  0\n",
      "q_loss:  [[[0.0573635]]]\n",
      "t:  456  :episode:  0\n",
      "q_loss:  [[[0.07093069]]]\n",
      "t:  457  :episode:  0\n",
      "q_loss:  [[[0.11596692]]]\n",
      "t:  458  :episode:  0\n",
      "q_loss:  [[[0.30694723]]]\n",
      "t:  459  :episode:  0\n",
      "q_loss:  [[[0.12156081]]]\n",
      "t:  460  :episode:  0\n",
      "q_loss:  [[[0.30050978]]]\n",
      "t:  461  :episode:  0\n",
      "q_loss:  [[[0.12228339]]]\n",
      "t:  462  :episode:  0\n",
      "q_loss:  [[[0.05858686]]]\n",
      "t:  463  :episode:  0\n",
      "q_loss:  [[[0.12668158]]]\n",
      "t:  464  :episode:  0\n",
      "q_loss:  [[[0.37362853]]]\n",
      "t:  465  :episode:  0\n",
      "q_loss:  [[[0.22972533]]]\n",
      "t:  466  :episode:  0\n",
      "q_loss:  [[[0.46514875]]]\n",
      "t:  467  :episode:  0\n",
      "q_loss:  [[[0.287916]]]\n",
      "t:  468  :episode:  0\n",
      "q_loss:  [[[0.10181631]]]\n",
      "t:  469  :episode:  0\n",
      "q_loss:  [[[0.17539155]]]\n",
      "t:  470  :episode:  0\n",
      "q_loss:  [[[0.18478358]]]\n",
      "t:  471  :episode:  0\n",
      "q_loss:  [[[0.11829542]]]\n",
      "t:  472  :episode:  0\n",
      "q_loss:  [[[0.19253817]]]\n",
      "t:  473  :episode:  0\n",
      "q_loss:  [[[0.17178214]]]\n",
      "t:  474  :episode:  0\n",
      "q_loss:  [[[0.14350879]]]\n",
      "t:  475  :episode:  0\n",
      "q_loss:  [[[0.5198735]]]\n",
      "t:  476  :episode:  0\n",
      "q_loss:  [[[0.05201534]]]\n",
      "t:  477  :episode:  0\n",
      "q_loss:  [[[0.03192322]]]\n",
      "t:  478  :episode:  0\n",
      "q_loss:  [[[0.03839118]]]\n",
      "t:  479  :episode:  0\n",
      "q_loss:  [[[0.19638465]]]\n",
      "t:  480  :episode:  0\n",
      "q_loss:  [[[0.03698755]]]\n",
      "t:  481  :episode:  0\n",
      "q_loss:  [[[0.14958546]]]\n",
      "t:  482  :episode:  0\n",
      "q_loss:  [[[0.14438309]]]\n",
      "t:  483  :episode:  0\n",
      "q_loss:  [[[0.12425105]]]\n",
      "t:  484  :episode:  0\n",
      "q_loss:  [[[0.2556546]]]\n",
      "t:  485  :episode:  0\n",
      "q_loss:  [[[0.12515949]]]\n",
      "t:  486  :episode:  0\n",
      "q_loss:  [[[0.2207512]]]\n",
      "t:  487  :episode:  0\n",
      "q_loss:  [[[0.10134864]]]\n",
      "t:  488  :episode:  0\n",
      "q_loss:  [[[0.08513966]]]\n",
      "t:  489  :episode:  0\n",
      "q_loss:  [[[0.13276505]]]\n",
      "t:  490  :episode:  0\n",
      "q_loss:  [[[0.14233537]]]\n",
      "t:  491  :episode:  0\n",
      "q_loss:  [[[0.15146679]]]\n",
      "t:  492  :episode:  0\n",
      "q_loss:  [[[0.15452862]]]\n",
      "t:  493  :episode:  0\n",
      "q_loss:  [[[0.1606711]]]\n",
      "t:  494  :episode:  0\n",
      "q_loss:  [[[0.09376411]]]\n",
      "t:  495  :episode:  0\n",
      "q_loss:  [[[0.05715605]]]\n",
      "t:  496  :episode:  0\n",
      "q_loss:  [[[0.12894332]]]\n",
      "t:  497  :episode:  0\n",
      "q_loss:  [[[0.13710044]]]\n",
      "t:  498  :episode:  0\n",
      "q_loss:  [[[0.35127455]]]\n",
      "t:  499  :episode:  0\n",
      "q_loss:  [[[0.40199026]]]\n",
      "t:  500  :episode:  0\n",
      "q_loss:  [[[0.11600354]]]\n",
      "t:  501  :episode:  0\n",
      "q_loss:  [[[0.07645582]]]\n",
      "t:  502  :episode:  0\n",
      "q_loss:  [[[0.444851]]]\n",
      "t:  503  :episode:  0\n",
      "q_loss:  [[[0.11225413]]]\n",
      "t:  504  :episode:  0\n",
      "q_loss:  [[[0.28380793]]]\n",
      "t:  505  :episode:  0\n",
      "q_loss:  [[[0.42082852]]]\n",
      "t:  506  :episode:  0\n",
      "q_loss:  [[[0.24300916]]]\n",
      "t:  507  :episode:  0\n",
      "q_loss:  [[[0.67985564]]]\n",
      "t:  508  :episode:  0\n",
      "q_loss:  [[[0.27631095]]]\n",
      "t:  509  :episode:  0\n",
      "q_loss:  [[[0.08633389]]]\n",
      "t:  510  :episode:  0\n",
      "q_loss:  [[[0.3662175]]]\n",
      "t:  511  :episode:  0\n",
      "q_loss:  [[[0.18177506]]]\n",
      "t:  512  :episode:  0\n",
      "q_loss:  [[[0.3672138]]]\n",
      "t:  513  :episode:  0\n",
      "q_loss:  [[[0.18244523]]]\n",
      "t:  514  :episode:  0\n",
      "q_loss:  [[[0.09103674]]]\n",
      "t:  515  :episode:  0\n",
      "q_loss:  [[[0.17369951]]]\n",
      "t:  516  :episode:  0\n",
      "q_loss:  [[[0.05592963]]]\n",
      "t:  517  :episode:  0\n",
      "q_loss:  [[[0.21290547]]]\n",
      "t:  518  :episode:  0\n",
      "q_loss:  [[[0.18755017]]]\n",
      "t:  519  :episode:  0\n",
      "q_loss:  [[[0.48920965]]]\n",
      "t:  520  :episode:  0\n",
      "q_loss:  [[[0.15703249]]]\n",
      "t:  521  :episode:  0\n",
      "q_loss:  [[[0.06466694]]]\n",
      "t:  522  :episode:  0\n",
      "q_loss:  [[[0.09244747]]]\n",
      "t:  523  :episode:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [[[0.11917534]]]\n",
      "t:  524  :episode:  0\n",
      "q_loss:  [[[0.08146324]]]\n",
      "t:  525  :episode:  0\n",
      "q_loss:  [[[0.05423318]]]\n",
      "t:  526  :episode:  0\n",
      "q_loss:  [[[0.24237628]]]\n",
      "t:  527  :episode:  0\n",
      "q_loss:  [[[0.09645288]]]\n",
      "t:  528  :episode:  0\n",
      "q_loss:  [[[0.28715998]]]\n",
      "t:  529  :episode:  0\n",
      "q_loss:  [[[0.06887515]]]\n",
      "t:  530  :episode:  0\n",
      "q_loss:  [[[0.17986822]]]\n",
      "t:  531  :episode:  0\n",
      "q_loss:  [[[0.098179]]]\n",
      "t:  532  :episode:  0\n",
      "q_loss:  [[[0.07066942]]]\n",
      "t:  533  :episode:  0\n",
      "q_loss:  [[[0.14780523]]]\n",
      "t:  534  :episode:  0\n",
      "q_loss:  [[[0.15473802]]]\n",
      "t:  535  :episode:  0\n",
      "q_loss:  [[[0.03879286]]]\n",
      "t:  536  :episode:  0\n",
      "q_loss:  [[[0.09935959]]]\n",
      "t:  537  :episode:  0\n",
      "q_loss:  [[[0.24300298]]]\n",
      "t:  538  :episode:  0\n",
      "q_loss:  [[[0.040072]]]\n",
      "t:  539  :episode:  0\n",
      "q_loss:  [[[0.30939078]]]\n",
      "t:  540  :episode:  0\n",
      "q_loss:  [[[0.05741322]]]\n",
      "t:  541  :episode:  0\n",
      "q_loss:  [[[0.2449966]]]\n",
      "t:  542  :episode:  0\n",
      "q_loss:  [[[0.04931071]]]\n",
      "t:  543  :episode:  0\n",
      "q_loss:  [[[0.06360967]]]\n",
      "t:  544  :episode:  0\n",
      "q_loss:  [[[0.04962309]]]\n",
      "t:  545  :episode:  0\n",
      "q_loss:  [[[0.1957354]]]\n",
      "t:  546  :episode:  0\n",
      "q_loss:  [[[0.06648096]]]\n",
      "t:  547  :episode:  0\n",
      "q_loss:  [[[0.0492774]]]\n",
      "t:  548  :episode:  0\n",
      "q_loss:  [[[0.04405825]]]\n",
      "t:  549  :episode:  0\n",
      "q_loss:  [[[0.14933182]]]\n",
      "t:  550  :episode:  0\n",
      "q_loss:  [[[0.09169118]]]\n",
      "t:  551  :episode:  0\n",
      "q_loss:  [[[0.06353038]]]\n",
      "t:  552  :episode:  0\n",
      "q_loss:  [[[0.19931789]]]\n",
      "t:  553  :episode:  0\n",
      "q_loss:  [[[0.08853708]]]\n",
      "t:  554  :episode:  0\n",
      "q_loss:  [[[0.03211463]]]\n",
      "t:  555  :episode:  0\n",
      "q_loss:  [[[0.25221735]]]\n",
      "t:  556  :episode:  0\n",
      "q_loss:  [[[0.15832476]]]\n",
      "t:  557  :episode:  0\n",
      "q_loss:  [[[0.10093365]]]\n",
      "t:  558  :episode:  0\n",
      "q_loss:  [[[0.05076469]]]\n",
      "t:  559  :episode:  0\n",
      "q_loss:  [[[0.04595012]]]\n",
      "t:  560  :episode:  0\n",
      "q_loss:  [[[0.03615406]]]\n",
      "t:  561  :episode:  0\n",
      "q_loss:  [[[0.11335592]]]\n",
      "t:  562  :episode:  0\n",
      "q_loss:  [[[0.04183057]]]\n",
      "t:  563  :episode:  0\n",
      "q_loss:  [[[0.11613321]]]\n",
      "t:  564  :episode:  0\n",
      "q_loss:  [[[0.3534313]]]\n",
      "t:  565  :episode:  0\n",
      "q_loss:  [[[0.06589513]]]\n",
      "t:  566  :episode:  0\n",
      "q_loss:  [[[0.21317093]]]\n",
      "t:  567  :episode:  0\n",
      "q_loss:  [[[0.44236517]]]\n",
      "t:  568  :episode:  0\n",
      "q_loss:  [[[0.04497616]]]\n",
      "t:  569  :episode:  0\n",
      "q_loss:  [[[0.11876033]]]\n",
      "t:  570  :episode:  0\n",
      "q_loss:  [[[0.18680556]]]\n",
      "t:  571  :episode:  0\n",
      "q_loss:  [[[0.07571898]]]\n",
      "t:  572  :episode:  0\n",
      "q_loss:  [[[0.17438462]]]\n",
      "t:  573  :episode:  0\n",
      "q_loss:  [[[0.07745978]]]\n",
      "t:  574  :episode:  0\n",
      "q_loss:  [[[0.09526991]]]\n",
      "t:  575  :episode:  0\n",
      "q_loss:  [[[0.0657691]]]\n",
      "t:  576  :episode:  0\n",
      "q_loss:  [[[0.09336133]]]\n",
      "t:  577  :episode:  0\n",
      "q_loss:  [[[0.0617379]]]\n",
      "t:  578  :episode:  0\n",
      "q_loss:  [[[0.13861996]]]\n",
      "t:  579  :episode:  0\n",
      "q_loss:  [[[0.12177866]]]\n",
      "t:  580  :episode:  0\n",
      "q_loss:  [[[0.28326517]]]\n",
      "t:  581  :episode:  0\n",
      "q_loss:  [[[0.16981786]]]\n",
      "t:  582  :episode:  0\n",
      "q_loss:  [[[0.44343835]]]\n",
      "t:  583  :episode:  0\n",
      "q_loss:  [[[0.04691117]]]\n",
      "t:  584  :episode:  0\n",
      "q_loss:  [[[0.06914186]]]\n",
      "t:  585  :episode:  0\n",
      "q_loss:  [[[0.06653078]]]\n",
      "t:  586  :episode:  0\n",
      "q_loss:  [[[0.10520996]]]\n",
      "t:  587  :episode:  0\n",
      "q_loss:  [[[0.08426106]]]\n",
      "t:  588  :episode:  0\n",
      "q_loss:  [[[0.01045536]]]\n",
      "t:  589  :episode:  0\n",
      "q_loss:  [[[0.30620116]]]\n",
      "t:  590  :episode:  0\n",
      "q_loss:  [[[0.19420837]]]\n",
      "t:  591  :episode:  0\n",
      "q_loss:  [[[0.10417053]]]\n",
      "t:  592  :episode:  0\n",
      "q_loss:  [[[0.10593441]]]\n",
      "t:  593  :episode:  0\n",
      "q_loss:  [[[0.63730586]]]\n",
      "t:  594  :episode:  0\n",
      "q_loss:  [[[0.09169155]]]\n",
      "t:  595  :episode:  0\n",
      "q_loss:  [[[0.21249889]]]\n",
      "t:  596  :episode:  0\n",
      "q_loss:  [[[0.21735035]]]\n",
      "t:  597  :episode:  0\n",
      "q_loss:  [[[0.5206853]]]\n",
      "t:  598  :episode:  0\n",
      "q_loss:  [[[0.11498621]]]\n",
      "t:  599  :episode:  0\n",
      "q_loss:  [[[0.06350996]]]\n",
      "t:  600  :episode:  0\n",
      "q_loss:  [[[0.30702695]]]\n",
      "t:  601  :episode:  0\n",
      "q_loss:  [[[0.0698508]]]\n",
      "t:  602  :episode:  0\n",
      "q_loss:  [[[0.09209656]]]\n",
      "t:  603  :episode:  0\n",
      "q_loss:  [[[0.21892563]]]\n",
      "t:  604  :episode:  0\n",
      "q_loss:  [[[0.17920509]]]\n",
      "t:  605  :episode:  0\n",
      "q_loss:  [[[0.09691346]]]\n",
      "t:  606  :episode:  0\n",
      "q_loss:  [[[0.24972782]]]\n",
      "t:  607  :episode:  0\n",
      "q_loss:  [[[0.29423043]]]\n",
      "t:  608  :episode:  0\n",
      "q_loss:  [[[0.07069714]]]\n",
      "t:  609  :episode:  0\n",
      "q_loss:  [[[0.22589877]]]\n",
      "t:  610  :episode:  0\n",
      "q_loss:  [[[0.46271414]]]\n",
      "t:  611  :episode:  0\n",
      "q_loss:  [[[0.09173249]]]\n",
      "t:  612  :episode:  0\n",
      "q_loss:  [[[0.44990134]]]\n",
      "t:  613  :episode:  0\n",
      "q_loss:  [[[0.05841728]]]\n",
      "t:  614  :episode:  0\n",
      "q_loss:  [[[0.15136337]]]\n",
      "t:  615  :episode:  0\n",
      "q_loss:  [[[0.09424333]]]\n",
      "t:  616  :episode:  0\n",
      "q_loss:  [[[0.03653941]]]\n",
      "t:  617  :episode:  0\n",
      "q_loss:  [[[0.10145876]]]\n",
      "t:  618  :episode:  0\n",
      "q_loss:  [[[0.283107]]]\n",
      "t:  619  :episode:  0\n",
      "q_loss:  [[[0.33597285]]]\n",
      "t:  620  :episode:  0\n",
      "q_loss:  [[[0.10407585]]]\n",
      "t:  621  :episode:  0\n",
      "q_loss:  [[[0.2343973]]]\n",
      "t:  622  :episode:  0\n",
      "q_loss:  [[[0.05924245]]]\n",
      "t:  623  :episode:  0\n",
      "q_loss:  [[[0.33910832]]]\n",
      "t:  624  :episode:  0\n",
      "q_loss:  [[[0.28746027]]]\n",
      "t:  625  :episode:  0\n",
      "q_loss:  [[[0.34788036]]]\n",
      "t:  626  :episode:  0\n",
      "q_loss:  [[[0.12887672]]]\n",
      "t:  627  :episode:  0\n",
      "q_loss:  [[[0.10864782]]]\n",
      "t:  628  :episode:  0\n",
      "q_loss:  [[[0.29369485]]]\n",
      "t:  629  :episode:  0\n",
      "q_loss:  [[[0.32951725]]]\n",
      "t:  630  :episode:  0\n",
      "q_loss:  [[[0.26257506]]]\n",
      "t:  631  :episode:  0\n",
      "q_loss:  [[[0.10132904]]]\n",
      "t:  632  :episode:  0\n",
      "q_loss:  [[[0.21213432]]]\n",
      "t:  633  :episode:  0\n",
      "q_loss:  [[[0.12934418]]]\n",
      "t:  634  :episode:  0\n",
      "q_loss:  [[[2.7492118]]]\n",
      "t:  635  :episode:  0\n",
      "q_loss:  [[[0.23345888]]]\n",
      "t:  636  :episode:  0\n",
      "q_loss:  [[[0.2671225]]]\n",
      "t:  637  :episode:  0\n",
      "q_loss:  [[[0.16948308]]]\n",
      "t:  638  :episode:  0\n",
      "q_loss:  [[[0.08445026]]]\n",
      "t:  639  :episode:  0\n",
      "q_loss:  [[[0.35565454]]]\n",
      "t:  640  :episode:  0\n",
      "q_loss:  [[[0.31408298]]]\n",
      "t:  641  :episode:  0\n",
      "q_loss:  [[[0.48845345]]]\n",
      "t:  642  :episode:  0\n",
      "q_loss:  [[[0.9283434]]]\n",
      "t:  643  :episode:  0\n",
      "q_loss:  [[[0.30347356]]]\n",
      "t:  644  :episode:  0\n",
      "q_loss:  [[[0.36458805]]]\n",
      "t:  645  :episode:  0\n",
      "q_loss:  [[[0.42133534]]]\n",
      "t:  646  :episode:  0\n",
      "q_loss:  [[[0.09742321]]]\n",
      "t:  647  :episode:  0\n",
      "q_loss:  [[[0.29290035]]]\n",
      "t:  648  :episode:  0\n",
      "q_loss:  [[[0.10392055]]]\n",
      "t:  649  :episode:  0\n",
      "q_loss:  [[[0.25499958]]]\n",
      "t:  650  :episode:  0\n",
      "q_loss:  [[[0.14075997]]]\n",
      "t:  651  :episode:  0\n",
      "q_loss:  [[[0.18756235]]]\n",
      "t:  652  :episode:  0\n",
      "q_loss:  [[[0.1432158]]]\n",
      "t:  653  :episode:  0\n",
      "q_loss:  [[[0.15212978]]]\n",
      "t:  654  :episode:  0\n",
      "q_loss:  [[[0.07941362]]]\n",
      "t:  655  :episode:  0\n",
      "q_loss:  [[[0.19293584]]]\n",
      "t:  656  :episode:  0\n",
      "q_loss:  [[[0.10991808]]]\n",
      "t:  657  :episode:  0\n",
      "q_loss:  [[[0.19533542]]]\n",
      "t:  658  :episode:  0\n",
      "q_loss:  [[[0.04672279]]]\n",
      "t:  659  :episode:  0\n",
      "q_loss:  [[[0.04269765]]]\n",
      "t:  660  :episode:  0\n",
      "q_loss:  [[[0.14964157]]]\n",
      "t:  661  :episode:  0\n",
      "q_loss:  [[[0.12428208]]]\n",
      "t:  662  :episode:  0\n",
      "q_loss:  [[[0.11012767]]]\n",
      "t:  663  :episode:  0\n",
      "q_loss:  [[[0.11299135]]]\n",
      "t:  664  :episode:  0\n",
      "q_loss:  [[[0.1316778]]]\n",
      "t:  665  :episode:  0\n",
      "q_loss:  [[[0.08230333]]]\n",
      "t:  666  :episode:  0\n",
      "q_loss:  [[[0.18804571]]]\n",
      "t:  667  :episode:  0\n",
      "q_loss:  [[[0.478062]]]\n",
      "t:  668  :episode:  0\n",
      "q_loss:  [[[0.14353803]]]\n",
      "t:  669  :episode:  0\n",
      "q_loss:  [[[0.17177144]]]\n",
      "t:  670  :episode:  0\n",
      "q_loss:  [[[0.3536613]]]\n",
      "t:  671  :episode:  0\n",
      "q_loss:  [[[0.12065274]]]\n",
      "t:  672  :episode:  0\n",
      "q_loss:  [[[0.161994]]]\n",
      "t:  673  :episode:  0\n",
      "q_loss:  [[[0.12587632]]]\n",
      "t:  674  :episode:  0\n",
      "q_loss:  [[[0.16889456]]]\n",
      "t:  675  :episode:  0\n",
      "q_loss:  [[[0.09038755]]]\n",
      "t:  676  :episode:  0\n",
      "q_loss:  [[[0.2910756]]]\n",
      "t:  677  :episode:  0\n",
      "q_loss:  [[[0.11132658]]]\n",
      "t:  678  :episode:  0\n",
      "q_loss:  [[[0.16667339]]]\n",
      "t:  679  :episode:  0\n",
      "q_loss:  [[[0.32243395]]]\n",
      "t:  680  :episode:  0\n",
      "q_loss:  [[[0.24198136]]]\n",
      "t:  681  :episode:  0\n",
      "q_loss:  [[[0.06500106]]]\n",
      "t:  682  :episode:  0\n",
      "q_loss:  [[[0.09978028]]]\n",
      "t:  683  :episode:  0\n",
      "q_loss:  [[[0.1996843]]]\n",
      "t:  684  :episode:  0\n",
      "q_loss:  [[[0.21859261]]]\n",
      "t:  685  :episode:  0\n",
      "q_loss:  [[[0.0840071]]]\n",
      "t:  686  :episode:  0\n",
      "q_loss:  [[[0.12948936]]]\n",
      "t:  687  :episode:  0\n",
      "q_loss:  [[[0.14396769]]]\n",
      "t:  688  :episode:  0\n",
      "q_loss:  [[[0.27704158]]]\n",
      "t:  689  :episode:  0\n",
      "q_loss:  [[[0.07046927]]]\n",
      "t:  690  :episode:  0\n",
      "q_loss:  [[[0.08803723]]]\n",
      "t:  691  :episode:  0\n",
      "q_loss:  [[[0.05619182]]]\n",
      "t:  692  :episode:  0\n",
      "q_loss:  [[[0.19788928]]]\n",
      "t:  693  :episode:  0\n",
      "q_loss:  [[[0.1072505]]]\n",
      "t:  694  :episode:  0\n",
      "q_loss:  [[[0.14612335]]]\n",
      "t:  695  :episode:  0\n",
      "q_loss:  [[[0.16435234]]]\n",
      "t:  696  :episode:  0\n",
      "q_loss:  [[[0.25169358]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  697  :episode:  0\n",
      "q_loss:  [[[0.12697116]]]\n",
      "t:  698  :episode:  0\n",
      "q_loss:  [[[0.36982906]]]\n",
      "t:  699  :episode:  0\n",
      "q_loss:  [[[0.06739365]]]\n",
      "t:  700  :episode:  0\n",
      "q_loss:  [[[0.17727895]]]\n",
      "t:  701  :episode:  0\n",
      "q_loss:  [[[0.04546996]]]\n",
      "t:  702  :episode:  0\n",
      "q_loss:  [[[0.33565098]]]\n",
      "t:  703  :episode:  0\n",
      "q_loss:  [[[0.14910677]]]\n",
      "t:  704  :episode:  0\n",
      "q_loss:  [[[0.2802129]]]\n",
      "t:  705  :episode:  0\n",
      "q_loss:  [[[0.11113691]]]\n",
      "t:  706  :episode:  0\n",
      "q_loss:  [[[0.29497862]]]\n",
      "t:  707  :episode:  0\n",
      "q_loss:  [[[0.20365383]]]\n",
      "t:  708  :episode:  0\n",
      "q_loss:  [[[0.4209993]]]\n",
      "t:  709  :episode:  0\n",
      "q_loss:  [[[0.20478722]]]\n",
      "t:  710  :episode:  0\n",
      "q_loss:  [[[0.08837675]]]\n",
      "t:  711  :episode:  0\n",
      "q_loss:  [[[0.179288]]]\n",
      "t:  712  :episode:  0\n",
      "q_loss:  [[[0.4719761]]]\n",
      "t:  713  :episode:  0\n",
      "q_loss:  [[[0.03572735]]]\n",
      "t:  714  :episode:  0\n",
      "q_loss:  [[[0.11410885]]]\n",
      "t:  715  :episode:  0\n",
      "q_loss:  [[[0.14111272]]]\n",
      "t:  716  :episode:  0\n",
      "q_loss:  [[[0.18828443]]]\n",
      "t:  717  :episode:  0\n",
      "q_loss:  [[[0.2917118]]]\n",
      "t:  718  :episode:  0\n",
      "q_loss:  [[[0.24192137]]]\n",
      "t:  719  :episode:  0\n",
      "q_loss:  [[[0.8487624]]]\n",
      "t:  720  :episode:  0\n",
      "q_loss:  [[[0.18493485]]]\n",
      "t:  721  :episode:  0\n",
      "q_loss:  [[[0.3580096]]]\n",
      "t:  722  :episode:  0\n",
      "q_loss:  [[[0.2193129]]]\n",
      "t:  723  :episode:  0\n",
      "q_loss:  [[[0.5139169]]]\n",
      "t:  724  :episode:  0\n",
      "q_loss:  [[[0.05109287]]]\n",
      "t:  725  :episode:  0\n",
      "q_loss:  [[[0.08393791]]]\n",
      "t:  726  :episode:  0\n",
      "q_loss:  [[[0.20829654]]]\n",
      "t:  727  :episode:  0\n",
      "q_loss:  [[[0.17142463]]]\n",
      "t:  728  :episode:  0\n",
      "q_loss:  [[[0.25245935]]]\n",
      "t:  729  :episode:  0\n",
      "q_loss:  [[[0.09918609]]]\n",
      "t:  730  :episode:  0\n",
      "q_loss:  [[[0.13876334]]]\n",
      "t:  731  :episode:  0\n",
      "q_loss:  [[[0.10274223]]]\n",
      "t:  732  :episode:  0\n",
      "q_loss:  [[[0.1806806]]]\n",
      "t:  733  :episode:  0\n",
      "q_loss:  [[[0.1994054]]]\n",
      "t:  734  :episode:  0\n",
      "q_loss:  [[[0.10807449]]]\n",
      "t:  735  :episode:  0\n",
      "q_loss:  [[[0.5706187]]]\n",
      "t:  736  :episode:  0\n",
      "q_loss:  [[[0.20359373]]]\n",
      "t:  737  :episode:  0\n",
      "q_loss:  [[[0.4709314]]]\n",
      "t:  738  :episode:  0\n",
      "q_loss:  [[[0.18546072]]]\n",
      "t:  739  :episode:  0\n",
      "q_loss:  [[[0.16984175]]]\n",
      "t:  740  :episode:  0\n",
      "q_loss:  [[[0.06034908]]]\n",
      "t:  741  :episode:  0\n",
      "q_loss:  [[[0.14221184]]]\n",
      "t:  742  :episode:  0\n",
      "q_loss:  [[[0.1890361]]]\n",
      "t:  743  :episode:  0\n",
      "q_loss:  [[[0.15885293]]]\n",
      "t:  744  :episode:  0\n",
      "q_loss:  [[[0.17387319]]]\n",
      "t:  745  :episode:  0\n",
      "q_loss:  [[[0.32833523]]]\n",
      "t:  746  :episode:  0\n",
      "q_loss:  [[[0.12873664]]]\n",
      "t:  747  :episode:  0\n",
      "q_loss:  [[[0.15375695]]]\n",
      "t:  748  :episode:  0\n",
      "q_loss:  [[[0.1664049]]]\n",
      "t:  749  :episode:  0\n",
      "q_loss:  [[[0.5589081]]]\n",
      "t:  750  :episode:  0\n",
      "q_loss:  [[[0.24105334]]]\n",
      "t:  751  :episode:  0\n",
      "q_loss:  [[[0.07676978]]]\n",
      "t:  752  :episode:  0\n",
      "q_loss:  [[[0.16263646]]]\n",
      "t:  753  :episode:  0\n",
      "q_loss:  [[[0.11206982]]]\n",
      "t:  754  :episode:  0\n",
      "q_loss:  [[[0.09395873]]]\n",
      "t:  755  :episode:  0\n",
      "q_loss:  [[[0.5417093]]]\n",
      "t:  756  :episode:  0\n",
      "q_loss:  [[[0.21466151]]]\n",
      "t:  757  :episode:  0\n",
      "q_loss:  [[[0.24716654]]]\n",
      "t:  758  :episode:  0\n",
      "q_loss:  [[[8.773762]]]\n",
      "t:  759  :episode:  0\n",
      "q_loss:  [[[0.13998908]]]\n",
      "t:  760  :episode:  0\n",
      "q_loss:  [[[0.26843914]]]\n",
      "t:  761  :episode:  0\n",
      "q_loss:  [[[0.7621269]]]\n",
      "t:  762  :episode:  0\n",
      "q_loss:  [[[0.23751023]]]\n",
      "t:  763  :episode:  0\n",
      "q_loss:  [[[0.6165809]]]\n",
      "t:  764  :episode:  0\n",
      "q_loss:  [[[7.8927007]]]\n",
      "t:  765  :episode:  0\n",
      "q_loss:  [[[2.6789474]]]\n",
      "t:  766  :episode:  0\n",
      "q_loss:  [[[0.4607147]]]\n",
      "t:  767  :episode:  0\n",
      "q_loss:  [[[0.21783462]]]\n",
      "t:  768  :episode:  0\n",
      "q_loss:  [[[0.7920247]]]\n",
      "t:  769  :episode:  0\n",
      "q_loss:  [[[22.318567]]]\n",
      "t:  770  :episode:  0\n",
      "q_loss:  [[[0.23374219]]]\n",
      "t:  771  :episode:  0\n",
      "q_loss:  [[[0.45521525]]]\n",
      "t:  772  :episode:  0\n",
      "q_loss:  [[[8.954463]]]\n",
      "t:  773  :episode:  0\n",
      "q_loss:  [[[0.6297008]]]\n",
      "t:  774  :episode:  0\n",
      "q_loss:  [[[0.72539073]]]\n",
      "t:  775  :episode:  0\n",
      "q_loss:  [[[2.3713934]]]\n",
      "t:  776  :episode:  0\n",
      "q_loss:  [[[10.59176]]]\n",
      "t:  777  :episode:  0\n",
      "q_loss:  [[[4.6192527]]]\n",
      "t:  778  :episode:  0\n",
      "q_loss:  [[[4.4365745]]]\n",
      "t:  779  :episode:  0\n",
      "q_loss:  [[[1.603455]]]\n",
      "t:  780  :episode:  0\n",
      "q_loss:  [[[0.8934293]]]\n",
      "t:  781  :episode:  0\n",
      "q_loss:  [[[1.8078145]]]\n",
      "t:  782  :episode:  0\n",
      "q_loss:  [[[1.3163165]]]\n",
      "t:  783  :episode:  0\n",
      "q_loss:  [[[1.4486551]]]\n",
      "t:  784  :episode:  0\n",
      "q_loss:  [[[5.3677087]]]\n",
      "t:  785  :episode:  0\n",
      "q_loss:  [[[1.3452181]]]\n",
      "t:  786  :episode:  0\n",
      "q_loss:  [[[1.3884462]]]\n",
      "t:  787  :episode:  0\n",
      "q_loss:  [[[0.46818686]]]\n",
      "t:  788  :episode:  0\n",
      "q_loss:  [[[3.6885116]]]\n",
      "t:  789  :episode:  0\n",
      "q_loss:  [[[0.83342713]]]\n",
      "t:  790  :episode:  0\n",
      "q_loss:  [[[1.8330711]]]\n",
      "t:  791  :episode:  0\n",
      "q_loss:  [[[3.649585]]]\n",
      "t:  792  :episode:  0\n",
      "q_loss:  [[[3.2718525]]]\n",
      "t:  793  :episode:  0\n",
      "q_loss:  [[[1.1561985]]]\n",
      "t:  794  :episode:  0\n",
      "q_loss:  [[[2.5136743]]]\n",
      "t:  795  :episode:  0\n",
      "q_loss:  [[[2.9171314]]]\n",
      "t:  796  :episode:  0\n",
      "q_loss:  [[[0.8946233]]]\n",
      "t:  797  :episode:  0\n",
      "q_loss:  [[[0.48643032]]]\n",
      "t:  798  :episode:  0\n",
      "q_loss:  [[[0.66377205]]]\n",
      "t:  799  :episode:  0\n",
      "q_loss:  [[[2.5754862]]]\n",
      "t:  800  :episode:  0\n",
      "q_loss:  [[[0.49766067]]]\n",
      "t:  801  :episode:  0\n",
      "q_loss:  [[[1.5022024]]]\n",
      "t:  802  :episode:  0\n",
      "q_loss:  [[[0.80163753]]]\n",
      "t:  803  :episode:  0\n",
      "q_loss:  [[[0.7553206]]]\n",
      "t:  804  :episode:  0\n",
      "q_loss:  [[[0.9388729]]]\n",
      "t:  805  :episode:  0\n",
      "q_loss:  [[[1.7196428]]]\n",
      "t:  806  :episode:  0\n",
      "q_loss:  [[[1.2975284]]]\n",
      "t:  807  :episode:  0\n",
      "q_loss:  [[[0.66796005]]]\n",
      "t:  808  :episode:  0\n",
      "q_loss:  [[[0.5626744]]]\n",
      "t:  809  :episode:  0\n",
      "q_loss:  [[[0.27753907]]]\n",
      "t:  810  :episode:  0\n",
      "q_loss:  [[[0.24983767]]]\n",
      "t:  811  :episode:  0\n",
      "q_loss:  [[[0.27086535]]]\n",
      "t:  812  :episode:  0\n",
      "q_loss:  [[[0.77369183]]]\n",
      "t:  813  :episode:  0\n",
      "q_loss:  [[[0.6663252]]]\n",
      "t:  814  :episode:  0\n",
      "q_loss:  [[[0.5501929]]]\n",
      "t:  815  :episode:  0\n",
      "q_loss:  [[[0.29803237]]]\n",
      "t:  816  :episode:  0\n",
      "q_loss:  [[[1.58566]]]\n",
      "t:  817  :episode:  0\n",
      "q_loss:  [[[0.47649175]]]\n",
      "t:  818  :episode:  0\n",
      "q_loss:  [[[0.13934484]]]\n",
      "t:  819  :episode:  0\n",
      "q_loss:  [[[0.2552659]]]\n",
      "t:  820  :episode:  0\n",
      "q_loss:  [[[0.54489756]]]\n",
      "t:  821  :episode:  0\n",
      "q_loss:  [[[1.3060812]]]\n",
      "t:  822  :episode:  0\n",
      "q_loss:  [[[0.44075269]]]\n",
      "t:  823  :episode:  0\n",
      "q_loss:  [[[0.73969305]]]\n",
      "t:  824  :episode:  0\n",
      "q_loss:  [[[3.6045694]]]\n",
      "t:  825  :episode:  0\n",
      "q_loss:  [[[0.25473192]]]\n",
      "t:  826  :episode:  0\n",
      "q_loss:  [[[0.5026384]]]\n",
      "t:  827  :episode:  0\n",
      "q_loss:  [[[0.5150911]]]\n",
      "t:  828  :episode:  0\n",
      "q_loss:  [[[1.0837379]]]\n",
      "t:  829  :episode:  0\n",
      "q_loss:  [[[0.9987587]]]\n",
      "t:  830  :episode:  0\n",
      "q_loss:  [[[0.20382962]]]\n",
      "t:  831  :episode:  0\n",
      "q_loss:  [[[1.2863467]]]\n",
      "t:  832  :episode:  0\n",
      "q_loss:  [[[0.337306]]]\n",
      "t:  833  :episode:  0\n",
      "q_loss:  [[[0.472081]]]\n",
      "t:  834  :episode:  0\n",
      "q_loss:  [[[0.49818653]]]\n",
      "t:  835  :episode:  0\n",
      "q_loss:  [[[0.13516812]]]\n",
      "t:  836  :episode:  0\n",
      "q_loss:  [[[2.7721086]]]\n",
      "t:  837  :episode:  0\n",
      "q_loss:  [[[0.4386534]]]\n",
      "t:  838  :episode:  0\n",
      "q_loss:  [[[1.3033586]]]\n",
      "t:  839  :episode:  0\n",
      "q_loss:  [[[1.4239106]]]\n",
      "t:  840  :episode:  0\n",
      "q_loss:  [[[2.2451274]]]\n",
      "t:  841  :episode:  0\n",
      "q_loss:  [[[2.2270145]]]\n",
      "t:  842  :episode:  0\n",
      "q_loss:  [[[0.24570337]]]\n",
      "t:  843  :episode:  0\n",
      "q_loss:  [[[0.7228608]]]\n",
      "t:  844  :episode:  0\n",
      "q_loss:  [[[1.2544229]]]\n",
      "t:  845  :episode:  0\n",
      "q_loss:  [[[1.11411]]]\n",
      "t:  846  :episode:  0\n",
      "q_loss:  [[[0.35729125]]]\n",
      "t:  847  :episode:  0\n",
      "q_loss:  [[[0.6586859]]]\n",
      "t:  848  :episode:  0\n",
      "q_loss:  [[[3.7041411]]]\n",
      "t:  849  :episode:  0\n",
      "q_loss:  [[[1.3614132]]]\n",
      "t:  850  :episode:  0\n",
      "q_loss:  [[[0.1712036]]]\n",
      "t:  851  :episode:  0\n",
      "q_loss:  [[[1.0673299]]]\n",
      "t:  852  :episode:  0\n",
      "q_loss:  [[[0.56388485]]]\n",
      "t:  853  :episode:  0\n",
      "q_loss:  [[[0.4797159]]]\n",
      "t:  854  :episode:  0\n",
      "q_loss:  [[[0.4517316]]]\n",
      "t:  855  :episode:  0\n",
      "q_loss:  [[[1.0634794]]]\n",
      "t:  856  :episode:  0\n",
      "q_loss:  [[[0.8684683]]]\n",
      "t:  857  :episode:  0\n",
      "q_loss:  [[[0.33812043]]]\n",
      "t:  858  :episode:  0\n",
      "q_loss:  [[[1.215749]]]\n",
      "t:  859  :episode:  0\n",
      "q_loss:  [[[1.7694606]]]\n",
      "t:  860  :episode:  0\n",
      "q_loss:  [[[0.72595245]]]\n",
      "t:  861  :episode:  0\n",
      "q_loss:  [[[0.49135137]]]\n",
      "t:  862  :episode:  0\n",
      "q_loss:  [[[0.7955115]]]\n",
      "t:  863  :episode:  0\n",
      "q_loss:  [[[0.4578025]]]\n",
      "t:  864  :episode:  0\n",
      "q_loss:  [[[0.25370333]]]\n",
      "t:  865  :episode:  0\n",
      "q_loss:  [[[0.22270411]]]\n",
      "t:  866  :episode:  0\n",
      "q_loss:  [[[1.3670478]]]\n",
      "t:  867  :episode:  0\n",
      "q_loss:  [[[0.89039034]]]\n",
      "t:  868  :episode:  0\n",
      "q_loss:  [[[1.0977205]]]\n",
      "t:  869  :episode:  0\n",
      "q_loss:  [[[5.8903065]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  870  :episode:  0\n",
      "q_loss:  [[[0.40417144]]]\n",
      "t:  871  :episode:  0\n",
      "q_loss:  [[[0.5676562]]]\n",
      "t:  872  :episode:  0\n",
      "q_loss:  [[[0.43989778]]]\n",
      "t:  873  :episode:  0\n",
      "q_loss:  [[[0.5272615]]]\n",
      "t:  874  :episode:  0\n",
      "q_loss:  [[[0.80771196]]]\n",
      "t:  875  :episode:  0\n",
      "q_loss:  [[[0.28876722]]]\n",
      "t:  876  :episode:  0\n",
      "q_loss:  [[[0.4433344]]]\n",
      "t:  877  :episode:  0\n",
      "q_loss:  [[[0.93179744]]]\n",
      "t:  878  :episode:  0\n",
      "q_loss:  [[[4.5246863]]]\n",
      "t:  879  :episode:  0\n",
      "q_loss:  [[[0.4296605]]]\n",
      "t:  880  :episode:  0\n",
      "q_loss:  [[[2.7408109]]]\n",
      "t:  881  :episode:  0\n",
      "q_loss:  [[[2.2193964]]]\n",
      "t:  882  :episode:  0\n",
      "q_loss:  [[[0.5734664]]]\n",
      "t:  883  :episode:  0\n",
      "q_loss:  [[[1.1198556]]]\n",
      "t:  884  :episode:  0\n",
      "q_loss:  [[[0.7860615]]]\n",
      "t:  885  :episode:  0\n",
      "q_loss:  [[[0.1394102]]]\n",
      "t:  886  :episode:  0\n",
      "q_loss:  [[[0.62225306]]]\n",
      "t:  887  :episode:  0\n",
      "q_loss:  [[[0.64317]]]\n",
      "t:  888  :episode:  0\n",
      "q_loss:  [[[0.35608506]]]\n",
      "t:  889  :episode:  0\n",
      "q_loss:  [[[0.26189673]]]\n",
      "t:  890  :episode:  0\n",
      "q_loss:  [[[0.5914463]]]\n",
      "t:  891  :episode:  0\n",
      "q_loss:  [[[1.0502955]]]\n",
      "t:  892  :episode:  0\n",
      "q_loss:  [[[0.05130153]]]\n",
      "t:  893  :episode:  0\n",
      "q_loss:  [[[0.3892866]]]\n",
      "t:  894  :episode:  0\n",
      "q_loss:  [[[2.2793775]]]\n",
      "t:  895  :episode:  0\n",
      "q_loss:  [[[1.840739]]]\n",
      "t:  896  :episode:  0\n",
      "q_loss:  [[[0.42838782]]]\n",
      "t:  897  :episode:  0\n",
      "q_loss:  [[[0.38559473]]]\n",
      "t:  898  :episode:  0\n",
      "q_loss:  [[[0.18270662]]]\n",
      "t:  899  :episode:  0\n",
      "q_loss:  [[[0.50422114]]]\n",
      "t:  900  :episode:  0\n",
      "q_loss:  [[[0.6062958]]]\n",
      "t:  901  :episode:  0\n",
      "q_loss:  [[[0.4647817]]]\n",
      "t:  902  :episode:  0\n",
      "q_loss:  [[[28.173712]]]\n",
      "t:  903  :episode:  0\n",
      "q_loss:  [[[0.32382023]]]\n",
      "t:  904  :episode:  0\n",
      "q_loss:  [[[9.7360935]]]\n",
      "t:  905  :episode:  0\n",
      "q_loss:  [[[3.3761973]]]\n",
      "t:  906  :episode:  0\n",
      "q_loss:  [[[0.9662043]]]\n",
      "t:  907  :episode:  0\n",
      "q_loss:  [[[4.516861]]]\n",
      "t:  908  :episode:  0\n",
      "q_loss:  [[[0.35660234]]]\n",
      "t:  909  :episode:  0\n",
      "q_loss:  [[[1.9461814]]]\n",
      "t:  910  :episode:  0\n",
      "q_loss:  [[[0.49441957]]]\n",
      "t:  911  :episode:  0\n",
      "q_loss:  [[[5.783216]]]\n",
      "t:  912  :episode:  0\n",
      "q_loss:  [[[0.1869481]]]\n",
      "t:  913  :episode:  0\n",
      "q_loss:  [[[0.45178613]]]\n",
      "t:  914  :episode:  0\n",
      "q_loss:  [[[3.9848402]]]\n",
      "t:  915  :episode:  0\n",
      "q_loss:  [[[0.2887267]]]\n",
      "t:  916  :episode:  0\n",
      "q_loss:  [[[1.2182832]]]\n",
      "t:  917  :episode:  0\n",
      "q_loss:  [[[5.64891]]]\n",
      "t:  918  :episode:  0\n",
      "q_loss:  [[[0.95182824]]]\n",
      "t:  919  :episode:  0\n",
      "q_loss:  [[[0.6292862]]]\n",
      "t:  920  :episode:  0\n",
      "q_loss:  [[[15.349107]]]\n",
      "t:  921  :episode:  0\n",
      "q_loss:  [[[50.736095]]]\n",
      "t:  922  :episode:  0\n",
      "q_loss:  [[[4.40113]]]\n",
      "t:  923  :episode:  0\n",
      "q_loss:  [[[2.6942244]]]\n",
      "t:  924  :episode:  0\n",
      "q_loss:  [[[26.18528]]]\n",
      "t:  925  :episode:  0\n",
      "q_loss:  [[[3.4808373]]]\n",
      "t:  926  :episode:  0\n",
      "q_loss:  [[[4.2336183]]]\n",
      "t:  927  :episode:  0\n",
      "q_loss:  [[[4.926544]]]\n",
      "t:  928  :episode:  0\n",
      "q_loss:  [[[1.0038003]]]\n",
      "t:  929  :episode:  0\n",
      "q_loss:  [[[0.59204435]]]\n",
      "t:  930  :episode:  0\n",
      "q_loss:  [[[4.551177]]]\n",
      "t:  931  :episode:  0\n",
      "q_loss:  [[[6.1556153]]]\n",
      "t:  932  :episode:  0\n",
      "q_loss:  [[[60.65634]]]\n",
      "t:  933  :episode:  0\n",
      "q_loss:  [[[9.66947]]]\n",
      "t:  934  :episode:  0\n",
      "q_loss:  [[[1.949666]]]\n",
      "t:  935  :episode:  0\n",
      "q_loss:  [[[0.6006158]]]\n",
      "t:  936  :episode:  0\n",
      "q_loss:  [[[2.7079074]]]\n",
      "t:  937  :episode:  0\n",
      "q_loss:  [[[4.6266003]]]\n",
      "t:  938  :episode:  0\n",
      "q_loss:  [[[6.7202005]]]\n",
      "t:  939  :episode:  0\n",
      "q_loss:  [[[3.0831368]]]\n",
      "t:  940  :episode:  0\n",
      "q_loss:  [[[4.463746]]]\n",
      "t:  941  :episode:  0\n",
      "q_loss:  [[[1.5624851]]]\n",
      "t:  942  :episode:  0\n",
      "q_loss:  [[[1.7212842]]]\n",
      "t:  943  :episode:  0\n",
      "q_loss:  [[[5.126555]]]\n",
      "t:  944  :episode:  0\n",
      "q_loss:  [[[0.7707695]]]\n",
      "t:  945  :episode:  0\n",
      "q_loss:  [[[1.6244717]]]\n",
      "t:  946  :episode:  0\n",
      "q_loss:  [[[4.4741993]]]\n",
      "t:  947  :episode:  0\n",
      "q_loss:  [[[2.3826861]]]\n",
      "t:  948  :episode:  0\n",
      "q_loss:  [[[1.027927]]]\n",
      "t:  949  :episode:  0\n",
      "q_loss:  [[[1.6002543]]]\n",
      "t:  950  :episode:  0\n",
      "q_loss:  [[[0.83793354]]]\n",
      "t:  951  :episode:  0\n",
      "q_loss:  [[[1.003876]]]\n",
      "t:  952  :episode:  0\n",
      "q_loss:  [[[5.088872]]]\n",
      "t:  953  :episode:  0\n",
      "q_loss:  [[[0.73489946]]]\n",
      "t:  954  :episode:  0\n",
      "q_loss:  [[[3.7342029]]]\n",
      "t:  955  :episode:  0\n",
      "q_loss:  [[[1.7595607]]]\n",
      "t:  956  :episode:  0\n",
      "q_loss:  [[[5.2764482]]]\n",
      "t:  957  :episode:  0\n",
      "q_loss:  [[[1.1393464]]]\n",
      "t:  958  :episode:  0\n",
      "q_loss:  [[[0.09260178]]]\n",
      "t:  959  :episode:  0\n",
      "q_loss:  [[[1.740415]]]\n",
      "t:  960  :episode:  0\n",
      "q_loss:  [[[1.831734]]]\n",
      "t:  961  :episode:  0\n",
      "q_loss:  [[[0.26268613]]]\n",
      "t:  962  :episode:  0\n",
      "q_loss:  [[[1.5520693]]]\n",
      "t:  963  :episode:  0\n",
      "q_loss:  [[[0.5748259]]]\n",
      "t:  964  :episode:  0\n",
      "q_loss:  [[[36.67657]]]\n",
      "t:  965  :episode:  0\n",
      "q_loss:  [[[0.41634288]]]\n",
      "t:  966  :episode:  0\n",
      "q_loss:  [[[5.486921]]]\n",
      "t:  967  :episode:  0\n",
      "q_loss:  [[[3.773586]]]\n",
      "t:  968  :episode:  0\n",
      "q_loss:  [[[2.4282181]]]\n",
      "t:  969  :episode:  0\n",
      "q_loss:  [[[3.08551]]]\n",
      "t:  970  :episode:  0\n",
      "q_loss:  [[[13.98246]]]\n",
      "t:  971  :episode:  0\n",
      "q_loss:  [[[2.598184]]]\n",
      "t:  972  :episode:  0\n",
      "q_loss:  [[[1.0473121]]]\n",
      "t:  973  :episode:  0\n",
      "q_loss:  [[[0.39615947]]]\n",
      "t:  974  :episode:  0\n",
      "q_loss:  [[[2.3282735]]]\n",
      "t:  975  :episode:  0\n",
      "q_loss:  [[[4.535485]]]\n",
      "t:  976  :episode:  0\n",
      "q_loss:  [[[4.150572]]]\n",
      "t:  977  :episode:  0\n",
      "q_loss:  [[[18.149176]]]\n",
      "t:  978  :episode:  0\n",
      "q_loss:  [[[2.060398]]]\n",
      "t:  979  :episode:  0\n",
      "q_loss:  [[[1.0825499]]]\n",
      "t:  980  :episode:  0\n",
      "q_loss:  [[[0.61861205]]]\n",
      "t:  981  :episode:  0\n",
      "q_loss:  [[[0.6600548]]]\n",
      "t:  982  :episode:  0\n",
      "q_loss:  [[[3.0478435]]]\n",
      "t:  983  :episode:  0\n",
      "q_loss:  [[[0.82354796]]]\n",
      "t:  984  :episode:  0\n",
      "q_loss:  [[[5.6614056]]]\n",
      "t:  985  :episode:  0\n",
      "q_loss:  [[[3.7254395]]]\n",
      "t:  986  :episode:  0\n",
      "q_loss:  [[[2.3635993]]]\n",
      "t:  987  :episode:  0\n",
      "q_loss:  [[[0.2549151]]]\n",
      "t:  988  :episode:  0\n",
      "q_loss:  [[[0.3612277]]]\n",
      "t:  989  :episode:  0\n",
      "q_loss:  [[[57.326103]]]\n",
      "t:  990  :episode:  0\n",
      "q_loss:  [[[21.227558]]]\n",
      "t:  991  :episode:  0\n",
      "q_loss:  [[[2.769117]]]\n",
      "t:  992  :episode:  0\n",
      "q_loss:  [[[1.9802217]]]\n",
      "t:  993  :episode:  0\n",
      "q_loss:  [[[97.00769]]]\n",
      "t:  994  :episode:  0\n",
      "q_loss:  [[[7.5729737]]]\n",
      "t:  995  :episode:  0\n",
      "q_loss:  [[[0.5531676]]]\n",
      "t:  996  :episode:  0\n",
      "q_loss:  [[[41.995365]]]\n",
      "t:  997  :episode:  0\n",
      "q_loss:  [[[4.2354126]]]\n",
      "t:  998  :episode:  0\n",
      "q_loss:  [[[4.379338]]]\n",
      "t:  999  :episode:  0\n",
      "q_loss:  [[[1.311257]]]\n",
      "Episode 0 finished after 1000 timesteps with average reward -7568.334537790246\n",
      "t:  0  :episode:  1\n",
      "q_loss:  [[[2.6722662]]]\n",
      "t:  1  :episode:  1\n",
      "q_loss:  [[[1.6416407]]]\n",
      "t:  2  :episode:  1\n",
      "q_loss:  [[[10.766702]]]\n",
      "t:  3  :episode:  1\n",
      "q_loss:  [[[13.016533]]]\n",
      "t:  4  :episode:  1\n",
      "q_loss:  [[[3.0965827]]]\n",
      "t:  5  :episode:  1\n",
      "q_loss:  [[[1.6600573]]]\n",
      "t:  6  :episode:  1\n",
      "q_loss:  [[[6.8259478]]]\n",
      "t:  7  :episode:  1\n",
      "q_loss:  [[[13.533634]]]\n",
      "t:  8  :episode:  1\n",
      "q_loss:  [[[1.1199336]]]\n",
      "t:  9  :episode:  1\n",
      "q_loss:  [[[2.7245898]]]\n",
      "t:  10  :episode:  1\n",
      "q_loss:  [[[3.8393054]]]\n",
      "t:  11  :episode:  1\n",
      "q_loss:  [[[1.6130037]]]\n",
      "t:  12  :episode:  1\n",
      "q_loss:  [[[34.348347]]]\n",
      "t:  13  :episode:  1\n",
      "q_loss:  [[[47.030983]]]\n",
      "t:  14  :episode:  1\n",
      "q_loss:  [[[5.4207582]]]\n",
      "t:  15  :episode:  1\n",
      "q_loss:  [[[4.667267]]]\n",
      "t:  16  :episode:  1\n",
      "q_loss:  [[[1.6690555]]]\n",
      "t:  17  :episode:  1\n",
      "q_loss:  [[[5.2692275]]]\n",
      "t:  18  :episode:  1\n",
      "q_loss:  [[[24.805025]]]\n",
      "t:  19  :episode:  1\n",
      "q_loss:  [[[3.3511353]]]\n",
      "t:  20  :episode:  1\n",
      "q_loss:  [[[3.7954853]]]\n",
      "t:  21  :episode:  1\n",
      "q_loss:  [[[4.5976696]]]\n",
      "t:  22  :episode:  1\n",
      "q_loss:  [[[5.9200344]]]\n",
      "t:  23  :episode:  1\n",
      "q_loss:  [[[87.71675]]]\n",
      "t:  24  :episode:  1\n",
      "q_loss:  [[[16.947449]]]\n",
      "t:  25  :episode:  1\n",
      "q_loss:  [[[121.35072]]]\n",
      "t:  26  :episode:  1\n",
      "q_loss:  [[[2.3006122]]]\n",
      "t:  27  :episode:  1\n",
      "q_loss:  [[[8.866633]]]\n",
      "t:  28  :episode:  1\n",
      "q_loss:  [[[1.876647]]]\n",
      "t:  29  :episode:  1\n",
      "q_loss:  [[[1.8431529]]]\n",
      "t:  30  :episode:  1\n",
      "q_loss:  [[[29.308605]]]\n",
      "t:  31  :episode:  1\n",
      "q_loss:  [[[66.52162]]]\n",
      "t:  32  :episode:  1\n",
      "q_loss:  [[[1.7659672]]]\n",
      "t:  33  :episode:  1\n",
      "q_loss:  [[[4.0973]]]\n",
      "t:  34  :episode:  1\n",
      "q_loss:  [[[25.651001]]]\n",
      "t:  35  :episode:  1\n",
      "q_loss:  [[[199.44563]]]\n",
      "t:  36  :episode:  1\n",
      "q_loss:  [[[5.4688106]]]\n",
      "t:  37  :episode:  1\n",
      "q_loss:  [[[32.024723]]]\n",
      "t:  38  :episode:  1\n",
      "q_loss:  [[[0.999593]]]\n",
      "t:  39  :episode:  1\n",
      "q_loss:  [[[2.5862598]]]\n",
      "t:  40  :episode:  1\n",
      "q_loss:  [[[2.4897368]]]\n",
      "t:  41  :episode:  1\n",
      "q_loss:  [[[19.023506]]]\n",
      "t:  42  :episode:  1\n",
      "q_loss:  [[[2.7788234]]]\n",
      "t:  43  :episode:  1\n",
      "q_loss:  [[[5.9143534]]]\n",
      "t:  44  :episode:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [[[5.156314]]]\n",
      "t:  45  :episode:  1\n",
      "q_loss:  [[[12.850725]]]\n",
      "t:  46  :episode:  1\n",
      "q_loss:  [[[1.3968465]]]\n",
      "t:  47  :episode:  1\n",
      "q_loss:  [[[1.9760733]]]\n",
      "t:  48  :episode:  1\n",
      "q_loss:  [[[14.062187]]]\n",
      "t:  49  :episode:  1\n",
      "q_loss:  [[[21.002018]]]\n",
      "t:  50  :episode:  1\n",
      "q_loss:  [[[8.87058]]]\n",
      "t:  51  :episode:  1\n",
      "q_loss:  [[[4.438919]]]\n",
      "t:  52  :episode:  1\n",
      "q_loss:  [[[3.6484988]]]\n",
      "t:  53  :episode:  1\n",
      "q_loss:  [[[2.3930821]]]\n",
      "t:  54  :episode:  1\n",
      "q_loss:  [[[5.445767]]]\n",
      "t:  55  :episode:  1\n",
      "q_loss:  [[[3.4786744]]]\n",
      "t:  56  :episode:  1\n",
      "q_loss:  [[[76.77724]]]\n",
      "t:  57  :episode:  1\n",
      "q_loss:  [[[1.3711998]]]\n",
      "t:  58  :episode:  1\n",
      "q_loss:  [[[5.7507524]]]\n",
      "t:  59  :episode:  1\n",
      "q_loss:  [[[2.6085715]]]\n",
      "t:  60  :episode:  1\n",
      "q_loss:  [[[118.60094]]]\n",
      "t:  61  :episode:  1\n",
      "q_loss:  [[[1.0640218]]]\n",
      "t:  62  :episode:  1\n",
      "q_loss:  [[[43.457993]]]\n",
      "t:  63  :episode:  1\n",
      "q_loss:  [[[4.0612545]]]\n",
      "t:  64  :episode:  1\n",
      "q_loss:  [[[15.90232]]]\n",
      "t:  65  :episode:  1\n",
      "q_loss:  [[[5.78113]]]\n",
      "t:  66  :episode:  1\n",
      "q_loss:  [[[2.7583404]]]\n",
      "t:  67  :episode:  1\n",
      "q_loss:  [[[4.7716956]]]\n",
      "t:  68  :episode:  1\n",
      "q_loss:  [[[4.8687763]]]\n",
      "t:  69  :episode:  1\n",
      "q_loss:  [[[13.568948]]]\n",
      "t:  70  :episode:  1\n",
      "q_loss:  [[[13.174346]]]\n",
      "t:  71  :episode:  1\n",
      "q_loss:  [[[1.8087506]]]\n",
      "t:  72  :episode:  1\n",
      "q_loss:  [[[7.0911574]]]\n",
      "t:  73  :episode:  1\n",
      "q_loss:  [[[43.963554]]]\n",
      "t:  74  :episode:  1\n",
      "q_loss:  [[[43.98204]]]\n",
      "t:  75  :episode:  1\n",
      "q_loss:  [[[29.779186]]]\n",
      "t:  76  :episode:  1\n",
      "q_loss:  [[[6.5062714]]]\n",
      "t:  77  :episode:  1\n",
      "q_loss:  [[[4.22935]]]\n",
      "t:  78  :episode:  1\n",
      "q_loss:  [[[10.686404]]]\n",
      "t:  79  :episode:  1\n",
      "q_loss:  [[[3.2771926]]]\n",
      "t:  80  :episode:  1\n",
      "q_loss:  [[[14.415218]]]\n",
      "t:  81  :episode:  1\n",
      "q_loss:  [[[2.5790029]]]\n",
      "t:  82  :episode:  1\n",
      "q_loss:  [[[41.922794]]]\n",
      "t:  83  :episode:  1\n",
      "q_loss:  [[[2.3056557]]]\n",
      "t:  84  :episode:  1\n",
      "q_loss:  [[[3.164704]]]\n",
      "t:  85  :episode:  1\n",
      "q_loss:  [[[33.2195]]]\n",
      "t:  86  :episode:  1\n",
      "q_loss:  [[[7.289488]]]\n",
      "t:  87  :episode:  1\n",
      "q_loss:  [[[38.716534]]]\n",
      "t:  88  :episode:  1\n",
      "q_loss:  [[[4.262697]]]\n",
      "t:  89  :episode:  1\n",
      "q_loss:  [[[17.294264]]]\n",
      "t:  90  :episode:  1\n",
      "q_loss:  [[[17.23148]]]\n",
      "t:  91  :episode:  1\n",
      "q_loss:  [[[3.8473577]]]\n",
      "t:  92  :episode:  1\n",
      "q_loss:  [[[4.5723367]]]\n",
      "t:  93  :episode:  1\n",
      "q_loss:  [[[2.9726863]]]\n",
      "t:  94  :episode:  1\n",
      "q_loss:  [[[14.744913]]]\n",
      "t:  95  :episode:  1\n",
      "q_loss:  [[[51.308075]]]\n",
      "t:  96  :episode:  1\n",
      "q_loss:  [[[33.653183]]]\n",
      "t:  97  :episode:  1\n",
      "q_loss:  [[[2.1010165]]]\n",
      "t:  98  :episode:  1\n",
      "q_loss:  [[[1.793288]]]\n",
      "t:  99  :episode:  1\n",
      "q_loss:  [[[4.3367777]]]\n",
      "t:  100  :episode:  1\n",
      "q_loss:  [[[19.442522]]]\n",
      "t:  101  :episode:  1\n",
      "q_loss:  [[[35.70351]]]\n",
      "t:  102  :episode:  1\n",
      "q_loss:  [[[53.111248]]]\n",
      "t:  103  :episode:  1\n",
      "q_loss:  [[[26.252544]]]\n",
      "t:  104  :episode:  1\n",
      "q_loss:  [[[2.2351103]]]\n",
      "t:  105  :episode:  1\n",
      "q_loss:  [[[28.562103]]]\n",
      "t:  106  :episode:  1\n",
      "q_loss:  [[[21.901747]]]\n",
      "t:  107  :episode:  1\n",
      "q_loss:  [[[7.9568996]]]\n",
      "t:  108  :episode:  1\n",
      "q_loss:  [[[6.45804]]]\n",
      "t:  109  :episode:  1\n",
      "q_loss:  [[[3.5694575]]]\n",
      "t:  110  :episode:  1\n",
      "q_loss:  [[[33.83626]]]\n",
      "t:  111  :episode:  1\n",
      "q_loss:  [[[9.043144]]]\n",
      "t:  112  :episode:  1\n",
      "q_loss:  [[[10.578702]]]\n",
      "t:  113  :episode:  1\n",
      "q_loss:  [[[12.825959]]]\n",
      "t:  114  :episode:  1\n",
      "q_loss:  [[[5.0712805]]]\n",
      "t:  115  :episode:  1\n",
      "q_loss:  [[[7.3385925]]]\n",
      "t:  116  :episode:  1\n",
      "q_loss:  [[[7.90049]]]\n",
      "t:  117  :episode:  1\n",
      "q_loss:  [[[19.561977]]]\n",
      "t:  118  :episode:  1\n",
      "q_loss:  [[[7.5620103]]]\n",
      "t:  119  :episode:  1\n",
      "q_loss:  [[[9.803804]]]\n",
      "t:  120  :episode:  1\n",
      "q_loss:  [[[2.3691554]]]\n",
      "t:  121  :episode:  1\n",
      "q_loss:  [[[3.3340502]]]\n",
      "t:  122  :episode:  1\n",
      "q_loss:  [[[33.9691]]]\n",
      "t:  123  :episode:  1\n",
      "q_loss:  [[[2.572258]]]\n",
      "t:  124  :episode:  1\n",
      "q_loss:  [[[2.4865704]]]\n",
      "t:  125  :episode:  1\n",
      "q_loss:  [[[5.078642]]]\n",
      "t:  126  :episode:  1\n",
      "q_loss:  [[[2.578035]]]\n",
      "t:  127  :episode:  1\n",
      "q_loss:  [[[10.469684]]]\n",
      "t:  128  :episode:  1\n",
      "q_loss:  [[[2.3090875]]]\n",
      "t:  129  :episode:  1\n",
      "q_loss:  [[[6.0744224]]]\n",
      "t:  130  :episode:  1\n",
      "q_loss:  [[[2.8547792]]]\n",
      "t:  131  :episode:  1\n",
      "q_loss:  [[[3.0194929]]]\n",
      "t:  132  :episode:  1\n",
      "q_loss:  [[[5.3271074]]]\n",
      "t:  133  :episode:  1\n",
      "q_loss:  [[[0.78657556]]]\n",
      "t:  134  :episode:  1\n",
      "q_loss:  [[[2.123195]]]\n",
      "t:  135  :episode:  1\n",
      "q_loss:  [[[13.07263]]]\n",
      "t:  136  :episode:  1\n",
      "q_loss:  [[[4.573381]]]\n",
      "t:  137  :episode:  1\n",
      "q_loss:  [[[6.840424]]]\n",
      "t:  138  :episode:  1\n",
      "q_loss:  [[[5.3704724]]]\n",
      "t:  139  :episode:  1\n",
      "q_loss:  [[[17.29223]]]\n",
      "t:  140  :episode:  1\n",
      "q_loss:  [[[3.3336823]]]\n",
      "t:  141  :episode:  1\n",
      "q_loss:  [[[1.7958698]]]\n",
      "t:  142  :episode:  1\n",
      "q_loss:  [[[4.0305605]]]\n",
      "t:  143  :episode:  1\n",
      "q_loss:  [[[2.9696965]]]\n",
      "t:  144  :episode:  1\n",
      "q_loss:  [[[17.509256]]]\n",
      "t:  145  :episode:  1\n",
      "q_loss:  [[[2.3816385]]]\n",
      "t:  146  :episode:  1\n",
      "q_loss:  [[[4.0840945]]]\n",
      "t:  147  :episode:  1\n",
      "q_loss:  [[[1.2167703]]]\n",
      "t:  148  :episode:  1\n",
      "q_loss:  [[[0.6653979]]]\n",
      "t:  149  :episode:  1\n",
      "q_loss:  [[[0.60848075]]]\n",
      "t:  150  :episode:  1\n",
      "q_loss:  [[[17.292324]]]\n",
      "t:  151  :episode:  1\n",
      "q_loss:  [[[6.056036]]]\n",
      "t:  152  :episode:  1\n",
      "q_loss:  [[[0.58029944]]]\n",
      "t:  153  :episode:  1\n",
      "q_loss:  [[[4.0114503]]]\n",
      "t:  154  :episode:  1\n",
      "q_loss:  [[[1.9878212]]]\n",
      "t:  155  :episode:  1\n",
      "q_loss:  [[[8.966555]]]\n",
      "t:  156  :episode:  1\n",
      "q_loss:  [[[0.78714097]]]\n",
      "t:  157  :episode:  1\n",
      "q_loss:  [[[3.3275983]]]\n",
      "t:  158  :episode:  1\n",
      "q_loss:  [[[0.4355231]]]\n",
      "t:  159  :episode:  1\n",
      "q_loss:  [[[0.70468277]]]\n",
      "t:  160  :episode:  1\n",
      "q_loss:  [[[3.5115228]]]\n",
      "t:  161  :episode:  1\n",
      "q_loss:  [[[1.9623495]]]\n",
      "t:  162  :episode:  1\n",
      "q_loss:  [[[0.5324279]]]\n",
      "t:  163  :episode:  1\n",
      "q_loss:  [[[0.5885973]]]\n",
      "t:  164  :episode:  1\n",
      "q_loss:  [[[12.972343]]]\n",
      "t:  165  :episode:  1\n",
      "q_loss:  [[[1.5554997]]]\n",
      "t:  166  :episode:  1\n",
      "q_loss:  [[[61.9629]]]\n",
      "t:  167  :episode:  1\n",
      "q_loss:  [[[0.6203989]]]\n",
      "t:  168  :episode:  1\n",
      "q_loss:  [[[0.54486525]]]\n",
      "t:  169  :episode:  1\n",
      "q_loss:  [[[1.0992588]]]\n",
      "t:  170  :episode:  1\n",
      "q_loss:  [[[0.83708507]]]\n",
      "t:  171  :episode:  1\n",
      "q_loss:  [[[1.2850868]]]\n",
      "t:  172  :episode:  1\n",
      "q_loss:  [[[4.2125115]]]\n",
      "t:  173  :episode:  1\n",
      "q_loss:  [[[2.5208285]]]\n",
      "t:  174  :episode:  1\n",
      "q_loss:  [[[1.4403899]]]\n",
      "t:  175  :episode:  1\n",
      "q_loss:  [[[6.287796]]]\n",
      "t:  176  :episode:  1\n",
      "q_loss:  [[[0.8847576]]]\n",
      "t:  177  :episode:  1\n",
      "q_loss:  [[[7.769388]]]\n",
      "t:  178  :episode:  1\n",
      "q_loss:  [[[3.4528408]]]\n",
      "t:  179  :episode:  1\n",
      "q_loss:  [[[7.37196]]]\n",
      "t:  180  :episode:  1\n",
      "q_loss:  [[[4.5274563]]]\n",
      "t:  181  :episode:  1\n",
      "q_loss:  [[[0.8712599]]]\n",
      "t:  182  :episode:  1\n",
      "q_loss:  [[[2.3027492]]]\n",
      "t:  183  :episode:  1\n",
      "q_loss:  [[[9.587]]]\n",
      "t:  184  :episode:  1\n",
      "q_loss:  [[[6.366646]]]\n",
      "t:  185  :episode:  1\n",
      "q_loss:  [[[4.8304095]]]\n",
      "t:  186  :episode:  1\n",
      "q_loss:  [[[34.03431]]]\n",
      "t:  187  :episode:  1\n",
      "q_loss:  [[[2.6187925]]]\n",
      "t:  188  :episode:  1\n",
      "q_loss:  [[[2.1160903]]]\n",
      "t:  189  :episode:  1\n",
      "q_loss:  [[[1.9861267]]]\n",
      "t:  190  :episode:  1\n",
      "q_loss:  [[[1.8413057]]]\n",
      "t:  191  :episode:  1\n",
      "q_loss:  [[[4.5879526]]]\n",
      "t:  192  :episode:  1\n",
      "q_loss:  [[[14.582901]]]\n",
      "t:  193  :episode:  1\n",
      "q_loss:  [[[2.1723988]]]\n",
      "t:  194  :episode:  1\n",
      "q_loss:  [[[2.8441944]]]\n",
      "t:  195  :episode:  1\n",
      "q_loss:  [[[2.874235]]]\n",
      "t:  196  :episode:  1\n",
      "q_loss:  [[[4.221633]]]\n",
      "t:  197  :episode:  1\n",
      "q_loss:  [[[1.708518]]]\n",
      "t:  198  :episode:  1\n",
      "q_loss:  [[[1.9429977]]]\n",
      "t:  199  :episode:  1\n",
      "q_loss:  [[[2.1951954]]]\n",
      "t:  200  :episode:  1\n",
      "q_loss:  [[[4.595538]]]\n",
      "t:  201  :episode:  1\n",
      "q_loss:  [[[27.950657]]]\n",
      "t:  202  :episode:  1\n",
      "q_loss:  [[[2.4059453]]]\n",
      "t:  203  :episode:  1\n",
      "q_loss:  [[[1.2853777]]]\n",
      "t:  204  :episode:  1\n",
      "q_loss:  [[[0.52260715]]]\n",
      "t:  205  :episode:  1\n",
      "q_loss:  [[[2.2388563]]]\n",
      "t:  206  :episode:  1\n",
      "q_loss:  [[[1.1622853]]]\n",
      "t:  207  :episode:  1\n",
      "q_loss:  [[[2.735845]]]\n",
      "t:  208  :episode:  1\n",
      "q_loss:  [[[4.6893573]]]\n",
      "t:  209  :episode:  1\n",
      "q_loss:  [[[1.0997761]]]\n",
      "t:  210  :episode:  1\n",
      "q_loss:  [[[2.0957978]]]\n",
      "t:  211  :episode:  1\n",
      "q_loss:  [[[1.223934]]]\n",
      "t:  212  :episode:  1\n",
      "q_loss:  [[[1.2652133]]]\n",
      "t:  213  :episode:  1\n",
      "q_loss:  [[[11.249469]]]\n",
      "t:  214  :episode:  1\n",
      "q_loss:  [[[6.601349]]]\n",
      "t:  215  :episode:  1\n",
      "q_loss:  [[[2.621101]]]\n",
      "t:  216  :episode:  1\n",
      "q_loss:  [[[0.6223186]]]\n",
      "t:  217  :episode:  1\n",
      "q_loss:  [[[0.6615467]]]\n",
      "t:  218  :episode:  1\n",
      "q_loss:  [[[5.226079]]]\n",
      "t:  219  :episode:  1\n",
      "q_loss:  [[[3.6242778]]]\n",
      "t:  220  :episode:  1\n",
      "q_loss:  [[[23.158604]]]\n",
      "t:  221  :episode:  1\n",
      "q_loss:  [[[1.9141563]]]\n",
      "t:  222  :episode:  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_loss:  [[[6.272296]]]\n",
      "t:  223  :episode:  1\n",
      "q_loss:  [[[3.1622462]]]\n",
      "t:  224  :episode:  1\n",
      "q_loss:  [[[2.83368]]]\n",
      "t:  225  :episode:  1\n",
      "q_loss:  [[[0.67198944]]]\n",
      "t:  226  :episode:  1\n",
      "q_loss:  [[[18.823359]]]\n",
      "t:  227  :episode:  1\n",
      "q_loss:  [[[3.7525167]]]\n",
      "t:  228  :episode:  1\n",
      "q_loss:  [[[0.70297396]]]\n",
      "t:  229  :episode:  1\n",
      "q_loss:  [[[3.479178]]]\n",
      "t:  230  :episode:  1\n",
      "q_loss:  [[[2.8217375]]]\n",
      "t:  231  :episode:  1\n",
      "q_loss:  [[[7.8781915]]]\n",
      "t:  232  :episode:  1\n",
      "q_loss:  [[[4.1015596]]]\n",
      "t:  233  :episode:  1\n",
      "q_loss:  [[[1.2546742]]]\n",
      "t:  234  :episode:  1\n",
      "q_loss:  [[[1.1565366]]]\n",
      "t:  235  :episode:  1\n",
      "q_loss:  [[[1.7441208]]]\n",
      "t:  236  :episode:  1\n",
      "q_loss:  [[[61.538654]]]\n",
      "t:  237  :episode:  1\n",
      "q_loss:  [[[6.711359]]]\n",
      "t:  238  :episode:  1\n",
      "q_loss:  [[[0.6709963]]]\n",
      "t:  239  :episode:  1\n",
      "q_loss:  [[[3.056792]]]\n",
      "t:  240  :episode:  1\n",
      "q_loss:  [[[2.2289307]]]\n",
      "t:  241  :episode:  1\n",
      "q_loss:  [[[4.0029902]]]\n",
      "t:  242  :episode:  1\n",
      "q_loss:  [[[49.86375]]]\n",
      "t:  243  :episode:  1\n",
      "q_loss:  [[[3.8996036]]]\n",
      "t:  244  :episode:  1\n",
      "q_loss:  [[[3.2454371]]]\n",
      "t:  245  :episode:  1\n",
      "q_loss:  [[[2.498805]]]\n",
      "t:  246  :episode:  1\n",
      "q_loss:  [[[1.3099601]]]\n",
      "t:  247  :episode:  1\n",
      "q_loss:  [[[0.9311068]]]\n",
      "t:  248  :episode:  1\n",
      "q_loss:  [[[1.1604419]]]\n",
      "t:  249  :episode:  1\n",
      "q_loss:  [[[4.0941954]]]\n",
      "t:  250  :episode:  1\n",
      "q_loss:  [[[7.1771336]]]\n",
      "t:  251  :episode:  1\n",
      "q_loss:  [[[2.6269495]]]\n",
      "t:  252  :episode:  1\n",
      "q_loss:  [[[9.082766]]]\n",
      "t:  253  :episode:  1\n",
      "q_loss:  [[[1.040204]]]\n",
      "t:  254  :episode:  1\n",
      "q_loss:  [[[0.6541039]]]\n",
      "t:  255  :episode:  1\n",
      "q_loss:  [[[2.288052]]]\n",
      "t:  256  :episode:  1\n",
      "q_loss:  [[[6.83084]]]\n",
      "t:  257  :episode:  1\n",
      "q_loss:  [[[12.69079]]]\n",
      "t:  258  :episode:  1\n",
      "q_loss:  [[[33.520622]]]\n",
      "t:  259  :episode:  1\n",
      "q_loss:  [[[2.3324497]]]\n",
      "t:  260  :episode:  1\n",
      "q_loss:  [[[1.4738948]]]\n",
      "t:  261  :episode:  1\n",
      "q_loss:  [[[1.3604393]]]\n",
      "t:  262  :episode:  1\n",
      "q_loss:  [[[1.0831885]]]\n",
      "t:  263  :episode:  1\n",
      "q_loss:  [[[1.4003258]]]\n",
      "t:  264  :episode:  1\n",
      "q_loss:  [[[1.0825629]]]\n",
      "t:  265  :episode:  1\n",
      "q_loss:  [[[8.517639]]]\n",
      "t:  266  :episode:  1\n",
      "q_loss:  [[[3.7254317]]]\n",
      "t:  267  :episode:  1\n",
      "q_loss:  [[[1.9410913]]]\n",
      "t:  268  :episode:  1\n",
      "q_loss:  [[[1.27452]]]\n",
      "t:  269  :episode:  1\n",
      "q_loss:  [[[0.9139675]]]\n",
      "t:  270  :episode:  1\n",
      "q_loss:  [[[10.449856]]]\n",
      "t:  271  :episode:  1\n",
      "q_loss:  [[[1.1082911]]]\n",
      "t:  272  :episode:  1\n",
      "q_loss:  [[[7.343728]]]\n",
      "t:  273  :episode:  1\n",
      "q_loss:  [[[4.7983317]]]\n",
      "t:  274  :episode:  1\n",
      "q_loss:  [[[3.0912852]]]\n",
      "t:  275  :episode:  1\n",
      "q_loss:  [[[3.1434617]]]\n",
      "t:  276  :episode:  1\n",
      "q_loss:  [[[1.6884885]]]\n",
      "t:  277  :episode:  1\n",
      "q_loss:  [[[3.7076488]]]\n",
      "t:  278  :episode:  1\n",
      "q_loss:  [[[1.0193257]]]\n",
      "t:  279  :episode:  1\n",
      "q_loss:  [[[1.2966944]]]\n",
      "t:  280  :episode:  1\n",
      "q_loss:  [[[2.5308056]]]\n",
      "t:  281  :episode:  1\n",
      "q_loss:  [[[2.5899377]]]\n",
      "t:  282  :episode:  1\n",
      "q_loss:  [[[26.996027]]]\n",
      "t:  283  :episode:  1\n",
      "q_loss:  [[[1.0065949]]]\n",
      "t:  284  :episode:  1\n",
      "q_loss:  [[[1.0432272]]]\n",
      "t:  285  :episode:  1\n",
      "q_loss:  [[[1.5059743]]]\n",
      "t:  286  :episode:  1\n",
      "q_loss:  [[[1.0120053]]]\n",
      "t:  287  :episode:  1\n",
      "q_loss:  [[[10.356549]]]\n",
      "t:  288  :episode:  1\n",
      "q_loss:  [[[2.0971446]]]\n",
      "t:  289  :episode:  1\n",
      "q_loss:  [[[1.7264249]]]\n",
      "t:  290  :episode:  1\n",
      "q_loss:  [[[0.6190537]]]\n",
      "t:  291  :episode:  1\n",
      "q_loss:  [[[22.915049]]]\n",
      "t:  292  :episode:  1\n",
      "q_loss:  [[[0.505694]]]\n",
      "t:  293  :episode:  1\n",
      "q_loss:  [[[0.7135866]]]\n",
      "t:  294  :episode:  1\n",
      "q_loss:  [[[2.0208979]]]\n",
      "t:  295  :episode:  1\n",
      "q_loss:  [[[2.31031]]]\n",
      "t:  296  :episode:  1\n",
      "q_loss:  [[[5.3282204]]]\n",
      "t:  297  :episode:  1\n",
      "q_loss:  [[[50.849342]]]\n",
      "t:  298  :episode:  1\n",
      "q_loss:  [[[1.7554463]]]\n",
      "t:  299  :episode:  1\n",
      "q_loss:  [[[1.2785876]]]\n",
      "t:  300  :episode:  1\n",
      "q_loss:  [[[1.4268081]]]\n",
      "t:  301  :episode:  1\n",
      "q_loss:  [[[1.8867061]]]\n",
      "t:  302  :episode:  1\n",
      "q_loss:  [[[1.115982]]]\n",
      "t:  303  :episode:  1\n",
      "q_loss:  [[[1.4996537]]]\n",
      "t:  304  :episode:  1\n",
      "q_loss:  [[[1.5706694]]]\n",
      "t:  305  :episode:  1\n",
      "q_loss:  [[[3.2702234]]]\n",
      "t:  306  :episode:  1\n",
      "q_loss:  [[[6.605013]]]\n",
      "t:  307  :episode:  1\n",
      "q_loss:  [[[1.4114177]]]\n",
      "t:  308  :episode:  1\n",
      "q_loss:  [[[4.307262]]]\n",
      "t:  309  :episode:  1\n",
      "q_loss:  [[[10.1919775]]]\n",
      "t:  310  :episode:  1\n",
      "q_loss:  [[[27.136358]]]\n",
      "t:  311  :episode:  1\n",
      "q_loss:  [[[3.801433]]]\n",
      "t:  312  :episode:  1\n",
      "q_loss:  [[[4.979846]]]\n",
      "t:  313  :episode:  1\n",
      "q_loss:  [[[1.7603743]]]\n",
      "t:  314  :episode:  1\n",
      "q_loss:  [[[6.3462257]]]\n",
      "t:  315  :episode:  1\n",
      "q_loss:  [[[3.7789798]]]\n",
      "t:  316  :episode:  1\n",
      "q_loss:  [[[7.6386833]]]\n",
      "t:  317  :episode:  1\n",
      "q_loss:  [[[2.6965365]]]\n",
      "t:  318  :episode:  1\n",
      "q_loss:  [[[1.5410677]]]\n",
      "t:  319  :episode:  1\n",
      "q_loss:  [[[2.6676745]]]\n",
      "t:  320  :episode:  1\n",
      "q_loss:  [[[1.4584485]]]\n",
      "t:  321  :episode:  1\n",
      "q_loss:  [[[3.2381003]]]\n",
      "t:  322  :episode:  1\n",
      "q_loss:  [[[1.252777]]]\n",
      "t:  323  :episode:  1\n",
      "q_loss:  [[[3.732598]]]\n",
      "t:  324  :episode:  1\n",
      "q_loss:  [[[1.5188107]]]\n",
      "t:  325  :episode:  1\n",
      "q_loss:  [[[1.0835328]]]\n",
      "t:  326  :episode:  1\n",
      "q_loss:  [[[5.308741]]]\n",
      "t:  327  :episode:  1\n",
      "q_loss:  [[[5.1050653]]]\n",
      "t:  328  :episode:  1\n",
      "q_loss:  [[[2.8061094]]]\n",
      "t:  329  :episode:  1\n",
      "q_loss:  [[[0.7814774]]]\n",
      "t:  330  :episode:  1\n",
      "q_loss:  [[[6.357142]]]\n",
      "t:  331  :episode:  1\n",
      "q_loss:  [[[4.2006903]]]\n",
      "t:  332  :episode:  1\n",
      "q_loss:  [[[8.02228]]]\n",
      "t:  333  :episode:  1\n",
      "q_loss:  [[[6.2040133]]]\n",
      "t:  334  :episode:  1\n",
      "q_loss:  [[[1.8114438]]]\n",
      "t:  335  :episode:  1\n",
      "q_loss:  [[[1.9967046]]]\n",
      "t:  336  :episode:  1\n",
      "q_loss:  [[[2.2038126]]]\n",
      "t:  337  :episode:  1\n",
      "q_loss:  [[[7.8478837]]]\n",
      "t:  338  :episode:  1\n",
      "q_loss:  [[[1.6664269]]]\n",
      "t:  339  :episode:  1\n",
      "q_loss:  [[[2.7298875]]]\n",
      "t:  340  :episode:  1\n",
      "q_loss:  [[[2.8789976]]]\n",
      "t:  341  :episode:  1\n",
      "q_loss:  [[[0.81248236]]]\n",
      "t:  342  :episode:  1\n",
      "q_loss:  [[[1.4888294]]]\n",
      "t:  343  :episode:  1\n",
      "q_loss:  [[[0.9969818]]]\n",
      "t:  344  :episode:  1\n",
      "q_loss:  [[[5.0449758]]]\n",
      "t:  345  :episode:  1\n",
      "q_loss:  [[[3.1568246]]]\n",
      "t:  346  :episode:  1\n",
      "q_loss:  [[[11.198284]]]\n",
      "t:  347  :episode:  1\n",
      "q_loss:  [[[13.622168]]]\n",
      "t:  348  :episode:  1\n",
      "q_loss:  [[[0.66213804]]]\n",
      "t:  349  :episode:  1\n",
      "q_loss:  [[[2.0252843]]]\n",
      "t:  350  :episode:  1\n",
      "q_loss:  [[[2.2439263]]]\n",
      "t:  351  :episode:  1\n",
      "q_loss:  [[[1.5950946]]]\n",
      "t:  352  :episode:  1\n",
      "q_loss:  [[[15.02868]]]\n",
      "t:  353  :episode:  1\n",
      "q_loss:  [[[1.569985]]]\n",
      "t:  354  :episode:  1\n",
      "q_loss:  [[[5.2553477]]]\n",
      "t:  355  :episode:  1\n",
      "q_loss:  [[[3.5287755]]]\n",
      "t:  356  :episode:  1\n",
      "q_loss:  [[[4.792222]]]\n",
      "t:  357  :episode:  1\n",
      "q_loss:  [[[4.728452]]]\n",
      "t:  358  :episode:  1\n",
      "q_loss:  [[[2.752617]]]\n",
      "t:  359  :episode:  1\n",
      "q_loss:  [[[1.28182]]]\n",
      "t:  360  :episode:  1\n",
      "q_loss:  [[[3.4943357]]]\n",
      "t:  361  :episode:  1\n",
      "q_loss:  [[[8.561575]]]\n",
      "t:  362  :episode:  1\n",
      "q_loss:  [[[1.9876361]]]\n",
      "t:  363  :episode:  1\n",
      "q_loss:  [[[1.5983485]]]\n",
      "t:  364  :episode:  1\n",
      "q_loss:  [[[0.90395796]]]\n",
      "t:  365  :episode:  1\n",
      "q_loss:  [[[1.4163234]]]\n",
      "t:  366  :episode:  1\n",
      "q_loss:  [[[1.6390383]]]\n",
      "t:  367  :episode:  1\n",
      "q_loss:  [[[4.505313]]]\n",
      "t:  368  :episode:  1\n",
      "q_loss:  [[[2.0241613]]]\n",
      "t:  369  :episode:  1\n",
      "q_loss:  [[[0.55952734]]]\n",
      "t:  370  :episode:  1\n",
      "q_loss:  [[[1.4689587]]]\n",
      "t:  371  :episode:  1\n",
      "q_loss:  [[[6.6020975]]]\n",
      "t:  372  :episode:  1\n",
      "q_loss:  [[[6.7614083]]]\n",
      "t:  373  :episode:  1\n",
      "q_loss:  [[[2.0090916]]]\n",
      "t:  374  :episode:  1\n",
      "q_loss:  [[[3.3436215]]]\n",
      "t:  375  :episode:  1\n",
      "q_loss:  [[[1.3188323]]]\n",
      "t:  376  :episode:  1\n",
      "q_loss:  [[[1.8144802]]]\n",
      "t:  377  :episode:  1\n",
      "q_loss:  [[[1.0565001]]]\n",
      "t:  378  :episode:  1\n",
      "q_loss:  [[[0.61878943]]]\n",
      "t:  379  :episode:  1\n",
      "q_loss:  [[[4.21209]]]\n",
      "t:  380  :episode:  1\n",
      "q_loss:  [[[2.1641536]]]\n",
      "t:  381  :episode:  1\n",
      "q_loss:  [[[20.291836]]]\n",
      "t:  382  :episode:  1\n",
      "q_loss:  [[[0.63334584]]]\n",
      "t:  383  :episode:  1\n",
      "q_loss:  [[[0.68688995]]]\n",
      "t:  384  :episode:  1\n",
      "q_loss:  [[[1.5181905]]]\n",
      "t:  385  :episode:  1\n",
      "q_loss:  [[[10.450124]]]\n",
      "t:  386  :episode:  1\n",
      "q_loss:  [[[3.3470256]]]\n",
      "t:  387  :episode:  1\n",
      "q_loss:  [[[0.5625243]]]\n",
      "t:  388  :episode:  1\n",
      "q_loss:  [[[2.2744453]]]\n",
      "t:  389  :episode:  1\n",
      "q_loss:  [[[2.8322434]]]\n",
      "t:  390  :episode:  1\n",
      "q_loss:  [[[1.3336031]]]\n",
      "t:  391  :episode:  1\n",
      "q_loss:  [[[13.781844]]]\n",
      "t:  392  :episode:  1\n",
      "q_loss:  [[[0.680646]]]\n",
      "t:  393  :episode:  1\n",
      "q_loss:  [[[2.281472]]]\n",
      "t:  394  :episode:  1\n",
      "q_loss:  [[[2.5785038]]]\n",
      "t:  395  :episode:  1\n",
      "q_loss:  [[[0.7370282]]]\n",
      "t:  396  :episode:  1\n",
      "q_loss:  [[[1.1626073]]]\n",
      "t:  397  :episode:  1\n",
      "q_loss:  [[[2.8152933]]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t:  398  :episode:  1\n",
      "q_loss:  [[[0.90266305]]]\n",
      "t:  399  :episode:  1\n",
      "q_loss:  [[[4.0427923]]]\n",
      "t:  400  :episode:  1\n",
      "q_loss:  [[[6.7602386]]]\n",
      "t:  401  :episode:  1\n",
      "q_loss:  [[[2.782588]]]\n",
      "t:  402  :episode:  1\n",
      "q_loss:  [[[0.9536701]]]\n",
      "t:  403  :episode:  1\n",
      "q_loss:  [[[1.2498293]]]\n",
      "t:  404  :episode:  1\n",
      "q_loss:  [[[9.341126]]]\n",
      "t:  405  :episode:  1\n",
      "q_loss:  [[[1.2558991]]]\n",
      "t:  406  :episode:  1\n",
      "q_loss:  [[[2.7359335]]]\n",
      "t:  407  :episode:  1\n",
      "q_loss:  [[[1.8276253]]]\n",
      "t:  408  :episode:  1\n",
      "q_loss:  [[[4.802902]]]\n",
      "t:  409  :episode:  1\n",
      "q_loss:  [[[1.8129337]]]\n",
      "t:  410  :episode:  1\n",
      "q_loss:  [[[0.45803678]]]\n",
      "t:  411  :episode:  1\n",
      "q_loss:  [[[1.6446155]]]\n",
      "t:  412  :episode:  1\n",
      "q_loss:  [[[1.3370475]]]\n",
      "t:  413  :episode:  1\n",
      "q_loss:  [[[5.9385867]]]\n",
      "t:  414  :episode:  1\n",
      "q_loss:  [[[5.775182]]]\n",
      "t:  415  :episode:  1\n",
      "q_loss:  [[[3.1966753]]]\n",
      "t:  416  :episode:  1\n",
      "q_loss:  [[[1.981069]]]\n",
      "t:  417  :episode:  1\n",
      "q_loss:  [[[6.9583097]]]\n",
      "t:  418  :episode:  1\n",
      "q_loss:  [[[2.6222093]]]\n",
      "t:  419  :episode:  1\n",
      "q_loss:  [[[1.8949392]]]\n",
      "t:  420  :episode:  1\n",
      "q_loss:  [[[1.8314621]]]\n",
      "t:  421  :episode:  1\n",
      "q_loss:  [[[1.1849321]]]\n",
      "t:  422  :episode:  1\n",
      "q_loss:  [[[0.6710565]]]\n",
      "t:  423  :episode:  1\n",
      "q_loss:  [[[2.1205704]]]\n",
      "t:  424  :episode:  1\n",
      "q_loss:  [[[27.982887]]]\n",
      "t:  425  :episode:  1\n",
      "q_loss:  [[[1.0255481]]]\n",
      "t:  426  :episode:  1\n",
      "q_loss:  [[[1.1055586]]]\n",
      "t:  427  :episode:  1\n",
      "q_loss:  [[[2.5546088]]]\n",
      "t:  428  :episode:  1\n",
      "q_loss:  [[[0.67553353]]]\n",
      "t:  429  :episode:  1\n",
      "q_loss:  [[[0.40015876]]]\n",
      "t:  430  :episode:  1\n",
      "q_loss:  [[[2.5410647]]]\n",
      "t:  431  :episode:  1\n",
      "q_loss:  [[[0.5800855]]]\n",
      "t:  432  :episode:  1\n",
      "q_loss:  [[[4.0976286]]]\n",
      "t:  433  :episode:  1\n",
      "q_loss:  [[[1.1163398]]]\n",
      "t:  434  :episode:  1\n",
      "q_loss:  [[[0.4293052]]]\n",
      "t:  435  :episode:  1\n",
      "q_loss:  [[[1.4198469]]]\n",
      "t:  436  :episode:  1\n",
      "q_loss:  [[[1.8740121]]]\n",
      "t:  437  :episode:  1\n",
      "q_loss:  [[[3.182565]]]\n",
      "t:  438  :episode:  1\n",
      "q_loss:  [[[0.9564251]]]\n",
      "t:  439  :episode:  1\n",
      "q_loss:  [[[1.4052607]]]\n",
      "t:  440  :episode:  1\n",
      "q_loss:  [[[2.2097967]]]\n",
      "t:  441  :episode:  1\n",
      "q_loss:  [[[2.0449235]]]\n",
      "t:  442  :episode:  1\n",
      "q_loss:  [[[1.6003418]]]\n",
      "t:  443  :episode:  1\n",
      "q_loss:  [[[14.255424]]]\n",
      "t:  444  :episode:  1\n",
      "q_loss:  [[[2.612029]]]\n",
      "t:  445  :episode:  1\n",
      "q_loss:  [[[2.3507695]]]\n",
      "t:  446  :episode:  1\n",
      "q_loss:  [[[0.19040433]]]\n",
      "t:  447  :episode:  1\n",
      "q_loss:  [[[0.6656627]]]\n",
      "t:  448  :episode:  1\n",
      "q_loss:  [[[0.4736815]]]\n",
      "t:  449  :episode:  1\n",
      "q_loss:  [[[4.432304]]]\n",
      "t:  450  :episode:  1\n",
      "q_loss:  [[[0.88335484]]]\n",
      "t:  451  :episode:  1\n",
      "q_loss:  [[[1.029296]]]\n",
      "t:  452  :episode:  1\n",
      "q_loss:  [[[0.6324399]]]\n",
      "t:  453  :episode:  1\n",
      "q_loss:  [[[0.60189474]]]\n",
      "t:  454  :episode:  1\n",
      "q_loss:  [[[18.026987]]]\n",
      "t:  455  :episode:  1\n",
      "q_loss:  [[[3.609432]]]\n",
      "t:  456  :episode:  1\n",
      "q_loss:  [[[2.349938]]]\n",
      "t:  457  :episode:  1\n",
      "q_loss:  [[[2.7606144]]]\n",
      "t:  458  :episode:  1\n",
      "q_loss:  [[[1.6937671]]]\n",
      "t:  459  :episode:  1\n",
      "q_loss:  [[[1.4100957]]]\n",
      "t:  460  :episode:  1\n",
      "q_loss:  [[[0.89495724]]]\n",
      "t:  461  :episode:  1\n",
      "q_loss:  [[[2.1220956]]]\n",
      "t:  462  :episode:  1\n",
      "q_loss:  [[[0.5642526]]]\n",
      "t:  463  :episode:  1\n",
      "q_loss:  [[[4.26597]]]\n",
      "t:  464  :episode:  1\n",
      "q_loss:  [[[0.95407975]]]\n",
      "t:  465  :episode:  1\n",
      "q_loss:  [[[0.9324514]]]\n",
      "t:  466  :episode:  1\n",
      "q_loss:  [[[0.86825806]]]\n",
      "t:  467  :episode:  1\n",
      "q_loss:  [[[3.319419]]]\n",
      "t:  468  :episode:  1\n",
      "q_loss:  [[[1.8936462]]]\n",
      "t:  469  :episode:  1\n",
      "q_loss:  [[[0.7691028]]]\n",
      "t:  470  :episode:  1\n",
      "q_loss:  [[[8.499796]]]\n",
      "t:  471  :episode:  1\n",
      "q_loss:  [[[1.669055]]]\n",
      "t:  472  :episode:  1\n",
      "q_loss:  [[[1.2895072]]]\n",
      "t:  473  :episode:  1\n",
      "q_loss:  [[[1.8123956]]]\n",
      "t:  474  :episode:  1\n",
      "q_loss:  [[[6.803581]]]\n",
      "t:  475  :episode:  1\n",
      "q_loss:  [[[2.016222]]]\n",
      "t:  476  :episode:  1\n",
      "q_loss:  [[[3.5889635]]]\n",
      "t:  477  :episode:  1\n",
      "q_loss:  [[[1.4354978]]]\n",
      "t:  478  :episode:  1\n",
      "q_loss:  [[[1.4345226]]]\n",
      "t:  479  :episode:  1\n",
      "q_loss:  [[[4.9329824]]]\n",
      "t:  480  :episode:  1\n",
      "q_loss:  [[[1.8505548]]]\n",
      "t:  481  :episode:  1\n",
      "q_loss:  [[[0.86536634]]]\n",
      "t:  482  :episode:  1\n",
      "q_loss:  [[[0.6066623]]]\n",
      "t:  483  :episode:  1\n",
      "q_loss:  [[[2.9642453]]]\n",
      "t:  484  :episode:  1\n",
      "q_loss:  [[[0.82585233]]]\n",
      "t:  485  :episode:  1\n",
      "q_loss:  [[[0.69615394]]]\n",
      "t:  486  :episode:  1\n",
      "q_loss:  [[[3.3759181]]]\n",
      "t:  487  :episode:  1\n",
      "q_loss:  [[[2.3957744]]]\n",
      "t:  488  :episode:  1\n",
      "q_loss:  [[[1.5190909]]]\n",
      "t:  489  :episode:  1\n",
      "q_loss:  [[[2.5332315]]]\n",
      "t:  490  :episode:  1\n",
      "q_loss:  [[[6.137899]]]\n",
      "t:  491  :episode:  1\n",
      "q_loss:  [[[2.4824872]]]\n",
      "t:  492  :episode:  1\n",
      "q_loss:  [[[2.031185]]]\n",
      "t:  493  :episode:  1\n",
      "q_loss:  [[[0.95125735]]]\n",
      "t:  494  :episode:  1\n",
      "q_loss:  [[[0.65183127]]]\n",
      "t:  495  :episode:  1\n",
      "q_loss:  [[[2.6141882]]]\n",
      "t:  496  :episode:  1\n",
      "q_loss:  [[[1.3382214]]]\n",
      "t:  497  :episode:  1\n",
      "q_loss:  [[[0.2909999]]]\n",
      "t:  498  :episode:  1\n",
      "q_loss:  [[[1.0577619]]]\n",
      "t:  499  :episode:  1\n",
      "q_loss:  [[[5.711419]]]\n",
      "t:  500  :episode:  1\n",
      "q_loss:  [[[2.114022]]]\n",
      "t:  501  :episode:  1\n",
      "q_loss:  [[[0.5118611]]]\n",
      "t:  502  :episode:  1\n",
      "q_loss:  [[[2.3201041]]]\n",
      "t:  503  :episode:  1\n",
      "q_loss:  [[[0.90827435]]]\n",
      "t:  504  :episode:  1\n",
      "q_loss:  [[[1.049819]]]\n",
      "t:  505  :episode:  1\n",
      "q_loss:  [[[0.5319237]]]\n",
      "t:  506  :episode:  1\n",
      "q_loss:  [[[2.3250608]]]\n",
      "t:  507  :episode:  1\n",
      "q_loss:  [[[0.8629999]]]\n",
      "t:  508  :episode:  1\n",
      "q_loss:  [[[1.4467931]]]\n",
      "t:  509  :episode:  1\n",
      "q_loss:  [[[1.6137493]]]\n",
      "t:  510  :episode:  1\n",
      "q_loss:  [[[1.4527509]]]\n",
      "t:  511  :episode:  1\n"
     ]
    }
   ],
   "source": [
    "state = env.reset()\n",
    "sac = SAC(action_space=action_space,\n",
    "          state_space=state_space,\n",
    "          capacity = buffer_size,\n",
    "          batch = batch_size,\n",
    "          tau = 0.999,\n",
    "          gamma = 0.99,\n",
    "          actor_lr = 0.0001,\n",
    "          critic_lr = 0.001,\n",
    "          variance = 0.2)\n",
    "\n",
    "#fill replay buffer\n",
    "#env._max_episode_steps = buffer_size\n",
    "#sac.replay_buffer.fill_buffer(buffer_size, state, episode_steps) # self,timesteps,state,prev_timesteps\n",
    "#env._max_episode_steps = episode_steps\n",
    "\n",
    "\n",
    "env = gym.wrappers.Monitor(env, \"baseline_training\", video_callable=lambda episode: True, force=\"true\")\n",
    "state = env.reset()\n",
    "\n",
    "for episode in range(episodes):\n",
    "    sumreward = 0\n",
    "    for step in range(episode_steps):\n",
    "        #print(observation)\n",
    "        print('t: ',step, ' :episode: ',episode)\n",
    "        #print('state: ',state)\n",
    "        \n",
    "        # get action\n",
    "        state = tf.reshape(state,(1,1,state_space)) #,dtype='float32')\n",
    "        #print(state)\n",
    "        tensor_noisy_action = sac.actor(state)+sac.actor.continous_noise()\n",
    "        #tensor_action = tf.clip_by_value(tensor_action, clip_value_min=-1.0, clip_value_max=1.0)\n",
    "\n",
    "        noisy_action = tensor_noisy_action[0][0]\n",
    "        #print('action: ',action)\n",
    "        \n",
    "        #get loss\n",
    "        #q_loss = sac.critic(state,tensor_action)\n",
    "        \n",
    "        \n",
    "        # execute action\n",
    "        next_state, reward, done, info = env.step(noisy_action)\n",
    "        sumreward += reward\n",
    "\n",
    "        # store transitions\n",
    "        sac.store_replay(state,next_state,noisy_action,reward,done)\n",
    "        \n",
    "        #print('state: ',state)\n",
    "        #print('next_state: ',next_state)\n",
    "        #print('action: ',action)\n",
    "        #print('reward: ',reward)\n",
    "\n",
    "        #sample minibatch from data\n",
    "        states_i,next_states_i,actions_i,rewards_i,terminal_i = sac.replay_buffer.sample()\n",
    "        \n",
    "        #set labels y_i\n",
    "        y = sac.set_labels(states_i,next_states_i,actions_i,rewards_i,terminal_i)\n",
    "        #print('y: ',y)\n",
    "        \n",
    "        # update critic net\n",
    "        q_loss = sac.critic.update(states_i, actions_i, y)\n",
    "\n",
    "        print('q_loss: ', q_loss.numpy())\n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar('Squared QLosses (qtarget - qval)^2', q_loss[0][0][0].numpy(),\n",
    "                              step=episode * episode_steps + step + 1)\n",
    "        \n",
    "        #losses[episode*timesteps + t] = loss\n",
    "        #losses[i_episode*timesteps+] = history.history\n",
    "        \n",
    "        #update actor net\n",
    "        sac.actor.update(states_i, sac.actor(states_i)) #actions)\n",
    "        #print('weight check: ',rl.actor.get_weights(),'\\n')\n",
    "        \n",
    "        #update target nets\n",
    "        sac.update_target_weights()\n",
    "        \n",
    "        state = next_state\n",
    "        if done:\n",
    "            state = env.reset()\n",
    "            #rewards[episode] = sumreward\n",
    "            #sac.save(base_dir+'/baseline_model')\n",
    "            print(\"Episode {} finished after {} timesteps with average reward {}\".format(episode,step+1,sumreward))\n",
    "            with writer_reward.as_default():\n",
    "                tf.summary.scalar('Episode sum reward', sumreward,step=episode)\n",
    "            break\n",
    "print('done') \n",
    "sac.save(base_dir+'/baseline_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6aFHYhHwRxH6"
   },
   "source": [
    " https://datascience.stackexchange.com/questions/13216/intuitive-explanation-of-noise-contrastive-estimation-nce-loss(InfoNCE Loss )\n",
    "<br>\n",
    "Representation Learning with Contrastive Predictive Coding\n",
    "<br>\n",
    "https://github.com/gdao-research/cpc/blob/master/cpc/data_handler.py (CPC)\n",
    "<br>\n",
    "https://github.com/davidtellez/contrastive-predictive-coding/blob/master/train_model.py (CPC)\n",
    "<br>\n",
    "https://github.com/MishaLaskin/curl/blob/23b0880708c29b078b0a25e62ff31fb587587b18/utils.py#L123 (replay buffer and SAC)\n",
    "<br>\n",
    "https://github.com/marload/DeepRL-TensorFlow2/blob/master/A2C/A2C_Discrete.py (A2C)\n",
    "<br>\n",
    "https://github.com/germain-hug/Deep-RL-Keras/blob/master/A3C/a3c.py (A3C)\n",
    "<br>\n",
    "https://github.com/tensorflow/agents/blob/v0.5.0/tf_agents/agents/sac/sac_agent.py (SAC)\n",
    "<br>\n",
    "https://github.com/cookbenjamin/DDPG/blob/master/networks/critic.py (transfer the action state merge to second layer)\n",
    "<br>\n",
    "https://github.com/georgesung/TD3 (check expected results)\n",
    "<br>\n",
    "https://github.com/georgesung/TD3/blob/master/DDPG.py (param mistake)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "CPCprocess.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:csci-7000-rl] *",
   "language": "python",
   "name": "conda-env-csci-7000-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
